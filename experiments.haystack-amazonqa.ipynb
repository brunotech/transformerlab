{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 14:55:39 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
      "03/06/2021 14:55:39 - INFO - faiss.loader -   Loading faiss.\n",
      "03/06/2021 14:55:39 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "from haystack.pipeline import ExtractiveQAPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four types of dataset associated with AmazonQA:\n",
    "\n",
    "* Products: combination of Amazon reviews and questions\n",
    "* QA pairs: heuristics applied to the products dataset to generate QA pairs and query-relevant review snippets (the main contribution from the paper)\n",
    "* SQuAD style: conversion of QA pairs to extractive QA format\n",
    "* MS MARCO: conversion of QA pairs to abstractive QA format'\n",
    "\n",
    "Task:\n",
    "\n",
    "> Given a set of product reviews and a question concerning a specific product, generate an informative\n",
    "natural language answer.\n",
    "\n",
    "So could build a system where you search for a product and then ask questions about that product. Will need a way to lookup Amazon Standard Identification Number (ASIN) per product to be human readable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-qar_squad_all.jsonl\t  train-qar_squad-music.json\n",
      "train-qar.jsonl\t\t\t  train-qar_squad-music.jsonl\n",
      "train-qar.jsonl.bak\t\t  train-qar_squad.json\n",
      "train-qar_meta.jsonl\t\t  train-qar_squad.jsonl\n",
      "train-qar_msmarco.jsonl\t\t  val-qar_squad-electronics.json\n",
      "train-qar_products.jsonl\t  val-qar_squad-music.json\n",
      "train-qar_squad-electronics.json  val-qar_squad.jsonl\n"
     ]
    }
   ],
   "source": [
    "data = Path('./data/amazon-qa')\n",
    "!ls {data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>questions</th>\n",
       "      <th>reviews</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B007F357HQ</td>\n",
       "      <td>[{'questionText': 'I had shoulder surgery 6 months ago and have a 4\" wide sc...</td>\n",
       "      <td>[{'helpful': [1, 1], 'reviewText': 'Love this - wasn't sure I would as I tho...</td>\n",
       "      <td>Beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00CRAJZFW</td>\n",
       "      <td>[{'questionText': 'is it for iphones', 'questionType': 'yesno', 'answers': [...</td>\n",
       "      <td>[{'helpful': [2, 4], 'reviewText': 'This product arrived exactly as pictured...</td>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002ZAZ7H4</td>\n",
       "      <td>[{'questionText': 'what is the width and ht of the cells?', 'questionType': ...</td>\n",
       "      <td>[{'helpful': [0, 0], 'reviewText': 'Very well constructed and designed.I lik...</td>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B008SCP8UE</td>\n",
       "      <td>[{'questionText': 'is it big for a bunny', 'questionType': 'yesno', 'answers...</td>\n",
       "      <td>[{'helpful': [0, 0], 'reviewText': 'Absolutely love!!! It was cute and easy ...</td>\n",
       "      <td>Pet_Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B001O4F8Y4</td>\n",
       "      <td>[{'questionText': 'We are having a problem with the range. We have an old ho...</td>\n",
       "      <td>[{'helpful': [0, 0], 'reviewText': 'We have a two story home and notice that...</td>\n",
       "      <td>Tools_and_Home_Improvement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  B007F357HQ   \n",
       "1  B00CRAJZFW   \n",
       "2  B002ZAZ7H4   \n",
       "3  B008SCP8UE   \n",
       "4  B001O4F8Y4   \n",
       "\n",
       "                                                                         questions  \\\n",
       "0  [{'questionText': 'I had shoulder surgery 6 months ago and have a 4\" wide sc...   \n",
       "1  [{'questionText': 'is it for iphones', 'questionType': 'yesno', 'answers': [...   \n",
       "2  [{'questionText': 'what is the width and ht of the cells?', 'questionType': ...   \n",
       "3  [{'questionText': 'is it big for a bunny', 'questionType': 'yesno', 'answers...   \n",
       "4  [{'questionText': 'We are having a problem with the range. We have an old ho...   \n",
       "\n",
       "                                                                           reviews  \\\n",
       "0  [{'helpful': [1, 1], 'reviewText': 'Love this - wasn't sure I would as I tho...   \n",
       "1  [{'helpful': [2, 4], 'reviewText': 'This product arrived exactly as pictured...   \n",
       "2  [{'helpful': [0, 0], 'reviewText': 'Very well constructed and designed.I lik...   \n",
       "3  [{'helpful': [0, 0], 'reviewText': 'Absolutely love!!! It was cute and easy ...   \n",
       "4  [{'helpful': [0, 0], 'reviewText': 'We have a two story home and notice that...   \n",
       "\n",
       "                      category  \n",
       "0                       Beauty  \n",
       "1  Cell_Phones_and_Accessories  \n",
       "2             Home_and_Kitchen  \n",
       "3                 Pet_Supplies  \n",
       "4   Tools_and_Home_Improvement  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df = pd.read_json(data/'train-qar_products.jsonl', lines=True, nrows=10)\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>category</th>\n",
       "      <th>questionText</th>\n",
       "      <th>questionType</th>\n",
       "      <th>review_snippets</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_answerable</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000MP20BU</td>\n",
       "      <td>Toys_and_Games</td>\n",
       "      <td>Many have stated similar to the following: \"Paint Chips Off Easily; Pieces a...</td>\n",
       "      <td>descriptive</td>\n",
       "      <td>[A lot of reviewers have said things about this puzzle not being that durabl...</td>\n",
       "      <td>[{'answerText': 'The paint has held up through two toddlers and still going ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00BOXZZU2</td>\n",
       "      <td>Health_and_Personal_Care</td>\n",
       "      <td>Will these work with the Phillips sonicare handles?</td>\n",
       "      <td>descriptive</td>\n",
       "      <td>[I didn't even realize such a small electric tooth-brush existed till I acci...</td>\n",
       "      <td>[{'answerText': 'The answer unfortunately, is no. The Slim Sonic is a compac...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00CSYD4M2</td>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "      <td>What kind of sim card it use?</td>\n",
       "      <td>descriptive</td>\n",
       "      <td>[I bought this phone a few weeks ago.I am using it in Costa Rica with a Kolb...</td>\n",
       "      <td>[{'answerText': 'This phone is an unlocked GSM device, it requires a MINI SI...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00C5TNSRG</td>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "      <td>does anyone know if this dinnerware set does not contain lead or traces of l...</td>\n",
       "      <td>descriptive</td>\n",
       "      <td>[I love my new dishes! They are so versatile. I can set a casual table and y...</td>\n",
       "      <td>[{'answerText': 'According to the internet search:   three-layer glass lamin...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0099XQBD4</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>I'm thinking of getting in to modular synthesizers.  Would this work for that?</td>\n",
       "      <td>descriptive</td>\n",
       "      <td>[Will order another in the near future and arrived very quickly. Easy to ins...</td>\n",
       "      <td>[{'answerText': 'Yes it will.', 'answerType': 'NA', 'helpful': [1, 1]}, {'an...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                     category  \\\n",
       "0  B000MP20BU               Toys_and_Games   \n",
       "1  B00BOXZZU2     Health_and_Personal_Care   \n",
       "2  B00CSYD4M2  Cell_Phones_and_Accessories   \n",
       "3  B00C5TNSRG             Home_and_Kitchen   \n",
       "4  B0099XQBD4          Musical_Instruments   \n",
       "\n",
       "                                                                      questionText  \\\n",
       "0  Many have stated similar to the following: \"Paint Chips Off Easily; Pieces a...   \n",
       "1                              Will these work with the Phillips sonicare handles?   \n",
       "2                                                    What kind of sim card it use?   \n",
       "3  does anyone know if this dinnerware set does not contain lead or traces of l...   \n",
       "4   I'm thinking of getting in to modular synthesizers.  Would this work for that?   \n",
       "\n",
       "  questionType  \\\n",
       "0  descriptive   \n",
       "1  descriptive   \n",
       "2  descriptive   \n",
       "3  descriptive   \n",
       "4  descriptive   \n",
       "\n",
       "                                                                   review_snippets  \\\n",
       "0  [A lot of reviewers have said things about this puzzle not being that durabl...   \n",
       "1  [I didn't even realize such a small electric tooth-brush existed till I acci...   \n",
       "2  [I bought this phone a few weeks ago.I am using it in Costa Rica with a Kolb...   \n",
       "3  [I love my new dishes! They are so versatile. I can set a casual table and y...   \n",
       "4  [Will order another in the near future and arrived very quickly. Easy to ins...   \n",
       "\n",
       "                                                                           answers  \\\n",
       "0  [{'answerText': 'The paint has held up through two toddlers and still going ...   \n",
       "1  [{'answerText': 'The answer unfortunately, is no. The Slim Sonic is a compac...   \n",
       "2  [{'answerText': 'This phone is an unlocked GSM device, it requires a MINI SI...   \n",
       "3  [{'answerText': 'According to the internet search:   three-layer glass lamin...   \n",
       "4  [{'answerText': 'Yes it will.', 'answerType': 'NA', 'helpful': [1, 1]}, {'an...   \n",
       "\n",
       "   is_answerable  qid  \n",
       "0              1    0  \n",
       "1              0    1  \n",
       "2              1    2  \n",
       "3              0    3  \n",
       "4              0    4  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qar_df = pd.read_json(data/'train-qar.jsonl', lines=True, nrows=10)\n",
    "qar_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>qas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the perfect kit to get started. Everything is miniaturized and comes...</td>\n",
       "      <td>[{'id': 331392, 'is_impossible': False, 'question': 'What exactly comes in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>... it doesn't last quite as long as advertised so therefore, I had to conti...</td>\n",
       "      <td>[{'id': 684949, 'is_impossible': False, 'question': 'How do you apply this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a pretty cool filter. If you spin it around it will totally change t...</td>\n",
       "      <td>[{'id': 604553, 'is_impossible': False, 'question': 'Does this come with a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This product was the exact match of the original manufactured equipment.. On...</td>\n",
       "      <td>[{'id': 341653, 'is_impossible': False, 'question': 'How to remove midgate r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice kit. Works well. Adjustable for proper sighting. Good quality. Instruct...</td>\n",
       "      <td>[{'id': 192046, 'is_impossible': False, 'question': 'does this include the m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           context  \\\n",
       "0  This is the perfect kit to get started. Everything is miniaturized and comes...   \n",
       "1  ... it doesn't last quite as long as advertised so therefore, I had to conti...   \n",
       "2  This is a pretty cool filter. If you spin it around it will totally change t...   \n",
       "3  This product was the exact match of the original manufactured equipment.. On...   \n",
       "4  Nice kit. Works well. Adjustable for proper sighting. Good quality. Instruct...   \n",
       "\n",
       "                                                                               qas  \n",
       "0  [{'id': 331392, 'is_impossible': False, 'question': 'What exactly comes in t...  \n",
       "1  [{'id': 684949, 'is_impossible': False, 'question': 'How do you apply this p...  \n",
       "2  [{'id': 604553, 'is_impossible': False, 'question': 'Does this come with a c...  \n",
       "3  [{'id': 341653, 'is_impossible': False, 'question': 'How to remove midgate r...  \n",
       "4  [{'id': 192046, 'is_impossible': False, 'question': 'does this include the m...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df = pd.read_json(data/'train-qar_squad.jsonl', lines=True, nrows=10)\n",
    "squad_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MARCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>passages</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>wellFormedAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[If your VHS tapes are getting old you may have problems like that.  Also He...</td>\n",
       "      <td>[{'is_selected': 1, 'url': '', 'passage_text': 'This product arrived in a &amp;#...</td>\n",
       "      <td>I am having issues with dropped video. Audio is fine. I'm getting video abou...</td>\n",
       "      <td>384160</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[No they are not made in USA  not the ones I got sorry, I am not sure. I bel...</td>\n",
       "      <td>[{'is_selected': 1, 'url': '', 'passage_text': 'My wife and I looked for mon...</td>\n",
       "      <td>Are all mattress materials made in the USA?</td>\n",
       "      <td>282084</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[It's not really suited for handling large debris. It should only be used fo...</td>\n",
       "      <td>[{'is_selected': 1, 'url': '', 'passage_text': 'We purchased our home a few ...</td>\n",
       "      <td>How well does it handle leaves?  especially large leaves?  I had a KK severa...</td>\n",
       "      <td>454427</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[There is no adapter, just the micro SD card., It comes with a standard SD c...</td>\n",
       "      <td>[{'is_selected': 1, 'url': '', 'passage_text': 'I purchased this card for my...</td>\n",
       "      <td>Does this card come with the adapter for the larger slots as in a RaspberryPI?</td>\n",
       "      <td>193420</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[I have done that to another grease gun before.  You would probably have to ...</td>\n",
       "      <td>[{'is_selected': 1, 'url': '', 'passage_text': 'The first one I got didn't w...</td>\n",
       "      <td>would this work with oil instead of grease?  I have a old milling machine wi...</td>\n",
       "      <td>661529</td>\n",
       "      <td>YESNO</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           answers  \\\n",
       "0  [If your VHS tapes are getting old you may have problems like that.  Also He...   \n",
       "1  [No they are not made in USA  not the ones I got sorry, I am not sure. I bel...   \n",
       "2  [It's not really suited for handling large debris. It should only be used fo...   \n",
       "3  [There is no adapter, just the micro SD card., It comes with a standard SD c...   \n",
       "4  [I have done that to another grease gun before.  You would probably have to ...   \n",
       "\n",
       "                                                                          passages  \\\n",
       "0  [{'is_selected': 1, 'url': '', 'passage_text': 'This product arrived in a &#...   \n",
       "1  [{'is_selected': 1, 'url': '', 'passage_text': 'My wife and I looked for mon...   \n",
       "2  [{'is_selected': 1, 'url': '', 'passage_text': 'We purchased our home a few ...   \n",
       "3  [{'is_selected': 1, 'url': '', 'passage_text': 'I purchased this card for my...   \n",
       "4  [{'is_selected': 1, 'url': '', 'passage_text': 'The first one I got didn't w...   \n",
       "\n",
       "                                                                             query  \\\n",
       "0  I am having issues with dropped video. Audio is fine. I'm getting video abou...   \n",
       "1                                      Are all mattress materials made in the USA?   \n",
       "2  How well does it handle leaves?  especially large leaves?  I had a KK severa...   \n",
       "3   Does this card come with the adapter for the larger slots as in a RaspberryPI?   \n",
       "4  would this work with oil instead of grease?  I have a old milling machine wi...   \n",
       "\n",
       "   query_id   query_type wellFormedAnswers  \n",
       "0    384160  DESCRIPTION                []  \n",
       "1    282084  DESCRIPTION                []  \n",
       "2    454427  DESCRIPTION                []  \n",
       "3    193420  DESCRIPTION                []  \n",
       "4    661529        YESNO                []  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marco_df = pd.read_json(data/'train-qar_msmarco.jsonl', lines=True, nrows=10)\n",
    "marco_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "Let's pick out the mapping from ASIN to QID from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "738776it [00:44, 16546.13it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "with open(data/'train-qar.jsonl', 'r') as f:\n",
    "    for _, line in tqdm(enumerate(f)):\n",
    "        row = json.loads(line)\n",
    "        rows.append((row['asin'], row['category'], row['qid'], row['is_answerable']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>category</th>\n",
       "      <th>qid</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000MP20BU</td>\n",
       "      <td>Toys_and_Games</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00BOXZZU2</td>\n",
       "      <td>Health_and_Personal_Care</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00CSYD4M2</td>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00C5TNSRG</td>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0099XQBD4</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                     category  qid  is_answerable\n",
       "0  B000MP20BU               Toys_and_Games    0              1\n",
       "1  B00BOXZZU2     Health_and_Personal_Care    1              0\n",
       "2  B00CSYD4M2  Cell_Phones_and_Accessories    2              1\n",
       "3  B00C5TNSRG             Home_and_Kitchen    3              0\n",
       "4  B0099XQBD4          Musical_Instruments    4              0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.DataFrame(rows, columns=['asin', 'category', 'qid', 'is_answerable'])\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738776, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert meta_df['qid'].nunique() == len(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Electronics                    169764\n",
       "Home_and_Kitchen               107423\n",
       "Sports_and_Outdoors             70824\n",
       "Tools_and_Home_Improvement      62995\n",
       "Health_and_Personal_Care        47589\n",
       "Automotive                      45892\n",
       "Cell_Phones_and_Accessories     42211\n",
       "Patio_Lawn_and_Garden           36693\n",
       "Toys_and_Games                  30838\n",
       "Office_Products                 26086\n",
       "Beauty                          24956\n",
       "Pet_Supplies                    21668\n",
       "Baby                            14427\n",
       "Musical_Instruments             14285\n",
       "Grocery_and_Gourmet_Food        11553\n",
       "Video_Games                      5901\n",
       "Clothing_Shoes_and_Jewelry       5671\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Electronics                    28696\n",
       "Home_and_Kitchen               17640\n",
       "Sports_and_Outdoors            11881\n",
       "Tools_and_Home_Improvement     10283\n",
       "Automotive                      8172\n",
       "Health_and_Personal_Care        8051\n",
       "Cell_Phones_and_Accessories     7133\n",
       "Patio_Lawn_and_Garden           6108\n",
       "Toys_and_Games                  5725\n",
       "Beauty                          4450\n",
       "Office_Products                 4339\n",
       "Pet_Supplies                    3349\n",
       "Baby                            2466\n",
       "Musical_Instruments             2366\n",
       "Grocery_and_Gourmet_Food        2272\n",
       "Clothing_Shoes_and_Jewelry      1021\n",
       "Video_Games                      886\n",
       "Name: asin, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.groupby('category')['asin'].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category                     is_answerable\n",
       "Automotive                   0                 23656\n",
       "                             1                 22236\n",
       "Baby                         1                 10255\n",
       "                             0                  4172\n",
       "Beauty                       1                 15243\n",
       "                             0                  9713\n",
       "Cell_Phones_and_Accessories  1                 27446\n",
       "                             0                 14765\n",
       "Clothing_Shoes_and_Jewelry   1                  3315\n",
       "                             0                  2356\n",
       "Electronics                  1                108614\n",
       "                             0                 61150\n",
       "Grocery_and_Gourmet_Food     1                  6774\n",
       "                             0                  4779\n",
       "Health_and_Personal_Care     1                 29539\n",
       "                             0                 18050\n",
       "Home_and_Kitchen             1                 66384\n",
       "                             0                 41039\n",
       "Musical_Instruments          1                  8694\n",
       "                             0                  5591\n",
       "Office_Products              1                 16862\n",
       "                             0                  9224\n",
       "Patio_Lawn_and_Garden        1                 22200\n",
       "                             0                 14493\n",
       "Pet_Supplies                 1                 14431\n",
       "                             0                  7237\n",
       "Sports_and_Outdoors          1                 43278\n",
       "                             0                 27546\n",
       "Tools_and_Home_Improvement   1                 36872\n",
       "                             0                 26123\n",
       "Toys_and_Games               1                 19128\n",
       "                             0                 11710\n",
       "Video_Games                  1                  4660\n",
       "                             0                  1241\n",
       "Name: is_answerable, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.groupby('category')['is_answerable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>category</th>\n",
       "      <th>qid</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0099XQBD4</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>B00F9ECDRU</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>B0083FTVB8</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>B005ETZ7NW</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>B000EJTXZU</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738436</th>\n",
       "      <td>B001KPWU7A</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>738436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738527</th>\n",
       "      <td>B00AMPDYDS</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>738527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738581</th>\n",
       "      <td>B005IQGKX2</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>738581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738652</th>\n",
       "      <td>B001KPWU7A</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>738652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738656</th>\n",
       "      <td>B0001ARCFA</td>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>738656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin             category     qid  is_answerable\n",
       "4       B0099XQBD4  Musical_Instruments       4              0\n",
       "55      B00F9ECDRU  Musical_Instruments      55              0\n",
       "59      B0083FTVB8  Musical_Instruments      59              0\n",
       "231     B005ETZ7NW  Musical_Instruments     231              0\n",
       "269     B000EJTXZU  Musical_Instruments     269              0\n",
       "...            ...                  ...     ...            ...\n",
       "738436  B001KPWU7A  Musical_Instruments  738436              0\n",
       "738527  B00AMPDYDS  Musical_Instruments  738527              0\n",
       "738581  B005IQGKX2  Musical_Instruments  738581              1\n",
       "738652  B001KPWU7A  Musical_Instruments  738652              1\n",
       "738656  B0001ARCFA  Musical_Instruments  738656              0\n",
       "\n",
       "[14285 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.query(\"category == 'Musical_Instruments'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup: no fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a single category like `Musical_Instruments` and build a `DataFrame` that has `asin`, `context` columns that we can use to create a simple QA system with an existing model fine-tuned on SQuAD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toys_and_Games'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2category = pd.Series(meta_df[\"category\"].values, index=meta_df[\"qid\"]).to_dict()\n",
    "qid2category[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B000MP20BU'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2asin = pd.Series(meta_df[\"asin\"].values, index=meta_df[\"qid\"]).to_dict()\n",
    "qid2asin[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that all SQuAD entries are answerable (does this make sense?). What about SQuAD v2 with impossible questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2isanswer = pd.Series(meta_df[\"is_answerable\"].values, index=meta_df[\"qid\"]).to_dict()\n",
    "qid2isanswer[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B0057JCYYE'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2asin[331392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "455931it [00:25, 17910.73it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "with open(data/'train-qar_squad.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for _, line in tqdm(enumerate(f)):\n",
    "        row = json.loads(line)\n",
    "        qid = row[\"qas\"][0][\"id\"]\n",
    "        if qid2category[qid] == \"Electronics\":\n",
    "            rows.append((qid2asin[qid], row[\"context\"], row[\"qas\"], qid2isanswer[qid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>qas</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009R95M</td>\n",
       "      <td>This is a pretty cool filter. If you spin it around it will totally change t...</td>\n",
       "      <td>[{'id': 604553, 'is_impossible': False, 'question': 'Does this come with a c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0051GN8GQ</td>\n",
       "      <td>so they fit well and function perfectly as workout headphones. BUT the littl...</td>\n",
       "      <td>[{'id': 698250, 'is_impossible': False, 'question': 'Will these headphones w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00CQ35HBQ</td>\n",
       "      <td>The memory fit into my dell inspiron 15 laptop. The memory was installed and...</td>\n",
       "      <td>[{'id': 639762, 'is_impossible': False, 'question': 'I have a new Dell Inspi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00BOYQH44</td>\n",
       "      <td>This is the best camera I have ever owned. I have shot over 800 pictures &amp; h...</td>\n",
       "      <td>[{'id': 701290, 'is_impossible': False, 'question': 'Does this camera have a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B008HODL7K</td>\n",
       "      <td>Great unit, really can't be beat for the price. Other reviews mentioned unev...</td>\n",
       "      <td>[{'id': 319235, 'is_impossible': False, 'question': 'Does this unit have a C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  B00009R95M   \n",
       "1  B0051GN8GQ   \n",
       "2  B00CQ35HBQ   \n",
       "3  B00BOYQH44   \n",
       "4  B008HODL7K   \n",
       "\n",
       "                                                                              text  \\\n",
       "0  This is a pretty cool filter. If you spin it around it will totally change t...   \n",
       "1  so they fit well and function perfectly as workout headphones. BUT the littl...   \n",
       "2  The memory fit into my dell inspiron 15 laptop. The memory was installed and...   \n",
       "3  This is the best camera I have ever owned. I have shot over 800 pictures & h...   \n",
       "4  Great unit, really can't be beat for the price. Other reviews mentioned unev...   \n",
       "\n",
       "                                                                               qas  \\\n",
       "0  [{'id': 604553, 'is_impossible': False, 'question': 'Does this come with a c...   \n",
       "1  [{'id': 698250, 'is_impossible': False, 'question': 'Will these headphones w...   \n",
       "2  [{'id': 639762, 'is_impossible': False, 'question': 'I have a new Dell Inspi...   \n",
       "3  [{'id': 701290, 'is_impossible': False, 'question': 'Does this camera have a...   \n",
       "4  [{'id': 319235, 'is_impossible': False, 'question': 'Does this unit have a C...   \n",
       "\n",
       "   is_answerable  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.DataFrame(rows, columns=['asin', 'text', \"qas\", 'is_answerable'])\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    108614\n",
       "Name: is_answerable, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df['is_answerable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108614, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25301"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df['asin'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boot ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -nc https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
    "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
    "! chown -R daemon:daemon elasticsearch-7.9.2\n",
    "\n",
    "es_server = Popen(['elasticsearch-7.9.2/bin/elasticsearch'],\n",
    "                   stdout=PIPE, stderr=STDOUT,\n",
    "                   preexec_fn=lambda: os.setuid(1)  # as daemon\n",
    "                  )\n",
    "# wait until ES has started\n",
    "! sleep 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/ [status:200 request:0.094s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.011s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.004s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.024s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.002s]\n"
     ]
    }
   ],
   "source": [
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/04/2021 21:20:03 - INFO - elasticsearch -   POST http://localhost:9200/document/_delete_by_query [status:200 request:0.970s]\n"
     ]
    }
   ],
   "source": [
    "document_store.delete_all_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Works perfectly and easy to use. Software download also great.The only surprise was that the one I ordered, (USB) doesn't work with an iPad.I was thinking it would work with both PC and iPad. My mistake. I use this with Logic Pro X on an iMac running Mavericks (it's replacing an Mbox) and with a Sony Vaio running Windows 7 and get excellent results (don't forget to install the Windows drivers or you'll run into latency issues). I also use it with the Auria App on my iPad Air. I did appreciate the direct line in switch...I could hear exactly what was being played into the unit without having to route through the computer. That was a nice feature. More recently, I was very happy to get this working with my ipad mini. I did purchase a recommended usb powered hub Belkin model &#34; F4U020&#34; and with that - I'm good to play music into and out of my ipad. Focusrite. An industry standard.I bought this specifically for use with an iPad to do mobile recording. The app I use is Auria, but GarageBand will work as well. Be sure to use/buy a POWERED USB hub in order to power the Scarlett.Wonderfully quiet device. Simple to use and the mic/instrument inputs are very warm sounding. It is truly shocking to see that you can achieve some VERY convincing, near commercial grade recording with this interface. Mac OS X 10.8.42: UpdateAmazon didn't sent me a 3rd replacement. And I'm really glad they didn't. I ended up saving a lot of money and buyingApogee Duet Audio Interface for iPad & Mac. After using Duet, I can tell you that any sound interface priced between 60 to 200 are the same thing. You may as well buy the simplest cheapest sound interface instead of this show off failure.I am very very VERY surprised about how many stars this product has. when i conect the headphones into the interface and give a test, i cant hear a suitable volume, i hear it very low; and if i increase the volume, this saturated.. very good this is honestly the best interface I've used for recording. this is a must but item you won't regret it. this is a beautiful piece of hardware. sounds really good. easy to use. and the director monitor function is great. the software that came with it is outdated and does not support Mavericks. however, I got on the help line and the gentlemen pointed me to a program called reaper that helped install the software so that I can take full advantage of it's benefits.Other than that! It's GREAT! and I love recording my guitar on it. Clean with no noise.\",\n",
       " 'meta': {'asin': 'B005OZE9SA', 'is_answerable': 1}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [{\"text\": row[\"text\"], \"meta\":{\"asin\": row[\"asin\"], \"is_answerable\": row[\"is_answerable\"]}} for _, row in qa_df.iterrows()]\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 15:11:02 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.124s]\n",
      "03/05/2021 15:11:04 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.382s]\n",
      "03/05/2021 15:11:05 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.381s]\n",
      "03/05/2021 15:11:06 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.281s]\n",
      "03/05/2021 15:11:08 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.237s]\n",
      "03/05/2021 15:11:09 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.254s]\n",
      "03/05/2021 15:11:10 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.260s]\n",
      "03/05/2021 15:11:12 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.275s]\n",
      "03/05/2021 15:11:13 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.273s]\n",
      "03/05/2021 15:11:14 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.272s]\n",
      "03/05/2021 15:11:16 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.264s]\n",
      "03/05/2021 15:11:17 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.276s]\n",
      "03/05/2021 15:11:18 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.331s]\n",
      "03/05/2021 15:11:20 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.288s]\n",
      "03/05/2021 15:11:21 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.285s]\n",
      "03/05/2021 15:11:22 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.257s]\n",
      "03/05/2021 15:11:24 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.265s]\n",
      "03/05/2021 15:11:25 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.238s]\n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 10:59:24 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/06/2021 10:59:42 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True, context_window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/squad/dev-v2.0.json: 100%|██████████| 1204/1204 [00:07<00:00, 162.32 Dicts/s]\n",
      "Evaluating: 100%|██████████| 274/274 [02:36<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# check evaluation on SQuAD v2\n",
    "reader_eval_results = reader.eval_on_file(\"data/squad\", \"dev-v2.0.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.9746483618293608\n",
      "Reader Exact Match: 0.7843005137707403\n",
      "Reader F1-Score: 0.8260896852846605\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1150/1150 [00:03<00:00, 371.15 Dicts/s]\n",
      "Evaluating: 100%|██████████| 133/133 [01:17<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# check evaluation on AmazonQA\n",
    "reader_eval_results = reader.eval_on_file(\"data/amazon-qa\", \"val-qar_squad-music.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.542608695652174\n",
      "Reader Exact Match: 0.0008695652173913044\n",
      "Reader F1-Score: 0.0752376647890378\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 14:39:19 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.088s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.25 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.14 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.83 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.97 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.93 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.88 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.86 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is a snare included?\n",
      "\n",
      "\n",
      "#1\n",
      "Answer: this one only came with one\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: the correct sounds out of it. When I slapped the \"bass\", it would play a \"snare\" sound combined with the bass. When I slapped the \"snare\", I would just get a wood sound.I've also seen images that most cajons come with multiple snares... this one only came with one.I'm really not sure what else to say. I wanted a Cajon to play with.but didn't want to pay 100.00 plus. This was a great option, Easy to put together with the limited tools I had on hand. And cheap enough that I wasn't worried to have \n",
      "\n",
      "\n",
      "\n",
      "#2\n",
      "Answer: this one only came with one\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: the correct sounds out of it. When I slapped the \"bass\", it would play a \"snare\" sound combined with the bass. When I slapped the \"snare\", I would just get a wood sound.I've also seen images that most cajons come with multiple snares... this one only came with one.I'm really not sure what else to say. I wanted a Cajon to play with.but didn't want to pay 100.00 plus. This was a great option, Easy to put together with the limited tools I had on hand. And cheap enough that I wasn't worried to have \n",
      "\n",
      "\n",
      "\n",
      "#3\n",
      "Answer: minimal snare sound\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: ussionist but a terrible wood worker so my husband built this for me. He said it was super easy and did not require a lot of tools. I've stained it black and added silver glitter paint and it looks snazzy. My only complaint is that it has a minimal snare sound. If you are a real percussionist, before you build this you may want to get some snare wires if you want more of a snare sound. I knew going in this would not be easy to put together. I tried to do as much research as possible, but... if y\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Is a snare included?\"\n",
    "# DIY drumkit\n",
    "asin = \"B009VDW4OW\"\n",
    "number_of_answers_to_fetch = 3\n",
    "\n",
    "prediction = pipe.run(query=query, filters={\"asin\": [asin]}, top_k_retriever=10, top_k_reader=number_of_answers_to_fetch)\n",
    "print(f\"Question: {prediction['query']}\")\n",
    "print(\"\\n\")\n",
    "for i in range(number_of_answers_to_fetch):\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Answer: {prediction['answers'][i]['answer']}\")\n",
    "    print(f\"ASIN: {prediction['answers'][i]['meta']['asin']}\")\n",
    "    print(f\"Is answerable?: {prediction['answers'][i]['meta']['is_answerable']}\")\n",
    "    print(f\"Context: {prediction['answers'][i]['context']}\")\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to the true SQuAD format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with our SQuAD dataset is that it is composed of _line-separated_ JSON instead of the single JSON object that SQuAD traditionally uses. So instead of having examples like \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"context\": \"blah blah\",\n",
    "    \"qas\": [\n",
    "        {\n",
    "            \"id\": 331392,\n",
    "            \"is_impossible\": false,\n",
    "            \"question\": \"blah blah?\",\n",
    "            \"answers\": [\n",
    "                {\n",
    "                    \"answer_start\": 2881,\n",
    "                    \"text\": \"blah blah\"\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            \"human_answers\": [\n",
    "                \"blah blah\",\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "what we really need is a JSON of the form\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": \"Beyoncé\",\n",
    "            \"paragraphs\": [\n",
    "                {\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"question\": \"When did Beyonce start becoming popular?\",\n",
    "                            \"id\": \"56be85543aeaaa14008c9063\",\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": \"in the late 1990s\",\n",
    "                                    \"answer_start\": 269\n",
    "                                }\n",
    "                            ],\n",
    "                            \"is_impossible\": false\n",
    "                        }\n",
    "                        ...\n",
    "                    ],\n",
    "                    \"context\": \"Beyoncé ...\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Let's write a function that does the conversion for us. To warm-up let's load a single example from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "with open(data/\"train-qar_squad.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        qid = ex[\"qas\"][0][\"id\"]\n",
    "        asin = qid2asin[qid]\n",
    "        if asin == \"B0057JCYYE\" or asin == \"B00F9ECDRU\":\n",
    "            examples.append(ex)\n",
    "        if len(examples) > 4:\n",
    "            break\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the human answers, but we do need the mapping from `qid` to `asin` so that we can collect all questions together that belong to the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin2qas = {}\n",
    "seen_asin = set()\n",
    "\n",
    "for ex in examples:\n",
    "    qid = ex[\"qas\"][0][\"id\"]\n",
    "    asin = qid2asin[qid]\n",
    "    qas = [{k:v for k,v in ex[\"qas\"][0].items() if k != \"human_answers\"}]\n",
    "    par = [{\"qas\": qas, \"context\": ex[\"context\"]}]\n",
    "\n",
    "    if asin in seen_asin:\n",
    "        asin2qas[asin].extend(par)\n",
    "    else:\n",
    "        asin2qas[asin] = par\n",
    "        seen_asin.add(asin)\n",
    "\n",
    "\n",
    "# asin2qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_data = []\n",
    "\n",
    "for k,v in asin2qas.items():\n",
    "    squad_ex = {}\n",
    "    squad_ex[\"title\"] = k\n",
    "    squad_ex[\"paragraphs\"] = v\n",
    "    squad_data.append(squad_ex)\n",
    "    \n",
    "squad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dict = {\"data\": squad_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data/\"train-qar_squad.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(squad_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out answer fields\n",
    "with open(data/\"val-qar_squad.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['answers_snippet_spans_bleu2',\n",
       " 'answers_snippet_spans_bleu4',\n",
       " 'answers_snippet_spans_rouge',\n",
       " 'answers_sentence_ir',\n",
       " 'answers_sentence_bleu2',\n",
       " 'answers_sentence_bleu4']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in ex[\"qas\"][0].keys() if k.startswith(\"answers\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_squad_format(input_file: Path, output_file: Path, category: str = \"Musical_Instruments\"):\n",
    "    squad_data = []\n",
    "    asin2qas = {}\n",
    "    seen_asin = set()\n",
    "    answer_fields = ['answers_snippet_spans_bleu2', 'answers_snippet_spans_bleu4',  \n",
    "                     'answers_snippet_spans_rouge', 'answers_sentence_ir', \n",
    "                     'answers_sentence_bleu2',  'answers_sentence_bleu4']\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for _, line in tqdm(enumerate(f)):\n",
    "            row = json.loads(line)\n",
    "            qid = row[\"qas\"][0][\"id\"]\n",
    "            if qid2category[qid] == category:\n",
    "                asin = qid2asin[qid]\n",
    "                qas = [{\"answers\" if k in answer_fields else k:v for k,v in row[\"qas\"][0].items()}]\n",
    "                par = [{\"qas\": qas, \"context\": row[\"context\"]}]\n",
    "                \n",
    "                if asin in seen_asin:\n",
    "                    asin2qas[asin].extend(par)\n",
    "                else:\n",
    "                    asin2qas[asin] = par\n",
    "                    seen_asin.add(asin)\n",
    "                    \n",
    "    for k,v in asin2qas.items():\n",
    "        squad_ex = {}\n",
    "        squad_ex[\"title\"] = k\n",
    "        squad_ex[\"paragraphs\"] = v\n",
    "        squad_data.append(squad_ex)\n",
    "\n",
    "    squad_dict = {\"data\": squad_data}\n",
    "        \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(squad_dict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "455931it [00:13, 34990.08it/s]\n"
     ]
    }
   ],
   "source": [
    "category = \"Electronics\"\n",
    "convert_to_squad_format(data/'train-qar_squad.jsonl', data/f'train-qar_squad-{category.lower()}.json', category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58969it [00:03, 15988.79it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_squad_format(data/'val-qar_squad.jsonl', data/f'val-qar_squad-{category.lower()}.json', category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_json(data/'train-qar_squad-electronics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'B00009R95M', 'paragraphs': [{'qas': [{'id': 604553, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'B0051GN8GQ', 'paragraphs': [{'qas': [{'id': 698250, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'B00CQ35HBQ', 'paragraphs': [{'qas': [{'id': 639762, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'B00BOYQH44', 'paragraphs': [{'qas': [{'id': 701290, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'B008HODL7K', 'paragraphs': [{'qas': [{'id': 319235, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25296</th>\n",
       "      <td>{'title': 'B005LLFY5Y', 'paragraphs': [{'qas': [{'id': 212671, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25297</th>\n",
       "      <td>{'title': 'B0053QC0EU', 'paragraphs': [{'qas': [{'id': 596763, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25298</th>\n",
       "      <td>{'title': 'B0068PVBLS', 'paragraphs': [{'qas': [{'id': 525680, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25299</th>\n",
       "      <td>{'title': 'B009I9MX5Y', 'paragraphs': [{'qas': [{'id': 632546, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25300</th>\n",
       "      <td>{'title': 'B0097F1LW0', 'paragraphs': [{'qas': [{'id': 193506, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25301 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  data\n",
       "0      {'title': 'B00009R95M', 'paragraphs': [{'qas': [{'id': 604553, 'is_impossibl...\n",
       "1      {'title': 'B0051GN8GQ', 'paragraphs': [{'qas': [{'id': 698250, 'is_impossibl...\n",
       "2      {'title': 'B00CQ35HBQ', 'paragraphs': [{'qas': [{'id': 639762, 'is_impossibl...\n",
       "3      {'title': 'B00BOYQH44', 'paragraphs': [{'qas': [{'id': 701290, 'is_impossibl...\n",
       "4      {'title': 'B008HODL7K', 'paragraphs': [{'qas': [{'id': 319235, 'is_impossibl...\n",
       "...                                                                                ...\n",
       "25296  {'title': 'B005LLFY5Y', 'paragraphs': [{'qas': [{'id': 212671, 'is_impossibl...\n",
       "25297  {'title': 'B0053QC0EU', 'paragraphs': [{'qas': [{'id': 596763, 'is_impossibl...\n",
       "25298  {'title': 'B0068PVBLS', 'paragraphs': [{'qas': [{'id': 525680, 'is_impossibl...\n",
       "25299  {'title': 'B009I9MX5Y', 'paragraphs': [{'qas': [{'id': 632546, 'is_impossibl...\n",
       "25300  {'title': 'B0097F1LW0', 'paragraphs': [{'qas': [{'id': 193506, 'is_impossibl...\n",
       "\n",
       "[25301 rows x 1 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either something is wrong with my data preparation or getting the model to generalise is _hard_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 14:57:00 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 14:57:10 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", use_gpu=True, context_window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"data/amazon-qa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 14:57:17 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-electronics.json:  88%|████████▊ | 96000/108614 [01:36<00:11, 1131.67 Dicts/s]Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-electronics.json: 100%|██████████| 108614/108614 [01:41<00:00, 1068.48 Dicts/s]\n",
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-electronics.json: 100%|██████████| 13647/13647 [00:15<00:00, 889.83 Dicts/s] \n",
      "03/06/2021 14:59:31 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_training_steps': 8551, 'num_warmup_steps': 1710}'\n",
      "Train epoch 0/0 (Cur. train loss: 1.7659):  12%|█▏        | 1000/8551 [16:15<2:02:32,  1.03it/s]\n",
      "Evaluating:   0%|          | 0/1295 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 27/1295 [00:10<08:03,  2.62it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 54/1295 [00:20<07:52,  2.62it/s]\u001b[A\n",
      "Evaluating:   6%|▋         | 81/1295 [00:30<07:42,  2.62it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 108/1295 [00:41<07:32,  2.62it/s]\u001b[A\n",
      "Evaluating:  10%|█         | 135/1295 [00:51<07:22,  2.62it/s]\u001b[A\n",
      "Evaluating:  13%|█▎        | 162/1295 [01:01<07:12,  2.62it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 189/1295 [01:12<07:01,  2.62it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 216/1295 [01:22<06:51,  2.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▉        | 243/1295 [01:32<06:41,  2.62it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 270/1295 [01:42<06:31,  2.62it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 270/1295 [01:53<06:31,  2.62it/s]\u001b[A\n",
      "Evaluating:  23%|██▎       | 297/1295 [01:53<06:20,  2.62it/s]\u001b[A\n",
      "Evaluating:  25%|██▌       | 324/1295 [02:03<06:10,  2.62it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 351/1295 [02:13<05:59,  2.62it/s]\u001b[A\n",
      "Evaluating:  29%|██▉       | 378/1295 [02:24<05:49,  2.62it/s]\u001b[A\n",
      "Evaluating:  31%|███▏      | 405/1295 [02:34<05:39,  2.62it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 432/1295 [02:44<05:29,  2.62it/s]\u001b[A\n",
      "Evaluating:  35%|███▌      | 459/1295 [02:55<05:18,  2.62it/s]\u001b[A\n",
      "Evaluating:  38%|███▊      | 486/1295 [03:05<05:08,  2.62it/s]\u001b[A\n",
      "Evaluating:  40%|███▉      | 513/1295 [03:16<05:02,  2.58it/s]\u001b[A\n",
      "Evaluating:  42%|████▏     | 540/1295 [03:26<04:50,  2.60it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 567/1295 [03:36<04:39,  2.60it/s]\u001b[A\n",
      "Evaluating:  46%|████▌     | 594/1295 [03:47<04:28,  2.61it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 621/1295 [03:57<04:18,  2.61it/s]\u001b[A\n",
      "Evaluating:  50%|█████     | 648/1295 [04:07<04:07,  2.61it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 675/1295 [04:17<03:56,  2.62it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 702/1295 [04:28<03:46,  2.62it/s]\u001b[A\n",
      "Evaluating:  56%|█████▋    | 729/1295 [04:38<03:36,  2.62it/s]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 756/1295 [04:48<03:25,  2.62it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 783/1295 [04:59<03:15,  2.62it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 810/1295 [05:09<03:05,  2.62it/s]\u001b[A\n",
      "Evaluating:  65%|██████▍   | 837/1295 [05:19<02:54,  2.62it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 864/1295 [05:30<02:44,  2.62it/s]\u001b[A\n",
      "Evaluating:  69%|██████▉   | 891/1295 [05:40<02:34,  2.62it/s]\u001b[A\n",
      "Evaluating:  71%|███████   | 918/1295 [05:50<02:23,  2.62it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 945/1295 [06:00<02:13,  2.62it/s]\u001b[A\n",
      "Evaluating:  75%|███████▌  | 972/1295 [06:11<02:03,  2.62it/s]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 999/1295 [06:21<01:52,  2.62it/s]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 1026/1295 [06:31<01:42,  2.62it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 1053/1295 [06:42<01:32,  2.62it/s]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 1080/1295 [06:52<01:21,  2.63it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 1107/1295 [07:02<01:11,  2.62it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 1134/1295 [07:12<01:01,  2.62it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 1134/1295 [07:23<01:01,  2.62it/s]\u001b[A\n",
      "Evaluating:  90%|████████▉ | 1161/1295 [07:23<00:51,  2.62it/s]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 1188/1295 [07:33<00:40,  2.63it/s]\u001b[A\n",
      "Evaluating:  94%|█████████▍| 1215/1295 [07:43<00:30,  2.63it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 1242/1295 [07:54<00:20,  2.63it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1295/1295 [08:14<00:00,  2.62it/s]\u001b[A\n",
      "03/06/2021 15:24:08 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "03/06/2021 15:24:08 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "03/06/2021 15:24:08 - INFO - farm.eval -   loss: 1.8848301156791185\n",
      "03/06/2021 15:24:08 - INFO - farm.eval -   task_name: question_answering\n",
      "03/06/2021 15:24:08 - INFO - farm.eval -   EM: 7.327617791455998e-05\n",
      "03/06/2021 15:24:08 - INFO - farm.eval -   f1: 7.327617791455998e-05\n",
      "03/06/2021 15:24:08 - INFO - farm.eval -   top_n_accuracy: 0.7143694584890452\n",
      "03/06/2021 15:24:08 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 1.9165):  23%|██▎       | 2000/8551 [40:24<1:43:52,  1.05it/s]   \n",
      "Evaluating:   0%|          | 0/1295 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 27/1295 [00:10<08:03,  2.62it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 54/1295 [00:20<07:53,  2.62it/s]\u001b[A\n",
      "Evaluating:   6%|▋         | 81/1295 [00:30<07:43,  2.62it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 108/1295 [00:41<07:32,  2.62it/s]\u001b[A\n",
      "Evaluating:  10%|█         | 135/1295 [00:51<07:22,  2.62it/s]\u001b[A\n",
      "Evaluating:  13%|█▎        | 162/1295 [01:01<07:12,  2.62it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 189/1295 [01:12<07:01,  2.62it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 216/1295 [01:22<06:51,  2.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▉        | 243/1295 [01:32<06:41,  2.62it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 270/1295 [01:42<06:30,  2.62it/s]\u001b[A\n",
      "Evaluating:  23%|██▎       | 297/1295 [01:53<06:20,  2.62it/s]\u001b[A\n",
      "Evaluating:  25%|██▌       | 324/1295 [02:03<06:10,  2.62it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 351/1295 [02:13<06:00,  2.62it/s]\u001b[A\n",
      "Evaluating:  29%|██▉       | 378/1295 [02:24<05:50,  2.62it/s]\u001b[A\n",
      "Evaluating:  31%|███▏      | 405/1295 [02:34<05:40,  2.62it/s]\u001b[A\n",
      "Evaluating:  31%|███▏      | 405/1295 [02:44<05:40,  2.62it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 432/1295 [02:44<05:29,  2.62it/s]\u001b[A\n",
      "Evaluating:  35%|███▌      | 459/1295 [02:55<05:19,  2.61it/s]\u001b[A\n",
      "Evaluating:  38%|███▊      | 486/1295 [03:05<05:09,  2.62it/s]\u001b[A\n",
      "Evaluating:  40%|███▉      | 513/1295 [03:15<04:58,  2.62it/s]\u001b[A\n",
      "Evaluating:  42%|████▏     | 540/1295 [03:26<04:48,  2.62it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 567/1295 [03:36<04:37,  2.62it/s]\u001b[A\n",
      "Evaluating:  46%|████▌     | 594/1295 [03:46<04:27,  2.62it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 621/1295 [03:57<04:17,  2.62it/s]\u001b[A\n",
      "Evaluating:  50%|█████     | 648/1295 [04:07<04:06,  2.62it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 675/1295 [04:17<03:56,  2.62it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 702/1295 [04:27<03:46,  2.62it/s]\u001b[A\n",
      "Evaluating:  56%|█████▋    | 729/1295 [04:38<03:36,  2.62it/s]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 756/1295 [04:48<03:25,  2.62it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 783/1295 [04:58<03:15,  2.62it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 810/1295 [05:09<03:05,  2.62it/s]\u001b[A\n",
      "Evaluating:  65%|██████▍   | 837/1295 [05:19<02:54,  2.62it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 864/1295 [05:29<02:44,  2.62it/s]\u001b[A\n",
      "Evaluating:  69%|██████▉   | 891/1295 [05:40<02:34,  2.62it/s]\u001b[A\n",
      "Evaluating:  71%|███████   | 918/1295 [05:50<02:23,  2.62it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 945/1295 [06:00<02:13,  2.62it/s]\u001b[A\n",
      "Evaluating:  75%|███████▌  | 972/1295 [06:11<02:03,  2.62it/s]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 999/1295 [06:21<01:53,  2.62it/s]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 1026/1295 [06:31<01:42,  2.62it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 1053/1295 [06:41<01:32,  2.62it/s]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 1080/1295 [06:52<01:22,  2.62it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 1107/1295 [07:02<01:11,  2.62it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 1134/1295 [07:12<01:01,  2.62it/s]\u001b[A\n",
      "Evaluating:  90%|████████▉ | 1161/1295 [07:23<00:51,  2.62it/s]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 1188/1295 [07:33<00:40,  2.62it/s]\u001b[A\n",
      "Evaluating:  94%|█████████▍| 1215/1295 [07:43<00:30,  2.62it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 1242/1295 [07:54<00:20,  2.62it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1295/1295 [08:14<00:00,  2.62it/s]\u001b[A\n",
      "03/06/2021 15:48:17 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 2000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "03/06/2021 15:48:17 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "03/06/2021 15:48:17 - INFO - farm.eval -   loss: 1.9383908767104487\n",
      "03/06/2021 15:48:17 - INFO - farm.eval -   task_name: question_answering\n",
      "03/06/2021 15:48:17 - INFO - farm.eval -   EM: 7.327617791455998e-05\n",
      "03/06/2021 15:48:17 - INFO - farm.eval -   f1: 7.327617791455998e-05\n",
      "03/06/2021 15:48:17 - INFO - farm.eval -   top_n_accuracy: 0.712244449329523\n",
      "03/06/2021 15:48:17 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 1.9658):  35%|███▌      | 3000/8551 [1:04:34<1:27:55,  1.05it/s] \n",
      "Evaluating:   0%|          | 0/1295 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 27/1295 [00:10<08:04,  2.62it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 54/1295 [00:20<07:54,  2.62it/s]\u001b[A\n",
      "Evaluating:   6%|▋         | 81/1295 [00:30<07:43,  2.62it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 108/1295 [00:41<07:33,  2.62it/s]\u001b[A\n",
      "Evaluating:  10%|█         | 135/1295 [00:51<07:23,  2.62it/s]\u001b[A\n",
      "Evaluating:  13%|█▎        | 162/1295 [01:01<07:12,  2.62it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 189/1295 [01:12<07:02,  2.62it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 216/1295 [01:22<06:52,  2.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▉        | 243/1295 [01:32<06:41,  2.62it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 270/1295 [01:43<06:31,  2.62it/s]\u001b[A\n",
      "Evaluating:  23%|██▎       | 297/1295 [01:53<06:21,  2.62it/s]\u001b[A\n",
      "Evaluating:  25%|██▌       | 324/1295 [02:03<06:11,  2.62it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 351/1295 [02:14<06:00,  2.62it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 351/1295 [02:24<06:00,  2.62it/s]\u001b[A\n",
      "Evaluating:  29%|██▉       | 378/1295 [02:24<05:50,  2.62it/s]\u001b[A\n",
      "Evaluating:  31%|███▏      | 405/1295 [02:34<05:40,  2.62it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 432/1295 [02:45<05:29,  2.62it/s]\u001b[A\n",
      "Evaluating:  35%|███▌      | 459/1295 [02:55<05:19,  2.62it/s]\u001b[A\n",
      "Evaluating:  38%|███▊      | 486/1295 [03:05<05:08,  2.62it/s]\u001b[A\n",
      "Evaluating:  40%|███▉      | 513/1295 [03:15<04:58,  2.62it/s]\u001b[A\n",
      "Evaluating:  42%|████▏     | 540/1295 [03:26<04:48,  2.62it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 567/1295 [03:36<04:38,  2.62it/s]\u001b[A\n",
      "Evaluating:  46%|████▌     | 594/1295 [03:46<04:27,  2.62it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 621/1295 [03:57<04:17,  2.62it/s]\u001b[A\n",
      "Evaluating:  50%|█████     | 648/1295 [04:07<04:07,  2.62it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 675/1295 [04:17<03:56,  2.62it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 702/1295 [04:28<03:46,  2.62it/s]\u001b[A\n",
      "Evaluating:  56%|█████▋    | 729/1295 [04:38<03:36,  2.62it/s]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 756/1295 [04:48<03:25,  2.62it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 783/1295 [04:59<03:15,  2.62it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 810/1295 [05:09<03:05,  2.62it/s]\u001b[A\n",
      "Evaluating:  65%|██████▍   | 837/1295 [05:19<02:55,  2.62it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 864/1295 [05:30<02:44,  2.62it/s]\u001b[A\n",
      "Evaluating:  69%|██████▉   | 891/1295 [05:40<02:34,  2.61it/s]\u001b[A\n",
      "Evaluating:  71%|███████   | 918/1295 [05:50<02:24,  2.61it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 945/1295 [06:01<02:13,  2.61it/s]\u001b[A\n",
      "Evaluating:  75%|███████▌  | 972/1295 [06:11<02:03,  2.61it/s]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 999/1295 [06:21<01:53,  2.61it/s]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 1026/1295 [06:32<01:43,  2.61it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 1053/1295 [06:42<01:32,  2.61it/s]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 1080/1295 [06:52<01:22,  2.61it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 1107/1295 [07:03<01:11,  2.61it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 1134/1295 [07:13<01:01,  2.61it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 1134/1295 [07:24<01:01,  2.61it/s]\u001b[A\n",
      "Evaluating:  90%|████████▉ | 1161/1295 [07:24<00:52,  2.57it/s]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 1188/1295 [07:34<00:41,  2.58it/s]\u001b[A\n",
      "Evaluating:  94%|█████████▍| 1215/1295 [07:44<00:30,  2.59it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 1242/1295 [07:55<00:20,  2.60it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1295/1295 [08:15<00:00,  2.61it/s]\u001b[A\n",
      "03/06/2021 16:12:28 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 3000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "03/06/2021 16:12:28 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "03/06/2021 16:12:28 - INFO - farm.eval -   loss: 1.931796616208448\n",
      "03/06/2021 16:12:28 - INFO - farm.eval -   task_name: question_answering\n",
      "03/06/2021 16:12:28 - INFO - farm.eval -   EM: 7.327617791455998e-05\n",
      "03/06/2021 16:12:28 - INFO - farm.eval -   f1: 7.327617791455998e-05\n",
      "03/06/2021 16:12:28 - INFO - farm.eval -   top_n_accuracy: 0.7296109034952737\n",
      "03/06/2021 16:12:28 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 2.0257):  47%|████▋     | 4000/8551 [1:28:46<1:12:35,  1.04it/s]   \n",
      "Evaluating:   0%|          | 0/1295 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 27/1295 [00:10<08:05,  2.61it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 54/1295 [00:20<07:55,  2.61it/s]\u001b[A\n",
      "Evaluating:   6%|▋         | 81/1295 [00:31<07:44,  2.61it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 108/1295 [00:41<07:34,  2.61it/s]\u001b[A\n",
      "Evaluating:  10%|█         | 135/1295 [00:51<07:24,  2.61it/s]\u001b[A\n",
      "Evaluating:  13%|█▎        | 162/1295 [01:02<07:13,  2.61it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 189/1295 [01:12<07:03,  2.61it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 216/1295 [01:22<06:53,  2.61it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 216/1295 [01:32<06:53,  2.61it/s]\u001b[A\n",
      "Evaluating:  19%|█▉        | 243/1295 [01:33<06:43,  2.61it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 270/1295 [01:43<06:32,  2.61it/s]\u001b[A\n",
      "Evaluating:  23%|██▎       | 297/1295 [01:53<06:21,  2.61it/s]\u001b[A\n",
      "Evaluating:  25%|██▌       | 324/1295 [02:04<06:11,  2.61it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 351/1295 [02:14<06:01,  2.61it/s]\u001b[A\n",
      "Evaluating:  29%|██▉       | 378/1295 [02:24<05:50,  2.61it/s]\u001b[A\n",
      "Evaluating:  31%|███▏      | 405/1295 [02:35<05:40,  2.61it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 432/1295 [02:45<05:30,  2.61it/s]\u001b[A\n",
      "Evaluating:  35%|███▌      | 459/1295 [02:55<05:20,  2.61it/s]\u001b[A\n",
      "Evaluating:  38%|███▊      | 486/1295 [03:06<05:10,  2.61it/s]\u001b[A\n",
      "Evaluating:  40%|███▉      | 513/1295 [03:16<04:59,  2.61it/s]\u001b[A\n",
      "Evaluating:  42%|████▏     | 540/1295 [03:26<04:49,  2.61it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 567/1295 [03:37<04:38,  2.61it/s]\u001b[A\n",
      "Evaluating:  46%|████▌     | 594/1295 [03:47<04:28,  2.61it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 621/1295 [03:57<04:18,  2.61it/s]\u001b[A\n",
      "Evaluating:  50%|█████     | 648/1295 [04:08<04:07,  2.61it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 675/1295 [04:18<03:57,  2.61it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 702/1295 [04:28<03:47,  2.61it/s]\u001b[A\n",
      "Evaluating:  56%|█████▋    | 729/1295 [04:39<03:37,  2.61it/s]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 756/1295 [04:49<03:26,  2.61it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 783/1295 [05:00<03:16,  2.61it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 810/1295 [05:10<03:08,  2.57it/s]\u001b[A\n",
      "Evaluating:  65%|██████▍   | 837/1295 [05:21<02:57,  2.58it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 864/1295 [05:31<02:46,  2.59it/s]\u001b[A\n",
      "Evaluating:  69%|██████▉   | 891/1295 [05:41<02:35,  2.60it/s]\u001b[A\n",
      "Evaluating:  71%|███████   | 918/1295 [05:52<02:24,  2.60it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 945/1295 [06:02<02:14,  2.61it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 945/1295 [06:12<02:14,  2.61it/s]\u001b[A\n",
      "Evaluating:  75%|███████▌  | 972/1295 [06:12<02:04,  2.60it/s]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 999/1295 [06:23<01:53,  2.61it/s]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 1026/1295 [06:33<01:43,  2.61it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 1053/1295 [06:44<01:32,  2.61it/s]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 1080/1295 [06:54<01:22,  2.60it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 1107/1295 [07:04<01:12,  2.61it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 1134/1295 [07:15<01:01,  2.61it/s]\u001b[A\n",
      "Evaluating:  90%|████████▉ | 1161/1295 [07:25<00:51,  2.61it/s]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 1188/1295 [07:35<00:41,  2.61it/s]\u001b[A\n",
      "Evaluating:  94%|█████████▍| 1215/1295 [07:46<00:30,  2.61it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 1242/1295 [07:56<00:20,  2.61it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1295/1295 [08:16<00:00,  2.61it/s]\u001b[A\n",
      "03/06/2021 16:36:41 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 4000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "03/06/2021 16:36:41 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "03/06/2021 16:36:41 - INFO - farm.eval -   loss: 2.015457434141105\n",
      "03/06/2021 16:36:41 - INFO - farm.eval -   task_name: question_answering\n",
      "03/06/2021 16:36:41 - INFO - farm.eval -   EM: 7.327617791455998e-05\n",
      "03/06/2021 16:36:41 - INFO - farm.eval -   f1: 7.327617791455998e-05\n",
      "03/06/2021 16:36:41 - INFO - farm.eval -   top_n_accuracy: 0.7192056862314061\n",
      "03/06/2021 16:36:41 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 1.4510):  58%|█████▊    | 5000/8551 [1:52:59<56:17,  1.05it/s]     \n",
      "Evaluating:   0%|          | 0/1295 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 27/1295 [00:10<08:05,  2.61it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 54/1295 [00:20<07:55,  2.61it/s]\u001b[A\n",
      "Evaluating:   6%|▋         | 81/1295 [00:31<07:45,  2.61it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 108/1295 [00:41<07:35,  2.61it/s]\u001b[A\n",
      "Evaluating:  10%|█         | 135/1295 [00:51<07:24,  2.61it/s]\u001b[A\n",
      "Evaluating:  13%|█▎        | 162/1295 [01:02<07:14,  2.61it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 189/1295 [01:12<07:03,  2.61it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 216/1295 [01:22<06:53,  2.61it/s]\u001b[A\n",
      "Evaluating:  19%|█▉        | 243/1295 [01:33<06:43,  2.61it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 270/1295 [01:43<06:32,  2.61it/s]\u001b[A\n",
      "Evaluating:  23%|██▎       | 297/1295 [01:54<06:28,  2.57it/s]\u001b[A\n",
      "Evaluating:  25%|██▌       | 324/1295 [02:04<06:15,  2.58it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 351/1295 [02:15<06:04,  2.59it/s]\u001b[A\n",
      "Evaluating:  29%|██▉       | 378/1295 [02:25<05:53,  2.59it/s]\u001b[A\n",
      "Evaluating:  31%|███▏      | 405/1295 [02:35<05:42,  2.60it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 432/1295 [02:46<05:31,  2.60it/s]\u001b[A\n",
      "Evaluating:  35%|███▌      | 459/1295 [02:56<05:21,  2.60it/s]\u001b[A\n",
      "Evaluating:  38%|███▊      | 486/1295 [03:06<05:10,  2.60it/s]\u001b[A\n",
      "Evaluating:  40%|███▉      | 513/1295 [03:17<05:00,  2.60it/s]\u001b[A\n",
      "Evaluating:  42%|████▏     | 540/1295 [03:27<04:49,  2.61it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 567/1295 [03:37<04:39,  2.61it/s]\u001b[A\n",
      "Evaluating:  46%|████▌     | 594/1295 [03:48<04:28,  2.61it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 621/1295 [03:58<04:18,  2.61it/s]\u001b[A\n",
      "Evaluating:  50%|█████     | 648/1295 [04:08<04:07,  2.61it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 675/1295 [04:19<03:57,  2.61it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 702/1295 [04:29<03:47,  2.61it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 702/1295 [04:39<03:47,  2.61it/s]\u001b[A\n",
      "Evaluating:  56%|█████▋    | 729/1295 [04:39<03:37,  2.61it/s]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 756/1295 [04:50<03:26,  2.61it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 783/1295 [05:00<03:16,  2.60it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 810/1295 [05:11<03:06,  2.60it/s]\u001b[A\n",
      "Evaluating:  65%|██████▍   | 837/1295 [05:21<02:55,  2.60it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 864/1295 [05:31<02:45,  2.61it/s]\u001b[A\n",
      "Evaluating:  69%|██████▉   | 891/1295 [05:42<02:34,  2.61it/s]\u001b[A\n",
      "Evaluating:  71%|███████   | 918/1295 [05:52<02:24,  2.61it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 945/1295 [06:02<02:14,  2.61it/s]\u001b[A\n",
      "Evaluating:  75%|███████▌  | 972/1295 [06:13<02:03,  2.61it/s]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 999/1295 [06:23<01:53,  2.61it/s]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 1026/1295 [06:33<01:43,  2.61it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 1053/1295 [06:44<01:32,  2.61it/s]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 1080/1295 [06:54<01:22,  2.60it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 1107/1295 [07:05<01:12,  2.61it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 1134/1295 [07:15<01:01,  2.60it/s]\u001b[A\n",
      "Evaluating:  90%|████████▉ | 1161/1295 [07:25<00:51,  2.60it/s]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 1188/1295 [07:36<00:41,  2.61it/s]\u001b[A\n",
      "Evaluating:  94%|█████████▍| 1215/1295 [07:46<00:30,  2.61it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 1242/1295 [07:56<00:20,  2.61it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1295/1295 [08:17<00:00,  2.60it/s]\u001b[A\n",
      "03/06/2021 17:00:55 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 5000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "03/06/2021 17:00:55 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "03/06/2021 17:00:55 - INFO - farm.eval -   loss: 1.965344638538348\n",
      "03/06/2021 17:00:55 - INFO - farm.eval -   task_name: question_answering\n",
      "03/06/2021 17:00:55 - INFO - farm.eval -   EM: 7.327617791455998e-05\n",
      "03/06/2021 17:00:55 - INFO - farm.eval -   f1: 7.327617791455998e-05\n",
      "03/06/2021 17:00:55 - INFO - farm.eval -   top_n_accuracy: 0.730710046163992\n",
      "03/06/2021 17:00:55 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 1.6632):  70%|███████   | 6000/8551 [2:17:13<40:22,  1.05it/s]     \n",
      "Evaluating:   0%|          | 0/1295 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 27/1295 [00:10<08:06,  2.61it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 54/1295 [00:20<07:55,  2.61it/s]\u001b[A\n",
      "Evaluating:   6%|▋         | 81/1295 [00:31<07:45,  2.61it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 108/1295 [00:41<07:35,  2.61it/s]\u001b[A\n",
      "Evaluating:  10%|█         | 135/1295 [00:51<07:24,  2.61it/s]\u001b[A\n",
      "Evaluating:  13%|█▎        | 162/1295 [01:02<07:14,  2.61it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 189/1295 [01:12<07:04,  2.61it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 216/1295 [01:22<06:53,  2.61it/s]\u001b[A\n",
      "Evaluating:  19%|█▉        | 243/1295 [01:33<06:43,  2.61it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 270/1295 [01:43<06:33,  2.61it/s]\u001b[A\n",
      "Evaluating:  23%|██▎       | 297/1295 [01:53<06:23,  2.60it/s]\u001b[A\n",
      "Evaluating:  25%|██▌       | 324/1295 [02:04<06:12,  2.61it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 351/1295 [02:14<06:01,  2.61it/s]\u001b[A\n",
      "Evaluating:  29%|██▉       | 378/1295 [02:24<05:51,  2.61it/s]\u001b[A\n",
      "Evaluating:  31%|███▏      | 405/1295 [02:35<05:41,  2.61it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 432/1295 [02:45<05:31,  2.61it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 432/1295 [02:55<05:31,  2.61it/s]\u001b[A\n",
      "Evaluating:  35%|███▌      | 459/1295 [02:56<05:20,  2.61it/s]\u001b[A\n",
      "Evaluating:  38%|███▊      | 486/1295 [03:06<05:10,  2.60it/s]\u001b[A\n",
      "Evaluating:  40%|███▉      | 513/1295 [03:16<05:00,  2.60it/s]\u001b[A\n",
      "Evaluating:  42%|████▏     | 540/1295 [03:27<04:49,  2.60it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 567/1295 [03:37<04:39,  2.60it/s]\u001b[A\n",
      "Evaluating:  46%|████▌     | 594/1295 [03:47<04:29,  2.60it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 621/1295 [03:58<04:18,  2.60it/s]\u001b[A\n",
      "Evaluating:  50%|█████     | 648/1295 [04:08<04:08,  2.60it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 675/1295 [04:19<03:58,  2.60it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 702/1295 [04:29<03:47,  2.61it/s]\u001b[A\n",
      "Evaluating:  56%|█████▋    | 729/1295 [04:39<03:37,  2.61it/s]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 756/1295 [04:50<03:26,  2.61it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 783/1295 [05:00<03:16,  2.61it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 810/1295 [05:10<03:06,  2.61it/s]\u001b[A\n",
      "Evaluating:  65%|██████▍   | 837/1295 [05:21<02:55,  2.61it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 864/1295 [05:31<02:45,  2.61it/s]\u001b[A\n",
      "Evaluating:  69%|██████▉   | 891/1295 [05:41<02:35,  2.61it/s]\u001b[A\n",
      "Evaluating:  71%|███████   | 918/1295 [05:52<02:24,  2.61it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 945/1295 [06:03<02:16,  2.57it/s]\u001b[A\n",
      "Evaluating:  75%|███████▌  | 972/1295 [06:13<02:05,  2.58it/s]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 999/1295 [06:23<01:54,  2.59it/s]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 1026/1295 [06:34<01:43,  2.59it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 1053/1295 [06:44<01:33,  2.60it/s]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 1080/1295 [06:54<01:22,  2.60it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 1107/1295 [07:05<01:12,  2.60it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 1134/1295 [07:15<01:01,  2.61it/s]\u001b[A\n",
      "Evaluating:  90%|████████▉ | 1161/1295 [07:25<00:51,  2.61it/s]\u001b[A\n",
      "Evaluating:  90%|████████▉ | 1161/1295 [07:36<00:51,  2.61it/s]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 1188/1295 [07:36<00:41,  2.61it/s]\u001b[A\n",
      "Evaluating:  94%|█████████▍| 1215/1295 [07:46<00:30,  2.61it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 1242/1295 [07:57<00:20,  2.61it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1295/1295 [08:17<00:00,  2.60it/s]\u001b[A\n",
      "03/06/2021 17:25:09 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 6000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "03/06/2021 17:25:09 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "03/06/2021 17:25:09 - INFO - farm.eval -   loss: 1.9032256234116998\n",
      "03/06/2021 17:25:09 - INFO - farm.eval -   task_name: question_answering\n",
      "03/06/2021 17:25:09 - INFO - farm.eval -   EM: 7.327617791455998e-05\n",
      "03/06/2021 17:25:09 - INFO - farm.eval -   f1: 7.327617791455998e-05\n",
      "03/06/2021 17:25:09 - INFO - farm.eval -   top_n_accuracy: 0.7118780684399502\n",
      "03/06/2021 17:25:09 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 1.6849):  82%|████████▏ | 7000/8551 [2:41:28<24:32,  1.05it/s]     \n",
      "Evaluating:   0%|          | 0/1295 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 27/1295 [00:10<08:07,  2.60it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 54/1295 [00:20<07:57,  2.60it/s]\u001b[A\n",
      "Evaluating:   6%|▋         | 81/1295 [00:31<07:46,  2.60it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 108/1295 [00:41<07:36,  2.60it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 108/1295 [00:51<07:36,  2.60it/s]\u001b[A\n",
      "Evaluating:  10%|█         | 135/1295 [00:51<07:25,  2.60it/s]\u001b[A\n",
      "Evaluating:  13%|█▎        | 162/1295 [01:02<07:15,  2.60it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 189/1295 [01:12<07:04,  2.61it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 216/1295 [01:22<06:54,  2.60it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 242/1295 [01:32<06:44,  2.60it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 269/1295 [01:43<06:34,  2.60it/s]\u001b[A\n",
      "Evaluating:  23%|██▎       | 296/1295 [01:53<06:23,  2.60it/s]\u001b[A\n",
      "Evaluating:  25%|██▍       | 323/1295 [02:04<06:13,  2.60it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 350/1295 [02:14<06:03,  2.60it/s]\u001b[A\n",
      "Evaluating:  29%|██▉       | 377/1295 [02:24<05:52,  2.60it/s]\u001b[A\n",
      "Evaluating:  31%|███       | 404/1295 [02:35<05:42,  2.60it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 431/1295 [02:45<05:31,  2.60it/s]\u001b[A\n",
      "Evaluating:  35%|███▌      | 458/1295 [02:55<05:21,  2.60it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 485/1295 [03:06<05:15,  2.56it/s]\u001b[A\n",
      "Evaluating:  40%|███▉      | 512/1295 [03:17<05:03,  2.58it/s]\u001b[A\n",
      "Evaluating:  42%|████▏     | 539/1295 [03:27<04:52,  2.59it/s]\u001b[A\n",
      "Evaluating:  44%|████▎     | 566/1295 [03:37<04:41,  2.59it/s]\u001b[A\n",
      "Evaluating:  46%|████▌     | 593/1295 [03:48<04:30,  2.59it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 620/1295 [03:58<04:20,  2.60it/s]\u001b[A\n",
      "Evaluating:  50%|████▉     | 646/1295 [04:08<04:10,  2.60it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 673/1295 [04:19<03:59,  2.60it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 700/1295 [04:29<03:48,  2.60it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 727/1295 [04:39<03:38,  2.60it/s]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 754/1295 [04:50<03:27,  2.60it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 781/1295 [05:00<03:17,  2.60it/s]\u001b[A\n",
      "Evaluating:  62%|██████▏   | 808/1295 [05:10<03:06,  2.60it/s]\u001b[A\n",
      "Evaluating:  64%|██████▍   | 835/1295 [05:21<02:56,  2.61it/s]\u001b[A\n",
      "Evaluating:  64%|██████▍   | 835/1295 [05:31<02:56,  2.61it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 862/1295 [05:31<02:46,  2.60it/s]\u001b[A\n",
      "Evaluating:  69%|██████▊   | 889/1295 [05:42<02:35,  2.60it/s]\u001b[A\n",
      "Evaluating:  71%|███████   | 916/1295 [05:52<02:25,  2.60it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 943/1295 [06:02<02:15,  2.60it/s]\u001b[A\n",
      "Evaluating:  75%|███████▍  | 970/1295 [06:13<02:04,  2.60it/s]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 997/1295 [06:23<01:54,  2.60it/s]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 1024/1295 [06:33<01:44,  2.60it/s]\u001b[A\n",
      "Evaluating:  81%|████████  | 1051/1295 [06:44<01:33,  2.60it/s]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 1078/1295 [06:54<01:23,  2.60it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 1105/1295 [07:05<01:13,  2.60it/s]\u001b[A\n",
      "Evaluating:  87%|████████▋ | 1132/1295 [07:15<01:02,  2.60it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 1158/1295 [07:25<00:52,  2.60it/s]\u001b[A\n",
      "Evaluating:  91%|█████████▏| 1184/1295 [07:35<00:42,  2.60it/s]\u001b[A\n",
      "Evaluating:  94%|█████████▎| 1211/1295 [07:45<00:32,  2.60it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 1238/1295 [07:56<00:21,  2.60it/s]\u001b[A\n",
      "Evaluating:  98%|█████████▊| 1265/1295 [08:06<00:11,  2.61it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1295/1295 [08:17<00:00,  2.60it/s]\u001b[A\n",
      "03/06/2021 17:49:25 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 7000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "03/06/2021 17:49:25 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "03/06/2021 17:49:25 - INFO - farm.eval -   loss: 1.960302877280558\n",
      "03/06/2021 17:49:25 - INFO - farm.eval -   task_name: question_answering\n",
      "03/06/2021 17:49:25 - INFO - farm.eval -   EM: 7.327617791455998e-05\n",
      "03/06/2021 17:49:25 - INFO - farm.eval -   f1: 7.327617791455998e-05\n",
      "03/06/2021 17:49:25 - INFO - farm.eval -   top_n_accuracy: 0.7206712097896973\n",
      "03/06/2021 17:49:25 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 1.6431):  94%|█████████▎| 8000/8551 [3:05:45<08:45,  1.05it/s]    \n",
      "Evaluating:   0%|          | 0/1295 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 26/1295 [00:10<08:08,  2.60it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 53/1295 [00:20<07:58,  2.60it/s]\u001b[A\n",
      "Evaluating:   6%|▌         | 80/1295 [00:30<07:47,  2.60it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 107/1295 [00:41<07:36,  2.60it/s]\u001b[A\n",
      "Evaluating:  10%|█         | 134/1295 [00:51<07:26,  2.60it/s]\u001b[A\n",
      "Evaluating:  12%|█▏        | 161/1295 [01:01<07:15,  2.60it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 188/1295 [01:12<07:05,  2.60it/s]\u001b[A\n",
      "Evaluating:  17%|█▋        | 214/1295 [01:22<06:55,  2.60it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 240/1295 [01:32<06:46,  2.60it/s]\u001b[A\n",
      "Evaluating:  21%|██        | 267/1295 [01:42<06:35,  2.60it/s]\u001b[A\n",
      "Evaluating:  23%|██▎       | 294/1295 [01:53<06:25,  2.60it/s]\u001b[A\n",
      "Evaluating:  25%|██▍       | 321/1295 [02:03<06:14,  2.60it/s]\u001b[A\n",
      "Evaluating:  27%|██▋       | 348/1295 [02:13<06:03,  2.60it/s]\u001b[A\n",
      "Evaluating:  29%|██▉       | 375/1295 [02:24<05:53,  2.60it/s]\u001b[A\n",
      "Evaluating:  31%|███       | 402/1295 [02:34<05:42,  2.60it/s]\u001b[A\n",
      "Evaluating:  31%|███       | 402/1295 [02:44<05:42,  2.60it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 429/1295 [02:44<05:32,  2.60it/s]\u001b[A\n",
      "Evaluating:  35%|███▌      | 456/1295 [02:55<05:21,  2.61it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 483/1295 [03:05<05:11,  2.61it/s]\u001b[A\n",
      "Evaluating:  39%|███▉      | 510/1295 [03:15<05:01,  2.61it/s]\u001b[A\n",
      "Evaluating:  41%|████▏     | 537/1295 [03:26<04:50,  2.61it/s]\u001b[A\n",
      "Evaluating:  44%|████▎     | 564/1295 [03:36<04:40,  2.61it/s]\u001b[A\n",
      "Evaluating:  46%|████▌     | 591/1295 [03:47<04:30,  2.61it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 618/1295 [03:57<04:19,  2.60it/s]\u001b[A\n",
      "Evaluating:  50%|████▉     | 645/1295 [04:07<04:09,  2.60it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 672/1295 [04:18<03:59,  2.60it/s]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 699/1295 [04:28<03:48,  2.60it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 726/1295 [04:38<03:38,  2.61it/s]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 753/1295 [04:49<03:28,  2.60it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 780/1295 [04:59<03:17,  2.61it/s]\u001b[A\n",
      "Evaluating:  62%|██████▏   | 807/1295 [05:09<03:07,  2.60it/s]\u001b[A\n",
      "Evaluating:  64%|██████▍   | 834/1295 [05:20<02:57,  2.60it/s]\u001b[A\n",
      "Evaluating:  66%|██████▋   | 860/1295 [05:30<02:47,  2.60it/s]\u001b[A\n",
      "Evaluating:  68%|██████▊   | 887/1295 [05:40<02:36,  2.60it/s]\u001b[A\n",
      "Evaluating:  71%|███████   | 914/1295 [05:51<02:26,  2.60it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 941/1295 [06:01<02:16,  2.60it/s]\u001b[A\n",
      "Evaluating:  75%|███████▍  | 968/1295 [06:11<02:05,  2.60it/s]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 994/1295 [06:21<01:55,  2.60it/s]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 1021/1295 [06:32<01:45,  2.60it/s]\u001b[A\n",
      "Evaluating:  81%|████████  | 1048/1295 [06:42<01:34,  2.60it/s]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 1075/1295 [06:52<01:24,  2.60it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 1102/1295 [07:03<01:14,  2.61it/s]\u001b[A\n",
      "Evaluating:  87%|████████▋ | 1129/1295 [07:13<01:03,  2.61it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 1156/1295 [07:24<00:53,  2.61it/s]\u001b[A\n",
      "Evaluating:  91%|█████████▏| 1183/1295 [07:34<00:42,  2.61it/s]\u001b[A\n",
      "Evaluating:  91%|█████████▏| 1183/1295 [07:44<00:42,  2.61it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 1210/1295 [07:44<00:32,  2.61it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 1237/1295 [07:55<00:22,  2.60it/s]\u001b[A\n",
      "Evaluating:  98%|█████████▊| 1264/1295 [08:05<00:11,  2.60it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1295/1295 [08:17<00:00,  2.60it/s]\u001b[A\n",
      "03/06/2021 18:13:41 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 8000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "03/06/2021 18:13:41 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "03/06/2021 18:13:41 - INFO - farm.eval -   loss: 1.9514359583207348\n",
      "03/06/2021 18:13:41 - INFO - farm.eval -   task_name: question_answering\n",
      "03/06/2021 18:13:41 - INFO - farm.eval -   EM: 7.327617791455998e-05\n",
      "03/06/2021 18:13:41 - INFO - farm.eval -   f1: 7.327617791455998e-05\n",
      "03/06/2021 18:13:41 - INFO - farm.eval -   top_n_accuracy: 0.7173737817835422\n",
      "03/06/2021 18:13:41 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 1.9773): 100%|██████████| 8551/8551 [3:22:52<00:00,  1.42s/it]    \n",
      "03/06/2021 18:22:24 - INFO - haystack.reader.farm -   Saving reader model to models/haystack\n"
     ]
    }
   ],
   "source": [
    "reader.train(data_dir=train_data, \n",
    "             train_filename=\"train-qar_squad-electronics.json\", \n",
    "             dev_filename=\"val-qar_squad-electronics.json\", \n",
    "             use_gpu=True, n_epochs=1, save_dir=\"models/haystack/\",\n",
    "             evaluate_every=1000,\n",
    "             batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 12:40:51 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 12:40:54 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "03/06/2021 12:40:54 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "new_reader = FARMReader(model_name_or_path=\"models/haystack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1150/1150 [00:02<00:00, 390.39 Dicts/s]\n",
      "Evaluating: 100%|██████████| 133/133 [01:17<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "reader_eval_results = new_reader.eval_on_file(\"data/amazon-qa\", \"val-qar_squad-music.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.7417391304347826\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(new_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.002s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2580>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2400>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2a60>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "ConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             response = self.pool.urlopen(\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    720\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;31m# Disabled, indicate to re-raise the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-671ad1318973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnumber_of_answers_to_fetch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"asin\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_answers_to_fetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Question: {prediction['query']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, filters, top_k_retriever, top_k_reader)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         output = self.pipeline.run(\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mhas_next_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_node_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"component\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mnext_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_node_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline_type, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipeline_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpipeline_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Indexing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/base.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, query, filters, top_k_retriever, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     ):\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/sparse.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self, query, filters, top_k, index)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/document_store/elasticsearch.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, filters, top_k, custom_query, index)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Retriever query: {body}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_es_hit_to_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_embedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"from\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m         return self.transport.perform_request(\n\u001b[0m\u001b[1;32m   1659\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0m_make_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0;31m# raise exception on last retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 status, headers_response, data = connection.perform_request(\n\u001b[0m\u001b[1;32m    359\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TIMEOUT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"N/A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# raise warnings if any from the 'Warnings' header.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused)"
     ]
    }
   ],
   "source": [
    "query = \"Is a snare included?\"\n",
    "# DIY drumkit\n",
    "asin = \"B009VDW4OW\"\n",
    "number_of_answers_to_fetch = 3\n",
    "\n",
    "prediction = pipe.run(query=query, filters={\"asin\": [asin]}, top_k_retriever=10, top_k_reader=number_of_answers_to_fetch)\n",
    "print(f\"Question: {prediction['query']}\")\n",
    "print(\"\\n\")\n",
    "for i in range(number_of_answers_to_fetch):\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Answer: {prediction['answers'][i]['answer']}\")\n",
    "    print(f\"ASIN: {prediction['answers'][i]['meta']['asin']}\")\n",
    "    print(f\"Is answerable?: {prediction['answers'][i]['meta']['is_answerable']}\")\n",
    "    print(f\"Context: {prediction['answers'][i]['context']}\")\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "#### New reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1828/1828 [00:03<00:00, 507.82 Dicts/s]\n",
      "Evaluating: 100%|██████████| 238/238 [02:16<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.5\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "reader_eval_results = new_reader.eval_on_file(train_data, \"val-qar_squad-music.json\", device='cuda')\n",
    "\n",
    "## Reader Top-N-Accuracy is the proportion of predicted answers that match with their corresponding correct answer\n",
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQuAD reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-music.json: 100%|██████████| 2100/2100 [00:03<00:00, 664.52 Dicts/s]\n",
      "Evaluating: 100%|██████████| 210/210 [02:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.0\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "reader_eval_results = reader.eval_on_file(train_data, \"train-qar_squad-music.json\", device='cuda')\n",
    "\n",
    "## Reader Top-N-Accuracy is the proportion of predicted answers that match with their corresponding correct answer\n",
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformerlab",
   "language": "python",
   "name": "transformerlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
