{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Transformers\n",
    "\n",
    "> A partial re-implementation of Movement Pruning: Adaptive Sparsity by Fine-Tuning by Victor Sanh, Thomas Wolf, and Alexander M. Rush [[arXiv:2005.07683](https://arxiv.org/abs/2005.07683)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [_Movement Pruning: Adaptive Sparsity by Fine-Tuning_](https://arxiv.org/abs/2005.07683) by Victor Sanh, Thomas Wolf, and Alexander M. Rush\n",
    "* The scripts and notebooks that accompany the paper ([link](https://github.com/huggingface/transformers/tree/master/examples/research_projects/movement-pruning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformerlab.question_answering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.1 1.2.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "datasets.logging.set_verbosity_error()\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "print(transformers.__version__, datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, default_data_collator, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init, CrossEntropyLoss\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix seed for sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\")\n",
    "squad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fine-pruned model\n",
    "\n",
    "HuggingFace has released a PruneBERT checkpoint for SQuAD v1.1 called `prunebert-base-uncased-6-finepruned-w-distil-squad` which is described in their docs as follows:\n",
    "\n",
    "> Pre-trained BERT-base-uncased fine-pruned with soft movement pruning on SQuAD v1.1. We use an additional distillation signal from `BERT-base-uncased` finetuned on SQuAD. The encoder counts 6% of total non-null weights and reaches 83.8 F1 score. The model can be accessed with: `pruned_bert = BertForQuestionAnswering.from_pretrained(\"huggingface/prunebert-base-uncased-6-finepruned-w-distil-squad\")`\n",
    "\n",
    "In this notebook we'll focus on reproducing this model, so let's begin by simply validating that we can obtain the same F1-score. Before doing that, we first need to preprocess the data - let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(dataset, tokenizer):\n",
    "    max_length = 384 \n",
    "    doc_stride = 128 \n",
    "    pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "    fn_kwargs = {\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"max_length\": max_length,\n",
    "        \"doc_stride\": doc_stride,\n",
    "        \"pad_on_right\": pad_on_right\n",
    "    }\n",
    "    \n",
    "    train_enc = dataset['train'].map(prepare_train_features, fn_kwargs=fn_kwargs, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "    valid_enc = dataset['validation'].map(prepare_validation_features, fn_kwargs=fn_kwargs, batched=True, remove_columns=dataset[\"validation\"].column_names)\n",
    "\n",
    "    return train_enc, valid_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_model_name = \"huggingface/prunebert-base-uncased-6-finepruned-w-distil-squad\"\n",
    "# pruned_tokenizer = AutoTokenizer.from_pretrained(pruned_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_enc, valid_enc = convert_examples_to_features(squad, pruned_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is preprocessed, let's instantiate a custom trainer and evaluate the model on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_model = AutoModelForQuestionAnswering.from_pretrained(pruned_model_name).to(device)\n",
    "# batch_size = 8\n",
    "\n",
    "# eval_ds = valid_enc\n",
    "# eval_raw_ds = squad[\"validation\"]\n",
    "\n",
    "# pruned_args = QuestionAnsweringTrainingArguments(\n",
    "#     output_dir=\"checkpoints\",\n",
    "#     per_device_eval_batch_size=batch_size)\n",
    "\n",
    "# data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_trainer = QuestionAnsweringTrainer(\n",
    "#     model=pruned_model,\n",
    "#     args=pruned_args,\n",
    "#     eval_dataset=eval_ds,\n",
    "#     eval_examples=eval_raw_ds,\n",
    "#     tokenizer=pruned_tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=squad_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great - we get an F1-score that matches the value quoted by HuggingFace!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune-tuning without distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc, valid_enc = convert_examples_to_features(squad, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create masked variants of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.configuration_utils import PretrainedConfig\n",
    "\n",
    "class MaskedBertConfig(PretrainedConfig):\n",
    "    \"\"\"\n",
    "    A class replicating the `~transformers.BertConfig` with additional parameters for pruning/masking configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    model_type = \"masked_bert\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=30522,\n",
    "        hidden_size=768,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=12,\n",
    "        intermediate_size=3072,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=512,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        pad_token_id=0,\n",
    "        pruning_method=\"topK\",\n",
    "        mask_init=\"constant\",\n",
    "        mask_scale=0.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(pad_token_id=pad_token_id, **kwargs)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.pruning_method = pruning_method\n",
    "        self.mask_init = mask_init\n",
    "        self.mask_scale = mask_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.models.bert.modeling_bert import load_tf_weights_in_bert, ACT2FN\n",
    "\n",
    "class MaskedBertPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\"An abstract class to handle weights initialization and\n",
    "    a simple interface for downloading and loading pretrained models.\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = MaskedBertConfig\n",
    "    load_tf_weights = load_tf_weights_in_bert\n",
    "    base_model_prefix = \"bert\"\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            # HACK: replace BertLayerNorm with LayerNorm\n",
    "        elif isinstance(module, torch.nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedBertModel(MaskedBertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    The `MaskedBertModel` class replicates the :class:`~transformers.BertModel` class\n",
    "    and adds specific inputs to compute the adaptive mask on the fly.\n",
    "    Note that we freeze the embeddings modules from their pre-trained values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.embeddings.requires_grad_(requires_grad=False)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"Prunes heads of the model.\n",
    "        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n",
    "        See base class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_shape, device=device)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        if attention_mask.dim() == 3:\n",
    "            extended_attention_mask = attention_mask[:, None, :, :]\n",
    "        elif attention_mask.dim() == 2:\n",
    "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
    "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
    "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "            if self.config.is_decoder:\n",
    "                batch_size, seq_length = input_shape\n",
    "                seq_ids = torch.arange(seq_length, device=device)\n",
    "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
    "                causal_mask = causal_mask.to(\n",
    "                    attention_mask.dtype\n",
    "                )  # causal and attention masks must have same type with pytorch version < 1.3\n",
    "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
    "            else:\n",
    "                extended_attention_mask = attention_mask[:, None, None, :]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
    "                    input_shape, attention_mask.shape\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        # If a 2D ou 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "\n",
    "            if encoder_attention_mask.dim() == 3:\n",
    "                encoder_extended_attention_mask = encoder_attention_mask[:, None, :, :]\n",
    "            elif encoder_attention_mask.dim() == 2:\n",
    "                encoder_extended_attention_mask = encoder_attention_mask[:, None, None, :]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\".format(\n",
    "                        encoder_hidden_shape, encoder_attention_mask.shape\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            encoder_extended_attention_mask = encoder_extended_attention_mask.to(\n",
    "                dtype=next(self.parameters()).dtype\n",
    "            )  # fp16 compatibility\n",
    "            encoder_extended_attention_mask = (1.0 - encoder_extended_attention_mask) * -10000.0\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        if head_mask is not None:\n",
    "            if head_mask.dim() == 1:\n",
    "                head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "                head_mask = head_mask.expand(self.config.num_hidden_layers, -1, -1, -1, -1)\n",
    "            elif head_mask.dim() == 2:\n",
    "                head_mask = (\n",
    "                    head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)\n",
    "                )  # We can specify head_mask for each layer\n",
    "            head_mask = head_mask.to(\n",
    "                dtype=next(self.parameters()).dtype\n",
    "            )  # switch to float if need + fp16 compatibility\n",
    "        else:\n",
    "            head_mask = [None] * self.config.num_hidden_layers\n",
    "\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "\n",
    "        outputs = (sequence_output, pooled_output,) + encoder_outputs[\n",
    "            1:\n",
    "        ]  # add hidden_states and attentions if they are here\n",
    "        return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "#         self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None):\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand(input_shape)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = inputs_embeds + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.output_attentions = config.output_attentions\n",
    "        self.output_hidden_states = config.output_hidden_states\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if self.output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(\n",
    "                hidden_states,\n",
    "                attention_mask,\n",
    "                head_mask[i],\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "                threshold=threshold,\n",
    "            )\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            if self.output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[1],)\n",
    "\n",
    "        # Add last layer\n",
    "        if self.output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if self.output_hidden_states:\n",
    "            outputs = outputs + (all_hidden_states,)\n",
    "        if self.output_attentions:\n",
    "            outputs = outputs + (all_attentions,)\n",
    "        return outputs  # last-layer hidden state, (all hidden states), (all attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedBertForQuestionAnswering(MaskedBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = MaskedBertModel(config)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        start_positions=None,\n",
    "        end_positions=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        outputs = (\n",
    "            start_logits,\n",
    "            end_logits,\n",
    "        ) + outputs[2:]\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions.clamp_(0, ignored_index)\n",
    "            end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            outputs = (total_loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), start_logits, end_logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        if self.is_decoder:\n",
    "            self.crossattention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "        self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask, threshold=threshold)\n",
    "        attention_output = self_attention_outputs[0]\n",
    "        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:]  # add cross attentions if we output attention weights\n",
    "\n",
    "        intermediate_output = self.intermediate(attention_output, threshold=threshold)\n",
    "        layer_output = self.output(intermediate_output, attention_output, threshold=threshold)\n",
    "        outputs = (layer_output,) + outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        mask = torch.ones(self.self.num_attention_heads, self.self.attention_head_size)\n",
    "        heads = set(heads) - self.pruned_heads  # Convert to set and remove already pruned heads\n",
    "        for head in heads:\n",
    "            # Compute how many pruned heads are before the head and move the index accordingly\n",
    "            head = head - sum(1 if h < head else 0 for h in self.pruned_heads)\n",
    "            mask[head] = 0\n",
    "        mask = mask.view(-1).contiguous().eq(1)\n",
    "        index = torch.arange(len(mask))[mask].long()\n",
    "\n",
    "        # Prune linear layers\n",
    "        self.self.query = prune_linear_layer(self.self.query, index)\n",
    "        self.self.key = prune_linear_layer(self.self.key, index)\n",
    "        self.self.value = prune_linear_layer(self.self.value, index)\n",
    "        self.output.dense = prune_linear_layer(self.output.dense, index, dim=1)\n",
    "\n",
    "        # Update hyper params and store pruned heads\n",
    "        self.self.num_attention_heads = self.self.num_attention_heads - len(heads)\n",
    "        self.self.all_head_size = self.self.attention_head_size * self.self.num_attention_heads\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "        self_outputs = self.self(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "        attention_output = self.output(self_outputs[0], hidden_states, threshold=threshold)\n",
    "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n",
    "            )\n",
    "        self.output_attentions = config.output_attentions\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            self.all_head_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        self.key = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            self.all_head_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        self.value = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            self.all_head_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "        mixed_query_layer = self.query(hidden_states, threshold=threshold)\n",
    "\n",
    "        # If this is instantiated as a cross-attention module, the keys\n",
    "        # and values come from an encoder; the attention mask needs to be\n",
    "        # such that the encoder's padding tokens are not attended to.\n",
    "        if encoder_hidden_states is not None:\n",
    "            mixed_key_layer = self.key(encoder_hidden_states, threshold=threshold)\n",
    "            mixed_value_layer = self.value(encoder_hidden_states, threshold=threshold)\n",
    "            attention_mask = encoder_attention_mask\n",
    "        else:\n",
    "            mixed_key_layer = self.key(hidden_states, threshold=threshold)\n",
    "            mixed_value_layer = self.value(hidden_states, threshold=threshold)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if self.output_attentions else (context_layer,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Linear):\n",
    "    \"\"\"\n",
    "    Fully Connected layer with on the fly adaptive mask.\n",
    "    If needed, a score matrix is created to store the importance of each associated weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        bias: bool = True,\n",
    "        mask_init: str = \"constant\",\n",
    "        mask_scale: float = 0.0,\n",
    "        pruning_method: str = \"topK\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_features (`int`)\n",
    "                Size of each input sample\n",
    "            out_features (`int`)\n",
    "                Size of each output sample\n",
    "            bias (`bool`)\n",
    "                If set to ``False``, the layer will not learn an additive bias.\n",
    "                Default: ``True``\n",
    "            mask_init (`str`)\n",
    "                The initialization method for the score matrix if a score matrix is needed.\n",
    "                Choices: [\"constant\", \"uniform\", \"kaiming\"]\n",
    "                Default: ``constant``\n",
    "            mask_scale (`float`)\n",
    "                The initialization parameter for the chosen initialization method `mask_init`.\n",
    "                Default: ``0.``\n",
    "            pruning_method (`str`)\n",
    "                Method to compute the mask.\n",
    "                Choices: [\"topK\", \"threshold\", \"sigmoied_threshold\", \"magnitude\", \"l0\"]\n",
    "                Default: ``topK``\n",
    "        \"\"\"\n",
    "        super(MaskedLinear, self).__init__(in_features=in_features, out_features=out_features, bias=bias)\n",
    "        assert pruning_method in [\"topK\", \"threshold\", \"sigmoied_threshold\", \"magnitude\", \"l0\"]\n",
    "        self.pruning_method = pruning_method\n",
    "\n",
    "        if self.pruning_method in [\"topK\", \"threshold\", \"sigmoied_threshold\", \"l0\"]:\n",
    "            self.mask_scale = mask_scale\n",
    "            self.mask_init = mask_init\n",
    "            self.mask_scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
    "            self.init_mask()\n",
    "\n",
    "    def init_mask(self):\n",
    "        if self.mask_init == \"constant\":\n",
    "            init.constant_(self.mask_scores, val=self.mask_scale)\n",
    "        elif self.mask_init == \"uniform\":\n",
    "            init.uniform_(self.mask_scores, a=-self.mask_scale, b=self.mask_scale)\n",
    "        elif self.mask_init == \"kaiming\":\n",
    "            init.kaiming_uniform_(self.mask_scores, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, input: torch.tensor, threshold: float):\n",
    "        # Get the mask\n",
    "        if self.pruning_method == \"topK\":\n",
    "            mask = TopKBinarizer.apply(self.mask_scores, threshold)\n",
    "        elif self.pruning_method in [\"threshold\", \"sigmoied_threshold\"]:\n",
    "            sig = \"sigmoied\" in self.pruning_method\n",
    "            mask = ThresholdBinarizer.apply(self.mask_scores, threshold, sig)\n",
    "        elif self.pruning_method == \"magnitude\":\n",
    "            mask = MagnitudeBinarizer.apply(self.weight, threshold)\n",
    "        elif self.pruning_method == \"l0\":\n",
    "            l, r, b = -0.1, 1.1, 2 / 3\n",
    "            if self.training:\n",
    "                u = torch.zeros_like(self.mask_scores).uniform_().clamp(0.0001, 0.9999)\n",
    "                s = torch.sigmoid((u.log() - (1 - u).log() + self.mask_scores) / b)\n",
    "            else:\n",
    "                s = torch.sigmoid(self.mask_scores)\n",
    "            s_bar = s * (r - l) + l\n",
    "            mask = s_bar.clamp(min=0.0, max=1.0)\n",
    "        # Mask weights with computed mask\n",
    "        weight_thresholded = mask * self.weight\n",
    "        # Compute output (linear layer) with masked weights\n",
    "        return F.linear(input, weight_thresholded, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            config.hidden_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "#         self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor, threshold):\n",
    "        hidden_states = self.dense(hidden_states, threshold=threshold)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            config.intermediate_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states, threshold):\n",
    "        hidden_states = self.dense(hidden_states, threshold=threshold)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = MaskedLinear(\n",
    "            config.intermediate_size,\n",
    "            config.hidden_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "#         self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor, threshold):\n",
    "        hidden_states = self.dense(hidden_states, threshold=threshold)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKBinarizer(autograd.Function):\n",
    "    \"\"\"\n",
    "    Top-k Binarizer.\n",
    "    Computes a binary mask M from a real value matrix S such that `M_{i,j} = 1` if and only if `S_{i,j}`\n",
    "    is among the k% highest values of S.\n",
    "\n",
    "    Implementation is inspired from:\n",
    "        https://github.com/allenai/hidden-networks\n",
    "        What's hidden in a randomly weighted neural network?\n",
    "        Vivek Ramanujan*, Mitchell Wortsman*, Aniruddha Kembhavi, Ali Farhadi, Mohammad Rastegari\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs: torch.tensor, threshold: float):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (`torch.FloatTensor`)\n",
    "                The input matrix from which the binarizer computes the binary mask.\n",
    "            threshold (`float`)\n",
    "                The percentage of weights to keep (the rest is pruned).\n",
    "                `threshold` is a float between 0 and 1.\n",
    "        Returns:\n",
    "            mask (`torch.FloatTensor`)\n",
    "                Binary matrix of the same size as `inputs` acting as a mask (1 - the associated weight is\n",
    "                retained, 0 - the associated weight is pruned).\n",
    "        \"\"\"\n",
    "        # Get the subnetwork by sorting the inputs and using the top threshold %\n",
    "        if not isinstance(threshold, float):\n",
    "            threshold = threshold[0]\n",
    "        mask = inputs.clone()\n",
    "        _, idx = inputs.flatten().sort(descending=True)\n",
    "        j = int(threshold * inputs.numel())\n",
    "\n",
    "        # flat_out and mask access the same memory.\n",
    "        flat_out = mask.flatten()\n",
    "        flat_out[idx[j:]] = 0\n",
    "        flat_out[idx[:j]] = 1\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, gradOutput):\n",
    "        return gradOutput, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainingArguments(QuestionAnsweringTrainingArguments):\n",
    "    def __init__(self, *args, initial_threshold=1., final_threshold=0.1, initial_warmup=1, final_warmup=2, final_lambda=0.,\n",
    "                 mask_scores_learning_rate=1e-2, **kwargs): \n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.initial_threshold = initial_threshold\n",
    "        self.final_threshold = final_threshold\n",
    "        self.initial_warmup = initial_warmup\n",
    "        self.final_warmup = final_warmup\n",
    "        self.final_lambda = final_lambda\n",
    "        self.mask_scores_learning_rate = mask_scores_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer(QuestionAnsweringTrainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        if self.args.max_steps > 0:\n",
    "            self.t_total = self.args.max_steps\n",
    "            self.args.num_train_epochs = self.args.max_steps // (len(self.train_dataset) // self.args.gradient_accumulation_steps) + 1\n",
    "        else:\n",
    "            self.t_total = len(self.get_train_dataloader()) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
    "            \n",
    "#     def get_train_dataloader(self) -> DataLoader:\n",
    "#         \"\"\"\n",
    "#         Returns the training :class:`~torch.utils.data.DataLoader`.\n",
    "\n",
    "#         Will use no sampler if :obj:`self.train_dataset` does not implement :obj:`__len__`, a random sampler (adapted\n",
    "#         to distributed training if necessary) otherwise.\n",
    "\n",
    "#         Subclass and override this method if you want to inject some custom behavior.\n",
    "#         \"\"\"\n",
    "#         if self.train_dataset is None:\n",
    "#             raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "#         train_sampler = SequentialSampler(self.train_dataset)\n",
    "\n",
    "#         return DataLoader(\n",
    "#             self.train_dataset,\n",
    "#             batch_size=self.args.train_batch_size,\n",
    "#             sampler=train_sampler,\n",
    "#             collate_fn=self.data_collator,\n",
    "#             drop_last=self.args.dataloader_drop_last,\n",
    "# #             num_workers=self.args.dataloader_num_workers,\n",
    "#         )\n",
    "        \n",
    "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if \"mask_score\" in n and p.requires_grad],\n",
    "                \"lr\": self.args.mask_scores_learning_rate,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.model.named_parameters()\n",
    "                    if \"mask_score\" not in n and p.requires_grad and not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"lr\": self.args.learning_rate,\n",
    "                \"weight_decay\": self.args.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.model.named_parameters()\n",
    "                    if \"mask_score\" not in n and p.requires_grad and any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"lr\": self.args.learning_rate,\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
    "        self.lr_scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer, num_warmup_steps=self.args.warmup_steps, num_training_steps=self.t_total\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def compute_loss(self, model, inputs):\n",
    "            \n",
    "        threshold, regu_lambda = self._schedule_threshold(\n",
    "            step=self.state.global_step+1,\n",
    "            total_step=self.t_total,\n",
    "            warmup_steps=self.args.warmup_steps,\n",
    "            final_threshold=self.args.final_threshold,\n",
    "            initial_threshold=self.args.initial_threshold,\n",
    "            final_warmup=self.args.final_warmup,\n",
    "            initial_warmup=self.args.initial_warmup,\n",
    "            final_lambda=self.args.final_lambda,\n",
    "        )\n",
    "        inputs[\"threshold\"] = threshold  \n",
    "#         print(inputs)\n",
    "        outputs = model(**inputs)\n",
    "        # model outputs are always tuple in transformers (see doc)\n",
    "        loss, start_logits_stu, end_logits_stu = outputs\n",
    "        print(f\"Step: {self.state.global_step} | Threshold: {threshold} | Loss: {loss} | t_total: {self.t_total}\")\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def _schedule_threshold(\n",
    "        self,\n",
    "        step: int,\n",
    "        total_step: int,\n",
    "        warmup_steps: int,\n",
    "        initial_threshold: float,\n",
    "        final_threshold: float,\n",
    "        initial_warmup: int,\n",
    "        final_warmup: int,\n",
    "        final_lambda: float,\n",
    "    ):\n",
    "        if step <= initial_warmup * warmup_steps:\n",
    "            threshold = initial_threshold\n",
    "        elif step > (total_step - final_warmup * warmup_steps):\n",
    "            threshold = final_threshold\n",
    "        else:\n",
    "            spars_warmup_steps = initial_warmup * warmup_steps\n",
    "            spars_schedu_steps = (final_warmup + initial_warmup) * warmup_steps\n",
    "            mul_coeff = 1 - (step - spars_warmup_steps) / (total_step - spars_schedu_steps)\n",
    "            threshold = final_threshold + (initial_threshold - final_threshold) * (mul_coeff ** 3)\n",
    "        regu_lambda = final_lambda * threshold / final_threshold\n",
    "        return threshold, regu_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 160\n",
      "Number of validation examples: 20\n",
      "Number of raw validation examples: 20\n",
      "Number of warmup steps: 6\n"
     ]
    }
   ],
   "source": [
    "masked_config = MaskedBertConfig(pruning_method='topK', mask_init='constant', mask_scale=0.)\n",
    "masked_model = MaskedBertForQuestionAnswering.from_pretrained('bert-base-uncased', config=masked_config).to(device)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_train_examples = 160\n",
    "num_eval_examples = 20\n",
    "\n",
    "train_ds = train_enc.select(range(num_train_examples))\n",
    "eval_ds = valid_enc.select(range(num_eval_examples))\n",
    "eval_raw_ds = squad[\"validation\"].select(range(num_eval_examples))\n",
    "warmup_steps = 6\n",
    "max_steps = 100\n",
    "num_train_epochs=3\n",
    "\n",
    "print(f\"Number of training examples: {train_ds.num_rows}\")\n",
    "print(f\"Number of validation examples: {eval_ds.num_rows}\")\n",
    "print(f\"Number of raw validation examples: {eval_raw_ds.num_rows}\")\n",
    "\n",
    "logging_steps = len(train_ds) // batch_size\n",
    "\n",
    "print(f\"Number of warmup steps: {warmup_steps}\")\n",
    "\n",
    "pruning_training_args = PruningTrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "#     max_steps=max_steps,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=0.0,\n",
    "    logging_steps=logging_steps,\n",
    "    disable_tqdm=False,\n",
    "    warmup_steps=warmup_steps,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = eval_ds.map(lambda x : {'threshold': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_trainer = PruningTrainer(\n",
    "    model=masked_model,\n",
    "    args=pruning_training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    eval_examples=eval_raw_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=squad_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruning_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | Threshold: 1.0 | Loss: 5.989073753356934 | t_total: 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.956089</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.966422</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.957299</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 | Threshold: 1.0 | Loss: 5.893919944763184 | t_total: 60\n",
      "Step: 2 | Threshold: 1.0 | Loss: 5.9488115310668945 | t_total: 60\n",
      "Step: 3 | Threshold: 1.0 | Loss: 5.98604679107666 | t_total: 60\n",
      "Step: 4 | Threshold: 1.0 | Loss: 5.863607883453369 | t_total: 60\n",
      "Step: 5 | Threshold: 1.0 | Loss: 5.869380950927734 | t_total: 60\n",
      "Step: 6 | Threshold: 0.9372327502429543 | Loss: 5.9508376121521 | t_total: 60\n",
      "Step: 7 | Threshold: 0.8774538386783283 | Loss: 6.036736965179443 | t_total: 60\n",
      "Step: 8 | Threshold: 0.8205903790087464 | Loss: 6.004860877990723 | t_total: 60\n",
      "Step: 9 | Threshold: 0.7665694849368319 | Loss: 5.8888068199157715 | t_total: 60\n",
      "Step: 10 | Threshold: 0.7153182701652089 | Loss: 6.004155158996582 | t_total: 60\n",
      "Step: 11 | Threshold: 0.6667638483965016 | Loss: 5.920261383056641 | t_total: 60\n",
      "Step: 12 | Threshold: 0.6208333333333335 | Loss: 5.958797454833984 | t_total: 60\n",
      "Step: 13 | Threshold: 0.5774538386783284 | Loss: 5.935825347900391 | t_total: 60\n",
      "Step: 14 | Threshold: 0.5365524781341108 | Loss: 5.93231201171875 | t_total: 60\n",
      "Step: 15 | Threshold: 0.4980563654033041 | Loss: 6.0241193771362305 | t_total: 60\n",
      "Step: 16 | Threshold: 0.46189261418853267 | Loss: 5.993441581726074 | t_total: 60\n",
      "Step: 17 | Threshold: 0.4279883381924199 | Loss: 5.990145683288574 | t_total: 60\n",
      "Step: 18 | Threshold: 0.39627065111758986 | Loss: 5.913715839385986 | t_total: 60\n",
      "Step: 19 | Threshold: 0.3666666666666668 | Loss: 6.0169358253479 | t_total: 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfaa8b9a88246e8bd886a085b163979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 20 | Threshold: 0.33910349854227395 | Loss: 5.960466384887695 | t_total: 60\n",
      "Step: 21 | Threshold: 0.313508260447036 | Loss: 5.9842729568481445 | t_total: 60\n",
      "Step: 22 | Threshold: 0.2898080660835763 | Loss: 5.977084159851074 | t_total: 60\n",
      "Step: 23 | Threshold: 0.2679300291545189 | Loss: 5.983955383300781 | t_total: 60\n",
      "Step: 24 | Threshold: 0.2478012633624879 | Loss: 6.001889228820801 | t_total: 60\n",
      "Step: 25 | Threshold: 0.22934888241010692 | Loss: 5.960569381713867 | t_total: 60\n",
      "Step: 26 | Threshold: 0.21250000000000002 | Loss: 5.970836639404297 | t_total: 60\n",
      "Step: 27 | Threshold: 0.19718172983479104 | Loss: 6.005782127380371 | t_total: 60\n",
      "Step: 28 | Threshold: 0.18332118561710398 | Loss: 5.9965009689331055 | t_total: 60\n",
      "Step: 29 | Threshold: 0.1708454810495627 | Loss: 5.954586982727051 | t_total: 60\n",
      "Step: 30 | Threshold: 0.15968172983479106 | Loss: 5.943173885345459 | t_total: 60\n",
      "Step: 31 | Threshold: 0.149757045675413 | Loss: 5.925638198852539 | t_total: 60\n",
      "Step: 32 | Threshold: 0.14099854227405248 | Loss: 5.959353446960449 | t_total: 60\n",
      "Step: 33 | Threshold: 0.13333333333333336 | Loss: 5.951009273529053 | t_total: 60\n",
      "Step: 34 | Threshold: 0.1266885325558795 | Loss: 5.935051918029785 | t_total: 60\n",
      "Step: 35 | Threshold: 0.12099125364431487 | Loss: 6.000402450561523 | t_total: 60\n",
      "Step: 36 | Threshold: 0.11616861030126337 | Loss: 5.959772109985352 | t_total: 60\n",
      "Step: 37 | Threshold: 0.1121477162293489 | Loss: 5.929208755493164 | t_total: 60\n",
      "Step: 38 | Threshold: 0.10885568513119534 | Loss: 6.0065202713012695 | t_total: 60\n",
      "Step: 39 | Threshold: 0.10621963070942664 | Loss: 5.922368049621582 | t_total: 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008e1a79fffa48c0a2743a8623ebb7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 40 | Threshold: 0.10416666666666667 | Loss: 6.004820823669434 | t_total: 60\n",
      "Step: 41 | Threshold: 0.10262390670553936 | Loss: 5.9538068771362305 | t_total: 60\n",
      "Step: 42 | Threshold: 0.10151846452866861 | Loss: 5.936786651611328 | t_total: 60\n",
      "Step: 43 | Threshold: 0.10077745383867834 | Loss: 5.942336082458496 | t_total: 60\n",
      "Step: 44 | Threshold: 0.10032798833819243 | Loss: 5.980342864990234 | t_total: 60\n",
      "Step: 45 | Threshold: 0.1000971817298348 | Loss: 5.992645263671875 | t_total: 60\n",
      "Step: 46 | Threshold: 0.10001214771622935 | Loss: 5.945922374725342 | t_total: 60\n",
      "Step: 47 | Threshold: 0.1 | Loss: 5.956737995147705 | t_total: 60\n",
      "Step: 48 | Threshold: 0.1 | Loss: 5.9454522132873535 | t_total: 60\n",
      "Step: 49 | Threshold: 0.1 | Loss: 5.923829555511475 | t_total: 60\n",
      "Step: 50 | Threshold: 0.1 | Loss: 5.968041896820068 | t_total: 60\n",
      "Step: 51 | Threshold: 0.1 | Loss: 5.959756851196289 | t_total: 60\n",
      "Step: 52 | Threshold: 0.1 | Loss: 5.955117225646973 | t_total: 60\n",
      "Step: 53 | Threshold: 0.1 | Loss: 5.997429370880127 | t_total: 60\n",
      "Step: 54 | Threshold: 0.1 | Loss: 5.9266276359558105 | t_total: 60\n",
      "Step: 55 | Threshold: 0.1 | Loss: 5.98231315612793 | t_total: 60\n",
      "Step: 56 | Threshold: 0.1 | Loss: 5.927659511566162 | t_total: 60\n",
      "Step: 57 | Threshold: 0.1 | Loss: 5.994391441345215 | t_total: 60\n",
      "Step: 58 | Threshold: 0.1 | Loss: 5.920318603515625 | t_total: 60\n",
      "Step: 59 | Threshold: 0.1 | Loss: 5.931645393371582 | t_total: 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd76808e240844a1941bfc312ea1be6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=5.959936777750651)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruning_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruning_trainer.t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
