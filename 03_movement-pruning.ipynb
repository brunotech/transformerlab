{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Transformers\n",
    "\n",
    "> A partial re-implementation of Movement Pruning: Adaptive Sparsity by Fine-Tuning by Victor Sanh, Thomas Wolf, and Alexander M. Rush [[arXiv:2005.07683](https://arxiv.org/abs/2005.07683)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [_Movement Pruning: Adaptive Sparsity by Fine-Tuning_](https://arxiv.org/abs/2005.07683) by Victor Sanh, Thomas Wolf, and Alexander M. Rush\n",
    "* The scripts and notebooks that accompany the paper ([link](https://github.com/huggingface/transformers/tree/master/examples/research_projects/movement-pruning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformerlab.question_answering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.1 1.2.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "datasets.logging.set_verbosity_error()\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "print(transformers.__version__, datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, default_data_collator, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init, CrossEntropyLoss\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix seed for sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\")\n",
    "squad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fine-pruned model\n",
    "\n",
    "HuggingFace has released a PruneBERT checkpoint for SQuAD v1.1 called `prunebert-base-uncased-6-finepruned-w-distil-squad` which is described in their docs as follows:\n",
    "\n",
    "> Pre-trained BERT-base-uncased fine-pruned with soft movement pruning on SQuAD v1.1. We use an additional distillation signal from `BERT-base-uncased` finetuned on SQuAD. The encoder counts 6% of total non-null weights and reaches 83.8 F1 score. The model can be accessed with: `pruned_bert = BertForQuestionAnswering.from_pretrained(\"huggingface/prunebert-base-uncased-6-finepruned-w-distil-squad\")`\n",
    "\n",
    "In this notebook we'll focus on reproducing this model, so let's begin by simply validating that we can obtain the same F1-score. Before doing that, we first need to preprocess the data - let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(dataset, tokenizer):\n",
    "    max_length = 384 \n",
    "    doc_stride = 128 \n",
    "    pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "    fn_kwargs = {\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"max_length\": max_length,\n",
    "        \"doc_stride\": doc_stride,\n",
    "        \"pad_on_right\": pad_on_right\n",
    "    }\n",
    "    \n",
    "    train_enc = dataset['train'].map(prepare_train_features, fn_kwargs=fn_kwargs, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "    valid_enc = dataset['validation'].map(prepare_validation_features, fn_kwargs=fn_kwargs, batched=True, remove_columns=dataset[\"validation\"].column_names)\n",
    "\n",
    "    return train_enc, valid_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_model_name = \"huggingface/prunebert-base-uncased-6-finepruned-w-distil-squad\"\n",
    "# pruned_tokenizer = AutoTokenizer.from_pretrained(pruned_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_enc, valid_enc = convert_examples_to_features(squad, pruned_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is preprocessed, let's instantiate a custom trainer and evaluate the model on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_model = AutoModelForQuestionAnswering.from_pretrained(pruned_model_name).to(device)\n",
    "# batch_size = 8\n",
    "\n",
    "# eval_ds = valid_enc\n",
    "# eval_raw_ds = squad[\"validation\"]\n",
    "\n",
    "# pruned_args = QuestionAnsweringTrainingArguments(\n",
    "#     output_dir=\"checkpoints\",\n",
    "#     per_device_eval_batch_size=batch_size)\n",
    "\n",
    "# data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_trainer = QuestionAnsweringTrainer(\n",
    "#     model=pruned_model,\n",
    "#     args=pruned_args,\n",
    "#     eval_dataset=eval_ds,\n",
    "#     eval_examples=eval_raw_ds,\n",
    "#     tokenizer=pruned_tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=squad_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great - we get an F1-score that matches the value quoted by HuggingFace!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune-tuning without distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc, valid_enc = convert_examples_to_features(squad, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create masked variants of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.configuration_utils import PretrainedConfig\n",
    "\n",
    "class MaskedBertConfig(PretrainedConfig):\n",
    "    \"\"\"\n",
    "    A class replicating the `~transformers.BertConfig` with additional parameters for pruning/masking configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    model_type = \"masked_bert\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=30522,\n",
    "        hidden_size=768,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=12,\n",
    "        intermediate_size=3072,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=512,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        pad_token_id=0,\n",
    "        pruning_method=\"topK\",\n",
    "        mask_init=\"constant\",\n",
    "        mask_scale=0.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(pad_token_id=pad_token_id, **kwargs)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.pruning_method = pruning_method\n",
    "        self.mask_init = mask_init\n",
    "        self.mask_scale = mask_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.models.bert.modeling_bert import load_tf_weights_in_bert, ACT2FN\n",
    "\n",
    "class MaskedBertPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\"An abstract class to handle weights initialization and\n",
    "    a simple interface for downloading and loading pretrained models.\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = MaskedBertConfig\n",
    "    load_tf_weights = load_tf_weights_in_bert\n",
    "    base_model_prefix = \"bert\"\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            # HACK: replace BertLayerNorm with LayerNorm\n",
    "        elif isinstance(module, torch.nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedBertModel(MaskedBertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    The `MaskedBertModel` class replicates the :class:`~transformers.BertModel` class\n",
    "    and adds specific inputs to compute the adaptive mask on the fly.\n",
    "    Note that we freeze the embeddings modules from their pre-trained values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.embeddings.requires_grad_(requires_grad=False)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"Prunes heads of the model.\n",
    "        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n",
    "        See base class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_shape, device=device)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        if attention_mask.dim() == 3:\n",
    "            extended_attention_mask = attention_mask[:, None, :, :]\n",
    "        elif attention_mask.dim() == 2:\n",
    "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
    "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
    "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "            if self.config.is_decoder:\n",
    "                batch_size, seq_length = input_shape\n",
    "                seq_ids = torch.arange(seq_length, device=device)\n",
    "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
    "                causal_mask = causal_mask.to(\n",
    "                    attention_mask.dtype\n",
    "                )  # causal and attention masks must have same type with pytorch version < 1.3\n",
    "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
    "            else:\n",
    "                extended_attention_mask = attention_mask[:, None, None, :]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
    "                    input_shape, attention_mask.shape\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        # If a 2D ou 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "\n",
    "            if encoder_attention_mask.dim() == 3:\n",
    "                encoder_extended_attention_mask = encoder_attention_mask[:, None, :, :]\n",
    "            elif encoder_attention_mask.dim() == 2:\n",
    "                encoder_extended_attention_mask = encoder_attention_mask[:, None, None, :]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\".format(\n",
    "                        encoder_hidden_shape, encoder_attention_mask.shape\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            encoder_extended_attention_mask = encoder_extended_attention_mask.to(\n",
    "                dtype=next(self.parameters()).dtype\n",
    "            )  # fp16 compatibility\n",
    "            encoder_extended_attention_mask = (1.0 - encoder_extended_attention_mask) * -10000.0\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        if head_mask is not None:\n",
    "            if head_mask.dim() == 1:\n",
    "                head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "                head_mask = head_mask.expand(self.config.num_hidden_layers, -1, -1, -1, -1)\n",
    "            elif head_mask.dim() == 2:\n",
    "                head_mask = (\n",
    "                    head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)\n",
    "                )  # We can specify head_mask for each layer\n",
    "            head_mask = head_mask.to(\n",
    "                dtype=next(self.parameters()).dtype\n",
    "            )  # switch to float if need + fp16 compatibility\n",
    "        else:\n",
    "            head_mask = [None] * self.config.num_hidden_layers\n",
    "\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "\n",
    "        outputs = (sequence_output, pooled_output,) + encoder_outputs[\n",
    "            1:\n",
    "        ]  # add hidden_states and attentions if they are here\n",
    "        return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "#         self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None):\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand(input_shape)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = inputs_embeds + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.output_attentions = config.output_attentions\n",
    "        self.output_hidden_states = config.output_hidden_states\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if self.output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(\n",
    "                hidden_states,\n",
    "                attention_mask,\n",
    "                head_mask[i],\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "                threshold=threshold,\n",
    "            )\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            if self.output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[1],)\n",
    "\n",
    "        # Add last layer\n",
    "        if self.output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if self.output_hidden_states:\n",
    "            outputs = outputs + (all_hidden_states,)\n",
    "        if self.output_attentions:\n",
    "            outputs = outputs + (all_attentions,)\n",
    "        return outputs  # last-layer hidden state, (all hidden states), (all attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedBertForQuestionAnswering(MaskedBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = MaskedBertModel(config)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        start_positions=None,\n",
    "        end_positions=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        outputs = (\n",
    "            start_logits,\n",
    "            end_logits,\n",
    "        ) + outputs[2:]\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions.clamp_(0, ignored_index)\n",
    "            end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            outputs = (total_loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), start_logits, end_logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        if self.is_decoder:\n",
    "            self.crossattention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "        self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask, threshold=threshold)\n",
    "        attention_output = self_attention_outputs[0]\n",
    "        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:]  # add cross attentions if we output attention weights\n",
    "\n",
    "        intermediate_output = self.intermediate(attention_output, threshold=threshold)\n",
    "        layer_output = self.output(intermediate_output, attention_output, threshold=threshold)\n",
    "        outputs = (layer_output,) + outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        mask = torch.ones(self.self.num_attention_heads, self.self.attention_head_size)\n",
    "        heads = set(heads) - self.pruned_heads  # Convert to set and remove already pruned heads\n",
    "        for head in heads:\n",
    "            # Compute how many pruned heads are before the head and move the index accordingly\n",
    "            head = head - sum(1 if h < head else 0 for h in self.pruned_heads)\n",
    "            mask[head] = 0\n",
    "        mask = mask.view(-1).contiguous().eq(1)\n",
    "        index = torch.arange(len(mask))[mask].long()\n",
    "\n",
    "        # Prune linear layers\n",
    "        self.self.query = prune_linear_layer(self.self.query, index)\n",
    "        self.self.key = prune_linear_layer(self.self.key, index)\n",
    "        self.self.value = prune_linear_layer(self.self.value, index)\n",
    "        self.output.dense = prune_linear_layer(self.output.dense, index, dim=1)\n",
    "\n",
    "        # Update hyper params and store pruned heads\n",
    "        self.self.num_attention_heads = self.self.num_attention_heads - len(heads)\n",
    "        self.self.all_head_size = self.self.attention_head_size * self.self.num_attention_heads\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "        self_outputs = self.self(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "        attention_output = self.output(self_outputs[0], hidden_states, threshold=threshold)\n",
    "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n",
    "            )\n",
    "        self.output_attentions = config.output_attentions\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            self.all_head_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        self.key = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            self.all_head_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        self.value = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            self.all_head_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        threshold=None,\n",
    "    ):\n",
    "        mixed_query_layer = self.query(hidden_states, threshold=threshold)\n",
    "\n",
    "        # If this is instantiated as a cross-attention module, the keys\n",
    "        # and values come from an encoder; the attention mask needs to be\n",
    "        # such that the encoder's padding tokens are not attended to.\n",
    "        if encoder_hidden_states is not None:\n",
    "            mixed_key_layer = self.key(encoder_hidden_states, threshold=threshold)\n",
    "            mixed_value_layer = self.value(encoder_hidden_states, threshold=threshold)\n",
    "            attention_mask = encoder_attention_mask\n",
    "        else:\n",
    "            mixed_key_layer = self.key(hidden_states, threshold=threshold)\n",
    "            mixed_value_layer = self.value(hidden_states, threshold=threshold)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if self.output_attentions else (context_layer,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Linear):\n",
    "    \"\"\"\n",
    "    Fully Connected layer with on the fly adaptive mask.\n",
    "    If needed, a score matrix is created to store the importance of each associated weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        bias: bool = True,\n",
    "        mask_init: str = \"constant\",\n",
    "        mask_scale: float = 0.0,\n",
    "        pruning_method: str = \"topK\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_features (`int`)\n",
    "                Size of each input sample\n",
    "            out_features (`int`)\n",
    "                Size of each output sample\n",
    "            bias (`bool`)\n",
    "                If set to ``False``, the layer will not learn an additive bias.\n",
    "                Default: ``True``\n",
    "            mask_init (`str`)\n",
    "                The initialization method for the score matrix if a score matrix is needed.\n",
    "                Choices: [\"constant\", \"uniform\", \"kaiming\"]\n",
    "                Default: ``constant``\n",
    "            mask_scale (`float`)\n",
    "                The initialization parameter for the chosen initialization method `mask_init`.\n",
    "                Default: ``0.``\n",
    "            pruning_method (`str`)\n",
    "                Method to compute the mask.\n",
    "                Choices: [\"topK\", \"threshold\", \"sigmoied_threshold\", \"magnitude\", \"l0\"]\n",
    "                Default: ``topK``\n",
    "        \"\"\"\n",
    "        super(MaskedLinear, self).__init__(in_features=in_features, out_features=out_features, bias=bias)\n",
    "        assert pruning_method in [\"topK\", \"threshold\", \"sigmoied_threshold\", \"magnitude\", \"l0\"]\n",
    "        self.pruning_method = pruning_method\n",
    "\n",
    "        if self.pruning_method in [\"topK\", \"threshold\", \"sigmoied_threshold\", \"l0\"]:\n",
    "            self.mask_scale = mask_scale\n",
    "            self.mask_init = mask_init\n",
    "            self.mask_scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
    "            self.init_mask()\n",
    "\n",
    "    def init_mask(self):\n",
    "        if self.mask_init == \"constant\":\n",
    "            init.constant_(self.mask_scores, val=self.mask_scale)\n",
    "        elif self.mask_init == \"uniform\":\n",
    "            init.uniform_(self.mask_scores, a=-self.mask_scale, b=self.mask_scale)\n",
    "        elif self.mask_init == \"kaiming\":\n",
    "            init.kaiming_uniform_(self.mask_scores, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, input: torch.tensor, threshold: float):\n",
    "        # Get the mask\n",
    "        if self.pruning_method == \"topK\":\n",
    "            mask = TopKBinarizer.apply(self.mask_scores, threshold)\n",
    "        elif self.pruning_method in [\"threshold\", \"sigmoied_threshold\"]:\n",
    "            sig = \"sigmoied\" in self.pruning_method\n",
    "            mask = ThresholdBinarizer.apply(self.mask_scores, threshold, sig)\n",
    "        elif self.pruning_method == \"magnitude\":\n",
    "            mask = MagnitudeBinarizer.apply(self.weight, threshold)\n",
    "        elif self.pruning_method == \"l0\":\n",
    "            l, r, b = -0.1, 1.1, 2 / 3\n",
    "            if self.training:\n",
    "                u = torch.zeros_like(self.mask_scores).uniform_().clamp(0.0001, 0.9999)\n",
    "                s = torch.sigmoid((u.log() - (1 - u).log() + self.mask_scores) / b)\n",
    "            else:\n",
    "                s = torch.sigmoid(self.mask_scores)\n",
    "            s_bar = s * (r - l) + l\n",
    "            mask = s_bar.clamp(min=0.0, max=1.0)\n",
    "        # Mask weights with computed mask\n",
    "        weight_thresholded = mask * self.weight\n",
    "        # Compute output (linear layer) with masked weights\n",
    "        return F.linear(input, weight_thresholded, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            config.hidden_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "#         self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor, threshold):\n",
    "        hidden_states = self.dense(hidden_states, threshold=threshold)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = MaskedLinear(\n",
    "            config.hidden_size,\n",
    "            config.intermediate_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states, threshold):\n",
    "        hidden_states = self.dense(hidden_states, threshold=threshold)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = MaskedLinear(\n",
    "            config.intermediate_size,\n",
    "            config.hidden_size,\n",
    "            pruning_method=config.pruning_method,\n",
    "            mask_init=config.mask_init,\n",
    "            mask_scale=config.mask_scale,\n",
    "        )\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "#         self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor, threshold):\n",
    "        hidden_states = self.dense(hidden_states, threshold=threshold)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKBinarizer(autograd.Function):\n",
    "    \"\"\"\n",
    "    Top-k Binarizer.\n",
    "    Computes a binary mask M from a real value matrix S such that `M_{i,j} = 1` if and only if `S_{i,j}`\n",
    "    is among the k% highest values of S.\n",
    "\n",
    "    Implementation is inspired from:\n",
    "        https://github.com/allenai/hidden-networks\n",
    "        What's hidden in a randomly weighted neural network?\n",
    "        Vivek Ramanujan*, Mitchell Wortsman*, Aniruddha Kembhavi, Ali Farhadi, Mohammad Rastegari\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs: torch.tensor, threshold: float):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (`torch.FloatTensor`)\n",
    "                The input matrix from which the binarizer computes the binary mask.\n",
    "            threshold (`float`)\n",
    "                The percentage of weights to keep (the rest is pruned).\n",
    "                `threshold` is a float between 0 and 1.\n",
    "        Returns:\n",
    "            mask (`torch.FloatTensor`)\n",
    "                Binary matrix of the same size as `inputs` acting as a mask (1 - the associated weight is\n",
    "                retained, 0 - the associated weight is pruned).\n",
    "        \"\"\"\n",
    "        # Get the subnetwork by sorting the inputs and using the top threshold %\n",
    "        if not isinstance(threshold, float):\n",
    "            threshold = threshold[0]\n",
    "        mask = inputs.clone()\n",
    "        _, idx = inputs.flatten().sort(descending=True)\n",
    "        j = int(threshold * inputs.numel())\n",
    "\n",
    "        # flat_out and mask access the same memory.\n",
    "        flat_out = mask.flatten()\n",
    "        flat_out[idx[j:]] = 0\n",
    "        flat_out[idx[:j]] = 1\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, gradOutput):\n",
    "        return gradOutput, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainingArguments(QuestionAnsweringTrainingArguments):\n",
    "    def __init__(self, *args, initial_threshold=1., final_threshold=0.1, initial_warmup=1, final_warmup=2, final_lambda=0.,\n",
    "                 mask_scores_learning_rate=1e-2, **kwargs): \n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.initial_threshold = initial_threshold\n",
    "        self.final_threshold = final_threshold\n",
    "        self.initial_warmup = initial_warmup\n",
    "        self.final_warmup = final_warmup\n",
    "        self.final_lambda = final_lambda\n",
    "        self.mask_scores_learning_rate = mask_scores_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer(QuestionAnsweringTrainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        if self.args.max_steps > 0:\n",
    "            self.t_total = self.args.max_steps\n",
    "            self.args.num_train_epochs = self.args.max_steps // (len(self.train_dataset) // self.args.gradient_accumulation_steps) + 1\n",
    "        else:\n",
    "            self.t_total = len(self.get_train_dataloader()) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
    "            \n",
    "#     def get_train_dataloader(self) -> DataLoader:\n",
    "#         \"\"\"\n",
    "#         Returns the training :class:`~torch.utils.data.DataLoader`.\n",
    "\n",
    "#         Will use no sampler if :obj:`self.train_dataset` does not implement :obj:`__len__`, a random sampler (adapted\n",
    "#         to distributed training if necessary) otherwise.\n",
    "\n",
    "#         Subclass and override this method if you want to inject some custom behavior.\n",
    "#         \"\"\"\n",
    "#         if self.train_dataset is None:\n",
    "#             raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "#         train_sampler = SequentialSampler(self.train_dataset)\n",
    "\n",
    "#         return DataLoader(\n",
    "#             self.train_dataset,\n",
    "#             batch_size=self.args.train_batch_size,\n",
    "#             sampler=train_sampler,\n",
    "#             collate_fn=self.data_collator,\n",
    "#             drop_last=self.args.dataloader_drop_last,\n",
    "# #             num_workers=self.args.dataloader_num_workers,\n",
    "#         )\n",
    "        \n",
    "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if \"mask_score\" in n and p.requires_grad],\n",
    "                \"lr\": self.args.mask_scores_learning_rate,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.model.named_parameters()\n",
    "                    if \"mask_score\" not in n and p.requires_grad and not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"lr\": self.args.learning_rate,\n",
    "                \"weight_decay\": self.args.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.model.named_parameters()\n",
    "                    if \"mask_score\" not in n and p.requires_grad and any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"lr\": self.args.learning_rate,\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
    "        self.lr_scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer, num_warmup_steps=self.args.warmup_steps, num_training_steps=self.t_total\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def compute_loss(self, model, inputs):\n",
    "            \n",
    "        threshold, regu_lambda = self._schedule_threshold(\n",
    "            step=self.state.global_step+1,\n",
    "            total_step=self.t_total,\n",
    "            warmup_steps=self.args.warmup_steps,\n",
    "            final_threshold=self.args.final_threshold,\n",
    "            initial_threshold=self.args.initial_threshold,\n",
    "            final_warmup=self.args.final_warmup,\n",
    "            initial_warmup=self.args.initial_warmup,\n",
    "            final_lambda=self.args.final_lambda,\n",
    "        )\n",
    "        inputs[\"threshold\"] = threshold  \n",
    "#         print(inputs)\n",
    "        outputs = model(**inputs)\n",
    "        # model outputs are always tuple in transformers (see doc)\n",
    "        loss, start_logits_stu, end_logits_stu = outputs\n",
    "        print(f\"Step: {self.state.global_step} | Threshold: {threshold} | Loss: {loss} | t_total: {self.t_total}\")\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def _schedule_threshold(\n",
    "        self,\n",
    "        step: int,\n",
    "        total_step: int,\n",
    "        warmup_steps: int,\n",
    "        initial_threshold: float,\n",
    "        final_threshold: float,\n",
    "        initial_warmup: int,\n",
    "        final_warmup: int,\n",
    "        final_lambda: float,\n",
    "    ):\n",
    "        if step <= initial_warmup * warmup_steps:\n",
    "            threshold = initial_threshold\n",
    "        elif step > (total_step - final_warmup * warmup_steps):\n",
    "            threshold = final_threshold\n",
    "        else:\n",
    "            spars_warmup_steps = initial_warmup * warmup_steps\n",
    "            spars_schedu_steps = (final_warmup + initial_warmup) * warmup_steps\n",
    "            mul_coeff = 1 - (step - spars_warmup_steps) / (total_step - spars_schedu_steps)\n",
    "            threshold = final_threshold + (initial_threshold - final_threshold) * (mul_coeff ** 3)\n",
    "        regu_lambda = final_lambda * threshold / final_threshold\n",
    "        return threshold, regu_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 160\n",
      "Number of validation examples: 20\n",
      "Number of raw validation examples: 20\n",
      "Number of warmup steps: 6\n"
     ]
    }
   ],
   "source": [
    "masked_config = MaskedBertConfig(pruning_method='topK', mask_init='constant', mask_scale=0.)\n",
    "masked_model = MaskedBertForQuestionAnswering.from_pretrained('bert-base-uncased', config=masked_config).to(device)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_train_examples = 160\n",
    "num_eval_examples = 20\n",
    "\n",
    "train_ds = train_enc.select(range(num_train_examples))\n",
    "eval_ds = valid_enc.select(range(num_eval_examples))\n",
    "eval_raw_ds = squad[\"validation\"].select(range(num_eval_examples))\n",
    "warmup_steps = 6\n",
    "max_steps = 100\n",
    "num_train_epochs=10\n",
    "\n",
    "print(f\"Number of training examples: {train_ds.num_rows}\")\n",
    "print(f\"Number of validation examples: {eval_ds.num_rows}\")\n",
    "print(f\"Number of raw validation examples: {eval_raw_ds.num_rows}\")\n",
    "\n",
    "logging_steps = len(train_ds) // batch_size\n",
    "\n",
    "print(f\"Number of warmup steps: {warmup_steps}\")\n",
    "\n",
    "pruning_training_args = PruningTrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "#     max_steps=max_steps,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=0.0,\n",
    "    logging_steps=logging_steps,\n",
    "    disable_tqdm=False,\n",
    "    warmup_steps=warmup_steps,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = eval_ds.map(lambda x : {'threshold': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_trainer = PruningTrainer(\n",
    "    model=masked_model,\n",
    "    args=pruning_training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    eval_examples=eval_raw_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=squad_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruning_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | Threshold: 1.0 | Loss: 5.989073753356934 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 03:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.845221</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.383459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.990707</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.959200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.954142</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.964359</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.957894</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.702786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.959497</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.940603</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.957425</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.091374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.954855</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.063492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 | Threshold: 1.0 | Loss: 5.893919944763184 | t_total: 200\n",
      "Step: 2 | Threshold: 1.0 | Loss: 5.9488115310668945 | t_total: 200\n",
      "Step: 3 | Threshold: 1.0 | Loss: 5.98604679107666 | t_total: 200\n",
      "Step: 4 | Threshold: 1.0 | Loss: 5.863607883453369 | t_total: 200\n",
      "Step: 5 | Threshold: 1.0 | Loss: 5.869380950927734 | t_total: 200\n",
      "Step: 6 | Threshold: 0.9852461977703495 | Loss: 5.623629570007324 | t_total: 200\n",
      "Step: 7 | Threshold: 0.9706545235949898 | Loss: 5.372407913208008 | t_total: 200\n",
      "Step: 8 | Threshold: 0.9562240817388141 | Loss: 5.281087398529053 | t_total: 200\n",
      "Step: 9 | Threshold: 0.9419539764667164 | Loss: 5.054854393005371 | t_total: 200\n",
      "Step: 10 | Threshold: 0.9278433120435897 | Loss: 6.036581039428711 | t_total: 200\n",
      "Step: 11 | Threshold: 0.9138911927343276 | Loss: 6.019186973571777 | t_total: 200\n",
      "Step: 12 | Threshold: 0.9000967228038235 | Loss: 5.940598487854004 | t_total: 200\n",
      "Step: 13 | Threshold: 0.8864590065169706 | Loss: 5.9573073387146 | t_total: 200\n",
      "Step: 14 | Threshold: 0.8729771481386623 | Loss: 5.967960357666016 | t_total: 200\n",
      "Step: 15 | Threshold: 0.8596502519337925 | Loss: 6.043519496917725 | t_total: 200\n",
      "Step: 16 | Threshold: 0.8464774221672543 | Loss: 5.992321968078613 | t_total: 200\n",
      "Step: 17 | Threshold: 0.8334577631039412 | Loss: 6.140920162200928 | t_total: 200\n",
      "Step: 18 | Threshold: 0.8205903790087464 | Loss: 5.976899147033691 | t_total: 200\n",
      "Step: 19 | Threshold: 0.8078743741465636 | Loss: 5.9462995529174805 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba9cf696d73419181386fb96cd56ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 20 | Threshold: 0.7953088527822858 | Loss: 6.08903694152832 | t_total: 200\n",
      "Step: 21 | Threshold: 0.7828929191808071 | Loss: 5.997733116149902 | t_total: 200\n",
      "Step: 22 | Threshold: 0.7706256776070204 | Loss: 6.2273664474487305 | t_total: 200\n",
      "Step: 23 | Threshold: 0.7585062323258194 | Loss: 5.976736068725586 | t_total: 200\n",
      "Step: 24 | Threshold: 0.7465336876020973 | Loss: 6.014189720153809 | t_total: 200\n",
      "Step: 25 | Threshold: 0.7347071477007473 | Loss: 5.955245494842529 | t_total: 200\n",
      "Step: 26 | Threshold: 0.7230257168866635 | Loss: 5.984169006347656 | t_total: 200\n",
      "Step: 27 | Threshold: 0.7114884994247389 | Loss: 5.970478534698486 | t_total: 200\n",
      "Step: 28 | Threshold: 0.7000945995798671 | Loss: 5.956234931945801 | t_total: 200\n",
      "Step: 29 | Threshold: 0.6888431216169413 | Loss: 5.966883182525635 | t_total: 200\n",
      "Step: 30 | Threshold: 0.677733169800855 | Loss: 6.008230209350586 | t_total: 200\n",
      "Step: 31 | Threshold: 0.6667638483965016 | Loss: 5.891583442687988 | t_total: 200\n",
      "Step: 32 | Threshold: 0.6559342616687744 | Loss: 5.972797393798828 | t_total: 200\n",
      "Step: 33 | Threshold: 0.6452435138825672 | Loss: 5.98258638381958 | t_total: 200\n",
      "Step: 34 | Threshold: 0.634690709302773 | Loss: 5.976987838745117 | t_total: 200\n",
      "Step: 35 | Threshold: 0.6242749521942856 | Loss: 5.967738151550293 | t_total: 200\n",
      "Step: 36 | Threshold: 0.6139953468219981 | Loss: 5.981882095336914 | t_total: 200\n",
      "Step: 37 | Threshold: 0.6038509974508041 | Loss: 5.932724952697754 | t_total: 200\n",
      "Step: 38 | Threshold: 0.5938410083455972 | Loss: 5.993355751037598 | t_total: 200\n",
      "Step: 39 | Threshold: 0.5839644837712704 | Loss: 5.968194961547852 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d469d8d0ae184915bca685022c1cf725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 40 | Threshold: 0.5742205279927174 | Loss: 6.029837608337402 | t_total: 200\n",
      "Step: 41 | Threshold: 0.5646082452748316 | Loss: 5.945032596588135 | t_total: 200\n",
      "Step: 42 | Threshold: 0.5551267398825062 | Loss: 5.928070068359375 | t_total: 200\n",
      "Step: 43 | Threshold: 0.5457751160806347 | Loss: 5.924349784851074 | t_total: 200\n",
      "Step: 44 | Threshold: 0.5365524781341108 | Loss: 5.952756881713867 | t_total: 200\n",
      "Step: 45 | Threshold: 0.5274579303078277 | Loss: 6.009023666381836 | t_total: 200\n",
      "Step: 46 | Threshold: 0.5184905768666789 | Loss: 5.953790187835693 | t_total: 200\n",
      "Step: 47 | Threshold: 0.5096495220755575 | Loss: 5.969111442565918 | t_total: 200\n",
      "Step: 48 | Threshold: 0.5009338701993574 | Loss: 5.95670747756958 | t_total: 200\n",
      "Step: 49 | Threshold: 0.49234272550297187 | Loss: 5.937241554260254 | t_total: 200\n",
      "Step: 50 | Threshold: 0.48387519225129416 | Loss: 5.956970691680908 | t_total: 200\n",
      "Step: 51 | Threshold: 0.4755303747092179 | Loss: 5.897049427032471 | t_total: 200\n",
      "Step: 52 | Threshold: 0.4673073771416364 | Loss: 6.020175933837891 | t_total: 200\n",
      "Step: 53 | Threshold: 0.45920530381344304 | Loss: 5.974974155426025 | t_total: 200\n",
      "Step: 54 | Threshold: 0.4512232589895313 | Loss: 5.941563129425049 | t_total: 200\n",
      "Step: 55 | Threshold: 0.4433603469347944 | Loss: 5.973285675048828 | t_total: 200\n",
      "Step: 56 | Threshold: 0.4356156719141262 | Loss: 5.947533130645752 | t_total: 200\n",
      "Step: 57 | Threshold: 0.4279883381924199 | Loss: 5.977324485778809 | t_total: 200\n",
      "Step: 58 | Threshold: 0.4204774500345687 | Loss: 5.936073303222656 | t_total: 200\n",
      "Step: 59 | Threshold: 0.41308211170546627 | Loss: 5.953125476837158 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca86a001495641a6bbe879d1bb4e78b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 60 | Threshold: 0.40580142747000614 | Loss: 5.967108726501465 | t_total: 200\n",
      "Step: 61 | Threshold: 0.39863450159308145 | Loss: 6.0039567947387695 | t_total: 200\n",
      "Step: 62 | Threshold: 0.3915804383395858 | Loss: 5.914857864379883 | t_total: 200\n",
      "Step: 63 | Threshold: 0.3846383419744125 | Loss: 5.953590393066406 | t_total: 200\n",
      "Step: 64 | Threshold: 0.37780731676245516 | Loss: 5.911615371704102 | t_total: 200\n",
      "Step: 65 | Threshold: 0.3710864669686069 | Loss: 5.941280364990234 | t_total: 200\n",
      "Step: 66 | Threshold: 0.36447489685776135 | Loss: 5.941457748413086 | t_total: 200\n",
      "Step: 67 | Threshold: 0.3579717106948118 | Loss: 5.974471092224121 | t_total: 200\n",
      "Step: 68 | Threshold: 0.3515760127446519 | Loss: 5.998353004455566 | t_total: 200\n",
      "Step: 69 | Threshold: 0.34528690727217465 | Loss: 5.952250003814697 | t_total: 200\n",
      "Step: 70 | Threshold: 0.33910349854227395 | Loss: 5.961615085601807 | t_total: 200\n",
      "Step: 71 | Threshold: 0.3330248908198431 | Loss: 5.93968391418457 | t_total: 200\n",
      "Step: 72 | Threshold: 0.3270501883697754 | Loss: 5.92387056350708 | t_total: 200\n",
      "Step: 73 | Threshold: 0.32117849545696425 | Loss: 5.967021465301514 | t_total: 200\n",
      "Step: 74 | Threshold: 0.3154089163463032 | Loss: 5.900094032287598 | t_total: 200\n",
      "Step: 75 | Threshold: 0.3097405553026855 | Loss: 5.952943801879883 | t_total: 200\n",
      "Step: 76 | Threshold: 0.30417251659100475 | Loss: 5.93998908996582 | t_total: 200\n",
      "Step: 77 | Threshold: 0.2987039044761543 | Loss: 5.943734645843506 | t_total: 200\n",
      "Step: 78 | Threshold: 0.29333382322302737 | Loss: 6.010729789733887 | t_total: 200\n",
      "Step: 79 | Threshold: 0.2880613770965178 | Loss: 5.984235763549805 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9e0c6e8b2d488cbbc32f184e45d490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 80 | Threshold: 0.28288567036151874 | Loss: 5.952125549316406 | t_total: 200\n",
      "Step: 81 | Threshold: 0.2778058072829235 | Loss: 5.956075668334961 | t_total: 200\n",
      "Step: 82 | Threshold: 0.2728208921256258 | Loss: 6.00127649307251 | t_total: 200\n",
      "Step: 83 | Threshold: 0.2679300291545189 | Loss: 5.961522102355957 | t_total: 200\n",
      "Step: 84 | Threshold: 0.26313232263449626 | Loss: 5.887432098388672 | t_total: 200\n",
      "Step: 85 | Threshold: 0.2584268768304513 | Loss: 5.955479145050049 | t_total: 200\n",
      "Step: 86 | Threshold: 0.25381279600727735 | Loss: 5.992793083190918 | t_total: 200\n",
      "Step: 87 | Threshold: 0.24928918442986797 | Loss: 5.972589492797852 | t_total: 200\n",
      "Step: 88 | Threshold: 0.24485514636311648 | Loss: 5.986364841461182 | t_total: 200\n",
      "Step: 89 | Threshold: 0.24050978607191623 | Loss: 5.969649314880371 | t_total: 200\n",
      "Step: 90 | Threshold: 0.23625220782116085 | Loss: 5.953175067901611 | t_total: 200\n",
      "Step: 91 | Threshold: 0.23208151587574363 | Loss: 5.970466613769531 | t_total: 200\n",
      "Step: 92 | Threshold: 0.22799681450055795 | Loss: 6.011743545532227 | t_total: 200\n",
      "Step: 93 | Threshold: 0.22399720796049738 | Loss: 5.993350982666016 | t_total: 200\n",
      "Step: 94 | Threshold: 0.22008180052045526 | Loss: 5.990438461303711 | t_total: 200\n",
      "Step: 95 | Threshold: 0.216249696445325 | Loss: 5.978941917419434 | t_total: 200\n",
      "Step: 96 | Threshold: 0.21250000000000002 | Loss: 5.9181623458862305 | t_total: 200\n",
      "Step: 97 | Threshold: 0.20883181544937374 | Loss: 5.973453521728516 | t_total: 200\n",
      "Step: 98 | Threshold: 0.2052442470583396 | Loss: 5.895663261413574 | t_total: 200\n",
      "Step: 99 | Threshold: 0.20173639909179092 | Loss: 5.966483116149902 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626fbe091515415c9ff3e78d4c31c4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 100 | Threshold: 0.1983073758146213 | Loss: 5.97183895111084 | t_total: 200\n",
      "Step: 101 | Threshold: 0.19495628149172406 | Loss: 5.965817451477051 | t_total: 200\n",
      "Step: 102 | Threshold: 0.19168222038799265 | Loss: 5.938935279846191 | t_total: 200\n",
      "Step: 103 | Threshold: 0.18848429676832046 | Loss: 5.958086013793945 | t_total: 200\n",
      "Step: 104 | Threshold: 0.18536161489760092 | Loss: 5.9330363273620605 | t_total: 200\n",
      "Step: 105 | Threshold: 0.18231327904072742 | Loss: 6.009718894958496 | t_total: 200\n",
      "Step: 106 | Threshold: 0.17933839346259342 | Loss: 6.016504287719727 | t_total: 200\n",
      "Step: 107 | Threshold: 0.17643606242809237 | Loss: 5.903928756713867 | t_total: 200\n",
      "Step: 108 | Threshold: 0.17360539020211768 | Loss: 5.987347602844238 | t_total: 200\n",
      "Step: 109 | Threshold: 0.1708454810495627 | Loss: 5.91176700592041 | t_total: 200\n",
      "Step: 110 | Threshold: 0.16815543923532095 | Loss: 5.964362621307373 | t_total: 200\n",
      "Step: 111 | Threshold: 0.1655343690242857 | Loss: 5.93583869934082 | t_total: 200\n",
      "Step: 112 | Threshold: 0.16298137468135052 | Loss: 5.979209899902344 | t_total: 200\n",
      "Step: 113 | Threshold: 0.1604955604714088 | Loss: 5.960054874420166 | t_total: 200\n",
      "Step: 114 | Threshold: 0.15807603065935394 | Loss: 5.977814674377441 | t_total: 200\n",
      "Step: 115 | Threshold: 0.15572188951007937 | Loss: 5.943368911743164 | t_total: 200\n",
      "Step: 116 | Threshold: 0.15343224128847843 | Loss: 5.946555137634277 | t_total: 200\n",
      "Step: 117 | Threshold: 0.1512061902594447 | Loss: 5.904200553894043 | t_total: 200\n",
      "Step: 118 | Threshold: 0.1490428406878715 | Loss: 5.98307991027832 | t_total: 200\n",
      "Step: 119 | Threshold: 0.14694129683865223 | Loss: 5.96642541885376 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e5624f3f3644e0990ff40d475112b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 120 | Threshold: 0.1449006629766804 | Loss: 5.95989990234375 | t_total: 200\n",
      "Step: 121 | Threshold: 0.14292004336684933 | Loss: 5.9453935623168945 | t_total: 200\n",
      "Step: 122 | Threshold: 0.14099854227405248 | Loss: 5.95749568939209 | t_total: 200\n",
      "Step: 123 | Threshold: 0.1391352639631833 | Loss: 5.937592506408691 | t_total: 200\n",
      "Step: 124 | Threshold: 0.13732931269913518 | Loss: 5.97677755355835 | t_total: 200\n",
      "Step: 125 | Threshold: 0.13557979274680157 | Loss: 5.976527214050293 | t_total: 200\n",
      "Step: 126 | Threshold: 0.13388580837107586 | Loss: 5.95491361618042 | t_total: 200\n",
      "Step: 127 | Threshold: 0.13224646383685149 | Loss: 5.97629451751709 | t_total: 200\n",
      "Step: 128 | Threshold: 0.13066086340902183 | Loss: 5.968482971191406 | t_total: 200\n",
      "Step: 129 | Threshold: 0.1291281113524804 | Loss: 5.9564924240112305 | t_total: 200\n",
      "Step: 130 | Threshold: 0.12764731193212053 | Loss: 5.9574432373046875 | t_total: 200\n",
      "Step: 131 | Threshold: 0.12621756941283568 | Loss: 5.980905532836914 | t_total: 200\n",
      "Step: 132 | Threshold: 0.12483798805951929 | Loss: 5.993197441101074 | t_total: 200\n",
      "Step: 133 | Threshold: 0.12350767213706472 | Loss: 5.922572135925293 | t_total: 200\n",
      "Step: 134 | Threshold: 0.12222572591036544 | Loss: 5.920577049255371 | t_total: 200\n",
      "Step: 135 | Threshold: 0.12099125364431487 | Loss: 5.990545749664307 | t_total: 200\n",
      "Step: 136 | Threshold: 0.11980335960380642 | Loss: 5.975105285644531 | t_total: 200\n",
      "Step: 137 | Threshold: 0.1186611480537335 | Loss: 5.917780876159668 | t_total: 200\n",
      "Step: 138 | Threshold: 0.11756372325898955 | Loss: 5.945605754852295 | t_total: 200\n",
      "Step: 139 | Threshold: 0.11651018948446795 | Loss: 5.9763593673706055 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fd42c28b7c4e849123b5a2d67399a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 140 | Threshold: 0.11549965099506218 | Loss: 5.962859153747559 | t_total: 200\n",
      "Step: 141 | Threshold: 0.11453121205566563 | Loss: 5.902565956115723 | t_total: 200\n",
      "Step: 142 | Threshold: 0.11360397693117172 | Loss: 5.969881057739258 | t_total: 200\n",
      "Step: 143 | Threshold: 0.11271704988647388 | Loss: 5.970367431640625 | t_total: 200\n",
      "Step: 144 | Threshold: 0.11186953518646553 | Loss: 5.9229207038879395 | t_total: 200\n",
      "Step: 145 | Threshold: 0.11106053709604005 | Loss: 5.92866325378418 | t_total: 200\n",
      "Step: 146 | Threshold: 0.11028915988009093 | Loss: 5.9737701416015625 | t_total: 200\n",
      "Step: 147 | Threshold: 0.10955450780351156 | Loss: 5.946454048156738 | t_total: 200\n",
      "Step: 148 | Threshold: 0.10885568513119534 | Loss: 5.909182548522949 | t_total: 200\n",
      "Step: 149 | Threshold: 0.10819179612803573 | Loss: 5.940603733062744 | t_total: 200\n",
      "Step: 150 | Threshold: 0.1075619450589261 | Loss: 5.964258193969727 | t_total: 200\n",
      "Step: 151 | Threshold: 0.10696523618875992 | Loss: 5.888424396514893 | t_total: 200\n",
      "Step: 152 | Threshold: 0.1064007737824306 | Loss: 5.949192047119141 | t_total: 200\n",
      "Step: 153 | Threshold: 0.10586766210483153 | Loss: 5.907597541809082 | t_total: 200\n",
      "Step: 154 | Threshold: 0.10536500542085617 | Loss: 5.960988998413086 | t_total: 200\n",
      "Step: 155 | Threshold: 0.10489190799539792 | Loss: 5.962159633636475 | t_total: 200\n",
      "Step: 156 | Threshold: 0.1044474740933502 | Loss: 5.921489715576172 | t_total: 200\n",
      "Step: 157 | Threshold: 0.10403080797960644 | Loss: 5.918297290802002 | t_total: 200\n",
      "Step: 158 | Threshold: 0.10364101391906005 | Loss: 5.956133842468262 | t_total: 200\n",
      "Step: 159 | Threshold: 0.10327719617660447 | Loss: 5.956250190734863 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f9dc98cbc9466f8a8fa7460cc93c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 160 | Threshold: 0.1029384590171331 | Loss: 5.951730728149414 | t_total: 200\n",
      "Step: 161 | Threshold: 0.10262390670553936 | Loss: 5.930002212524414 | t_total: 200\n",
      "Step: 162 | Threshold: 0.10233264350671668 | Loss: 5.9388837814331055 | t_total: 200\n",
      "Step: 163 | Threshold: 0.1020637736855585 | Loss: 5.963850498199463 | t_total: 200\n",
      "Step: 164 | Threshold: 0.10181640150695821 | Loss: 5.9934587478637695 | t_total: 200\n",
      "Step: 165 | Threshold: 0.10158963123580925 | Loss: 5.935539245605469 | t_total: 200\n",
      "Step: 166 | Threshold: 0.10138256713700501 | Loss: 5.936539649963379 | t_total: 200\n",
      "Step: 167 | Threshold: 0.10119431347543895 | Loss: 5.942351341247559 | t_total: 200\n",
      "Step: 168 | Threshold: 0.10102397451600446 | Loss: 5.9381232261657715 | t_total: 200\n",
      "Step: 169 | Threshold: 0.10087065452359499 | Loss: 6.017017364501953 | t_total: 200\n",
      "Step: 170 | Threshold: 0.10073345776310395 | Loss: 5.961722373962402 | t_total: 200\n",
      "Step: 171 | Threshold: 0.10061148849942475 | Loss: 5.973657608032227 | t_total: 200\n",
      "Step: 172 | Threshold: 0.10050385099745081 | Loss: 5.960209846496582 | t_total: 200\n",
      "Step: 173 | Threshold: 0.10040964952207557 | Loss: 5.926680564880371 | t_total: 200\n",
      "Step: 174 | Threshold: 0.10032798833819243 | Loss: 5.9714274406433105 | t_total: 200\n",
      "Step: 175 | Threshold: 0.10025797171069482 | Loss: 5.960730075836182 | t_total: 200\n",
      "Step: 176 | Threshold: 0.10019870390447616 | Loss: 5.984414100646973 | t_total: 200\n",
      "Step: 177 | Threshold: 0.10014928918442988 | Loss: 5.935725212097168 | t_total: 200\n",
      "Step: 178 | Threshold: 0.10010883181544938 | Loss: 5.966444969177246 | t_total: 200\n",
      "Step: 179 | Threshold: 0.1000764360624281 | Loss: 5.959996223449707 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bccb9fd5414f77ae49752fb9d465a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 180 | Threshold: 0.10005120619025945 | Loss: 5.95906925201416 | t_total: 200\n",
      "Step: 181 | Threshold: 0.10003224646383686 | Loss: 5.941567420959473 | t_total: 200\n",
      "Step: 182 | Threshold: 0.10001866114805374 | Loss: 5.9982686042785645 | t_total: 200\n",
      "Step: 183 | Threshold: 0.10000955450780352 | Loss: 5.975482940673828 | t_total: 200\n",
      "Step: 184 | Threshold: 0.10000403080797961 | Loss: 5.929422855377197 | t_total: 200\n",
      "Step: 185 | Threshold: 0.10000119431347544 | Loss: 5.914976119995117 | t_total: 200\n",
      "Step: 186 | Threshold: 0.10000014928918444 | Loss: 5.949907302856445 | t_total: 200\n",
      "Step: 187 | Threshold: 0.1 | Loss: 5.926374435424805 | t_total: 200\n",
      "Step: 188 | Threshold: 0.1 | Loss: 5.976995468139648 | t_total: 200\n",
      "Step: 189 | Threshold: 0.1 | Loss: 5.975089073181152 | t_total: 200\n",
      "Step: 190 | Threshold: 0.1 | Loss: 5.936020374298096 | t_total: 200\n",
      "Step: 191 | Threshold: 0.1 | Loss: 5.955297470092773 | t_total: 200\n",
      "Step: 192 | Threshold: 0.1 | Loss: 5.952559947967529 | t_total: 200\n",
      "Step: 193 | Threshold: 0.1 | Loss: 5.929218292236328 | t_total: 200\n",
      "Step: 194 | Threshold: 0.1 | Loss: 5.971963882446289 | t_total: 200\n",
      "Step: 195 | Threshold: 0.1 | Loss: 5.963028907775879 | t_total: 200\n",
      "Step: 196 | Threshold: 0.1 | Loss: 5.917259216308594 | t_total: 200\n",
      "Step: 197 | Threshold: 0.1 | Loss: 5.999217987060547 | t_total: 200\n",
      "Step: 198 | Threshold: 0.1 | Loss: 5.954061508178711 | t_total: 200\n",
      "Step: 199 | Threshold: 0.1 | Loss: 5.971308708190918 | t_total: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb23d5dc09f240d6b5e65cb69d9dc845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=5.948390426635743)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruning_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruning_trainer.t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
