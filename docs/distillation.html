---

title: Distilling Transformers for Question Answering


keywords: fastai
sidebar: home_sidebar

summary: "A partial reimplementation of DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf <a href='https://arxiv.org/abs/1910.01108'>[arXiv:1910.01108</a>]"
description: "A partial reimplementation of DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf <a href='https://arxiv.org/abs/1910.01108'>[arXiv:1910.01108</a>]"
nb_path: "02_distillation.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 02_distillation.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-libraries">Load libraries<a class="anchor-link" href="#Load-libraries"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">datasets</span>
<span class="kn">import</span> <span class="nn">transformers</span>

<span class="nb">print</span><span class="p">(</span><span class="n">transformers</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="n">datasets</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>4.1.1 1.2.0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">load_metric</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForQuestionAnswering</span><span class="p">,</span> <span class="n">default_data_collator</span><span class="p">,</span>
                          <span class="n">EvalPrediction</span><span class="p">,</span> <span class="n">QuestionAnsweringPipeline</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">transformers.trainer_utils</span> <span class="kn">import</span> <span class="n">PredictionOutput</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running on device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Running on device: cuda
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-data">Load data<a class="anchor-link" href="#Load-data"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">squad</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;squad&quot;</span><span class="p">)</span>
<span class="n">squad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>DatasetDict({
    train: Dataset({
        features: [&#39;id&#39;, &#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;answers&#39;],
        num_rows: 87599
    })
    validation: Dataset({
        features: [&#39;id&#39;, &#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;answers&#39;],
        num_rows: 10570
    })
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-tune-the-teacher">Fine-tune the teacher<a class="anchor-link" href="#Fine-tune-the-teacher"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-data">Preprocess data<a class="anchor-link" href="#Preprocess-data"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher_model_name</span> <span class="o">=</span> <span class="s2">&quot;bert-base-uncased&quot;</span>
<span class="n">teacher_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">teacher_model_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_length</span> <span class="o">=</span> <span class="mi">384</span> 
<span class="n">doc_stride</span> <span class="o">=</span> <span class="mi">128</span> 
<span class="n">pad_on_right</span> <span class="o">=</span> <span class="n">teacher_tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">==</span> <span class="s2">&quot;right&quot;</span>

<span class="n">fn_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="n">teacher_tokenizer</span><span class="p">,</span>
    <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="n">max_length</span><span class="p">,</span>
    <span class="s2">&quot;doc_stride&quot;</span><span class="p">:</span> <span class="n">doc_stride</span><span class="p">,</span>
    <span class="s2">&quot;pad_on_right&quot;</span><span class="p">:</span> <span class="n">pad_on_right</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Preprocess-training-set">Preprocess training set<a class="anchor-link" href="#Preprocess-training-set"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_enc</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">prepare_train_features</span><span class="p">,</span> <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">squad</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
<span class="n">train_enc</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7/cache-5a2028a8427fd1c9.arrow
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Dataset({
    features: [&#39;attention_mask&#39;, &#39;end_positions&#39;, &#39;input_ids&#39;, &#39;start_positions&#39;, &#39;token_type_ids&#39;],
    num_rows: 88524
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">squad</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">teacher_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">train_enc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;answers&#39;: {&#39;answer_start&#39;: [515], &#39;text&#39;: [&#39;Saint Bernadette Soubirous&#39;]},
 &#39;context&#39;: &#39;Architecturally, the school has a Catholic character. Atop the &#39;
            &#34;Main Building&#39;s gold dome is a golden statue of the Virgin Mary. &#34;
            &#39;Immediately in front of the Main Building and facing it, is a &#39;
            &#39;copper statue of Christ with arms upraised with the legend &#39;
            &#39;&#34;Venite Ad Me Omnes&#34;. Next to the Main Building is the Basilica &#39;
            &#39;of the Sacred Heart. Immediately behind the basilica is the &#39;
            &#39;Grotto, a Marian place of prayer and reflection. It is a replica &#39;
            &#39;of the grotto at Lourdes, France where the Virgin Mary reputedly &#39;
            &#39;appeared to Saint Bernadette Soubirous in 1858. At the end of the &#39;
            &#39;main drive (and in a direct line that connects through 3 statues &#39;
            &#39;and the Gold Dome), is a simple, modern stone statue of Mary.&#39;,
 &#39;id&#39;: &#39;5733be284776f41900661182&#39;,
 &#39;question&#39;: &#39;To whom did the Virgin Mary allegedly appear in 1858 in Lourdes &#39;
             &#39;France?&#39;,
 &#39;title&#39;: &#39;University_of_Notre_Dame&#39;}
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;to whom did the virgin mary allegedly appear in 1858 in lourdes france? architecturally, the school has a catholic character. atop the main building\&#39;s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend &#34; venite ad me omnes &#34;. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary.&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Preprocess-validation-set">Preprocess validation set<a class="anchor-link" href="#Preprocess-validation-set"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_enc</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">prepare_validation_features</span><span class="p">,</span> <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">squad</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
<span class="n">valid_enc</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7/cache-791647bce0494b0b.arrow
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Dataset({
    features: [&#39;attention_mask&#39;, &#39;example_id&#39;, &#39;input_ids&#39;, &#39;offset_mapping&#39;, &#39;token_type_ids&#39;],
    num_rows: 10784
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">teacher_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">valid_enc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;answers&#39;: {&#39;answer_start&#39;: [177, 177, 177],
             &#39;text&#39;: [&#39;Denver Broncos&#39;, &#39;Denver Broncos&#39;, &#39;Denver Broncos&#39;]},
 &#39;context&#39;: &#39;Super Bowl 50 was an American football game to determine the &#39;
            &#39;champion of the National Football League (NFL) for the 2015 &#39;
            &#39;season. The American Football Conference (AFC) champion Denver &#39;
            &#39;Broncos defeated the National Football Conference (NFC) champion &#39;
            &#39;Carolina Panthers 24–10 to earn their third Super Bowl title. The &#39;
            &#34;game was played on February 7, 2016, at Levi&#39;s Stadium in the San &#34;
            &#39;Francisco Bay Area at Santa Clara, California. As this was the &#39;
            &#39;50th Super Bowl, the league emphasized the &#34;golden anniversary&#34; &#39;
            &#39;with various gold-themed initiatives, as well as temporarily &#39;
            &#39;suspending the tradition of naming each Super Bowl game with &#39;
            &#39;Roman numerals (under which the game would have been known as &#39;
            &#39;&#34;Super Bowl L&#34;), so that the logo could prominently feature the &#39;
            &#39;Arabic numerals 50.&#39;,
 &#39;id&#39;: &#39;56be4db0acb8001400a502ec&#39;,
 &#39;question&#39;: &#39;Which NFL team represented the AFC at Super Bowl 50?&#39;,
 &#39;title&#39;: &#39;Super_Bowl_50&#39;}
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 – 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi\&#39;s stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the &#34; golden anniversary &#34; with various gold - themed initiatives, as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as &#34; super bowl l &#34; ), so that the logo could prominently feature the arabic numerals 50.&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Initialize-trainer">Initialize trainer<a class="anchor-link" href="#Initialize-trainer"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher_model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">teacher_model_name</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">frac_of_samples</span> <span class="o">=</span> <span class="o">.</span><span class="mi">005</span>

<span class="k">if</span> <span class="n">frac_of_samples</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>    
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_enc</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">frac_of_samples</span> <span class="o">*</span> <span class="n">train_enc</span><span class="o">.</span><span class="n">num_rows</span><span class="p">)))</span>
    <span class="n">eval_ds</span> <span class="o">=</span> <span class="n">valid_enc</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">frac_of_samples</span> <span class="o">*</span> <span class="n">valid_enc</span><span class="o">.</span><span class="n">num_rows</span><span class="p">)))</span>
    <span class="n">eval_raw_ds</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">frac_of_samples</span> <span class="o">*</span> <span class="n">squad</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">num_rows</span><span class="p">)))</span>
    
    <span class="k">assert</span> <span class="n">eval_ds</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">==</span> <span class="n">eval_raw_ds</span><span class="o">.</span><span class="n">num_rows</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_enc</span>
    <span class="n">eval_ds</span> <span class="o">=</span> <span class="n">valid_enc</span>
    <span class="n">eval_raw_ds</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of training examples: </span><span class="si">{</span><span class="n">train_ds</span><span class="o">.</span><span class="n">num_rows</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of validation examples: </span><span class="si">{</span><span class="n">eval_ds</span><span class="o">.</span><span class="n">num_rows</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of raw validation examples: </span><span class="si">{</span><span class="n">eval_raw_ds</span><span class="o">.</span><span class="n">num_rows</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">logging_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

<span class="n">teacher_args</span> <span class="o">=</span> <span class="n">QuestionAnsweringTrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;checkpoints&quot;</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">data_collator</span> <span class="o">=</span> <span class="n">default_data_collator</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;]
- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: [&#39;qa_outputs.weight&#39;, &#39;qa_outputs.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of training examples: 442
Number of validation examples: 53
Number of raw validation examples: 53
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher_trainer</span> <span class="o">=</span> <span class="n">QuestionAnsweringTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">teacher_model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">teacher_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_ds</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_ds</span><span class="p">,</span>
    <span class="n">eval_examples</span><span class="o">=</span><span class="n">eval_raw_ds</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">teacher_tokenizer</span><span class="p">,</span>
    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">squad_metrics</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
        </style>
      
      <progress value='11066' max='11066' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [11066/11066 2:52:49, Epoch 2/2]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Exact Match</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1.000000</td>
      <td>1.348786</td>
      <td>No log</td>
      <td>78.798486</td>
      <td>86.681167</td>
    </tr>
    <tr>
      <td>2.000000</td>
      <td>0.820882</td>
      <td>No log</td>
      <td>80.075686</td>
      <td>87.778703</td>
    </tr>
  </tbody>
</table><p>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TrainOutput(global_step=11066, training_loss=1.0848221554800117)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher_trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s1">&#39;models/bert-base-uncased-finetuned-squad-v1&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-pipeline">Create pipeline<a class="anchor-link" href="#Create-pipeline"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher_pipe</span> <span class="o">=</span> <span class="n">QuestionAnsweringPipeline</span><span class="p">(</span><span class="n">teacher_trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">),</span> <span class="n">teacher_tokenizer</span><span class="p">)</span>

<span class="n">context</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;context&#39;</span><span class="p">]</span>
<span class="n">question</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span>

<span class="c1"># expected answer: &#39;Denver Broncos&#39;, score: 0.8437, start: 177, end: 191</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">teacher_pipe</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
<span class="n">result</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;score&#39;: 0.6260135173797607,
 &#39;start&#39;: 177,
 &#39;end&#39;: 191,
 &#39;answer&#39;: &#39;Denver Broncos&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Distillation">Distillation<a class="anchor-link" href="#Distillation"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-data">Preprocess data<a class="anchor-link" href="#Preprocess-data"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student_model_name</span> <span class="o">=</span> <span class="s2">&quot;distilbert-base-uncased&quot;</span>
<span class="n">student_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">student_model_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_length</span> <span class="o">=</span> <span class="mi">384</span> 
<span class="n">doc_stride</span> <span class="o">=</span> <span class="mi">128</span> 
<span class="n">pad_on_right</span> <span class="o">=</span> <span class="n">student_tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">==</span> <span class="s2">&quot;right&quot;</span>

<span class="n">fn_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="n">student_tokenizer</span><span class="p">,</span>
    <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="n">max_length</span><span class="p">,</span>
    <span class="s2">&quot;doc_stride&quot;</span><span class="p">:</span> <span class="n">doc_stride</span><span class="p">,</span>
    <span class="s2">&quot;pad_on_right&quot;</span><span class="p">:</span> <span class="n">pad_on_right</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Preprocess-training-set">Preprocess training set<a class="anchor-link" href="#Preprocess-training-set"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_enc</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">prepare_train_features</span><span class="p">,</span> <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">squad</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
<span class="n">train_enc</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Dataset({
    features: [&#39;attention_mask&#39;, &#39;end_positions&#39;, &#39;input_ids&#39;, &#39;start_positions&#39;],
    num_rows: 88524
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Preprocess-validation-set">Preprocess validation set<a class="anchor-link" href="#Preprocess-validation-set"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_enc</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">prepare_validation_features</span><span class="p">,</span> <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">squad</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
<span class="n">valid_enc</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Dataset({
    features: [&#39;attention_mask&#39;, &#39;example_id&#39;, &#39;input_ids&#39;, &#39;offset_mapping&#39;],
    num_rows: 10784
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-distillation-trainer">Create distillation trainer<a class="anchor-link" href="#Create-distillation-trainer"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DistillationTrainer" class="doc_header"><code>class</code> <code>DistillationTrainer</code><a href="https://github.com/lewtun/transformerlab/tree/master/transformerlab/distillation.py#L9" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DistillationTrainer</code>(<strong>*<code>args</code></strong>, <strong><code>teacher_model</code></strong>=<em><code>None</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/transformerlab/question-answering.html#QuestionAnsweringTrainer"><code>QuestionAnsweringTrainer</code></a></p>
</blockquote>
<p>Trainer is a simple but feature-complete training and eval loop for PyTorch, optimized for 🤗 Transformers.</p>
<p>Args:
    model (:class:<code>~transformers.PreTrainedModel</code> or :obj:<code>torch.nn.Module</code>, <code>optional</code>):
        The model to train, evaluate or use for predictions. If not provided, a <code>model_init</code> must be passed.</p>

<pre><code>    .. note::

        :class:`~transformers.Trainer` is optimized to work with the :class:`~transformers.PreTrainedModel`
        provided by the library. You can still use your own models defined as :obj:`torch.nn.Module` as long as
        they work the same way as the 🤗 Transformers models.
args (:class:`~transformers.TrainingArguments`, `optional`):
    The arguments to tweak for training. Will default to a basic instance of
    :class:`~transformers.TrainingArguments` with the ``output_dir`` set to a directory named `tmp_trainer` in
    the current directory if not provided.
data_collator (:obj:`DataCollator`, `optional`):
    The function to use to form a batch from a list of elements of :obj:`train_dataset` or :obj:`eval_dataset`.
    Will default to :func:`~transformers.default_data_collator` if no ``tokenizer`` is provided, an instance of
    :func:`~transformers.DataCollatorWithPadding` otherwise.
train_dataset (:obj:`torch.utils.data.dataset.Dataset`, `optional`):
    The dataset to use for training. If it is an :obj:`datasets.Dataset`, columns not accepted by the
    ``model.forward()`` method are automatically removed.
eval_dataset (:obj:`torch.utils.data.dataset.Dataset`, `optional`):
     The dataset to use for evaluation. If it is an :obj:`datasets.Dataset`, columns not accepted by the
     ``model.forward()`` method are automatically removed.
tokenizer (:class:`PreTrainedTokenizerBase`, `optional`):
    The tokenizer used to preprocess the data. If provided, will be used to automatically pad the inputs the
    maximum length when batching inputs, and it will be saved along the model to make it easier to rerun an
    interrupted training or reuse the fine-tuned model.
model_init (:obj:`Callable[[], PreTrainedModel]`, `optional`):
    A function that instantiates the model to be used. If provided, each call to
    :meth:`~transformers.Trainer.train` will start from a new instance of the model as given by this function.

    The function may have zero argument, or a single one containing the optuna/Ray Tune trial object, to be
    able to choose different architectures according to hyper parameters (such as layer count, sizes of inner
    layers, dropout probabilities etc).
compute_metrics (:obj:`Callable[[EvalPrediction], Dict]`, `optional`):
    The function that will be used to compute metrics at evaluation. Must take a
    :class:`~transformers.EvalPrediction` and return a dictionary string to metric values.
callbacks (List of :obj:`~transformers.TrainerCallback`, `optional`):
    A list of callbacks to customize the training loop. Will add those to the list of default callbacks
    detailed in :doc:`here &lt;callback&gt;`.

    If you want to remove one of the default callbacks used, use the :meth:`Trainer.remove_callback` method.
optimizers (:obj:`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR`, `optional`): A tuple
    containing the optimizer and the scheduler to use. Will default to an instance of
    :class:`~transformers.AdamW` on your model and a scheduler given by
    :func:`~transformers.get_linear_schedule_with_warmup` controlled by :obj:`args`.

</code></pre>
<p>Important attributes:</p>

<pre><code>- **model** -- Always points to the core model. If using a transformers model, it will be a
  :class:`~transformers.PreTrainedModel` subclass.
- **model_wrapped** -- Always points to the most external model in case one or more other modules wrap the
  original model. This is the model that should be used for the forward pass. For example, under ``DeepSpeed``,
  the inner model is wrapped in ``DeepSpeed`` and then again in ``torch.nn.DistributedDataParallel``. If the
  inner model hasn't been wrapped, then ``self.model_wrapped`` is the same as ``self.model``.
- **is_model_parallel** -- Whether or not a model has been switched to a model parallel mode (different from
  data parallelism, this means some of the model layers are split on different GPUs).</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Initialise-and-fine-tune-trainer">Initialise and fine-tune trainer<a class="anchor-link" href="#Initialise-and-fine-tune-trainer"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DistillationTrainingArguments" class="doc_header"><code>class</code> <code>DistillationTrainingArguments</code><a href="https://github.com/lewtun/transformerlab/tree/master/transformerlab/distillation.py#L63" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DistillationTrainingArguments</code>(<strong>*<code>args</code></strong>, <strong><code>alpha_ce</code></strong>=<em><code>0.5</code></em>, <strong><code>alpha_squad</code></strong>=<em><code>0.5</code></em>, <strong><code>temperature</code></strong>=<em><code>2.0</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/transformerlab/question-answering.html#QuestionAnsweringTrainingArguments"><code>QuestionAnsweringTrainingArguments</code></a></p>
</blockquote>
<p>TrainingArguments is the subset of the arguments we use in our example scripts <strong>which relate to the training loop
itself</strong>.</p>
<p>Using :class:<code>~transformers.HfArgumentParser</code> we can turn this class into <code>argparse
&lt;https://docs.python.org/3/library/argparse.html#module-argparse&gt;</code>__ arguments that can be specified on the command
line.</p>
<p>Parameters:
    output_dir (:obj:<code>str</code>):
        The output directory where the model predictions and checkpoints will be written.
    overwrite_output_dir (:obj:<code>bool</code>, <code>optional</code>, defaults to :obj:<code>False</code>):
        If :obj:<code>True</code>, overwrite the content of the output directory. Use this to continue training if
        :obj:<code>output_dir</code> points to a checkpoint directory.
    do_train (:obj:<code>bool</code>, <code>optional</code>, defaults to :obj:<code>False</code>):
        Whether to run training or not. This argument is not directly used by :class:<code>~transformers.Trainer</code>, it's
        intended to be used by your training/evaluation scripts instead. See the <code>example scripts
        &lt;https://github.com/huggingface/transformers/tree/master/examples&gt;</code><strong> for more details.
    do_eval (:obj:<code>bool</code>, <code>optional</code>):
        Whether to run evaluation on the validation set or not. Will be set to :obj:<code>True</code> if
        :obj:<code>evaluation_strategy</code> is different from :obj:<code>"no"</code>. This argument is not directly used by
        :class:<code>~transformers.Trainer</code>, it's intended to be used by your training/evaluation scripts instead. See
        the <code>example scripts &lt;https://github.com/huggingface/transformers/tree/master/examples&gt;</code></strong> for more
        details.
    do_predict (:obj:<code>bool</code>, <code>optional</code>, defaults to :obj:<code>False</code>):
        Whether to run predictions on the test set or not. This argument is not directly used by
        :class:<code>~transformers.Trainer</code>, it's intended to be used by your training/evaluation scripts instead. See
        the <code>example scripts &lt;https://github.com/huggingface/transformers/tree/master/examples&gt;</code>__ for more
        details.
    evaluation_strategy (:obj:<code>str</code> or :class:<code>~transformers.trainer_utils.EvaluationStrategy</code>, <code>optional</code>, defaults to :obj:<code>"no"</code>):
        The evaluation strategy to adopt during training. Possible values are:</p>

<pre><code>        * :obj:`"no"`: No evaluation is done during training.
        * :obj:`"steps"`: Evaluation is done (and logged) every :obj:`eval_steps`.
        * :obj:`"epoch"`: Evaluation is done at the end of each epoch.

prediction_loss_only (:obj:`bool`, `optional`, defaults to `False`):
    When performing evaluation and generating predictions, only returns the loss.
per_device_train_batch_size (:obj:`int`, `optional`, defaults to 8):
    The batch size per GPU/TPU core/CPU for training.
per_device_eval_batch_size (:obj:`int`, `optional`, defaults to 8):
    The batch size per GPU/TPU core/CPU for evaluation.
gradient_accumulation_steps (:obj:`int`, `optional`, defaults to 1):
    Number of updates steps to accumulate the gradients for, before performing a backward/update pass.

    .. warning::

        When using gradient accumulation, one step is counted as one step with backward pass. Therefore,
        logging, evaluation, save will be conducted every ``gradient_accumulation_steps * xxx_step`` training
        examples.
eval_accumulation_steps (:obj:`int`, `optional`):
    Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU. If
    left unset, the whole predictions are accumulated on GPU/TPU before being moved to the CPU (faster but
    requires more memory).
learning_rate (:obj:`float`, `optional`, defaults to 5e-5):
    The initial learning rate for Adam.
weight_decay (:obj:`float`, `optional`, defaults to 0):
    The weight decay to apply (if not zero).
adam_beta1 (:obj:`float`, `optional`, defaults to 0.9):
    The beta1 hyperparameter for the Adam optimizer.
adam_beta2 (:obj:`float`, `optional`, defaults to 0.999):
    The beta2 hyperparameter for the Adam optimizer.
adam_epsilon (:obj:`float`, `optional`, defaults to 1e-8):
    The epsilon hyperparameter for the Adam optimizer.
max_grad_norm (:obj:`float`, `optional`, defaults to 1.0):
    Maximum gradient norm (for gradient clipping).
num_train_epochs(:obj:`float`, `optional`, defaults to 3.0):
    Total number of training epochs to perform (if not an integer, will perform the decimal part percents of
    the last epoch before stopping training).
max_steps (:obj:`int`, `optional`, defaults to -1):
    If set to a positive number, the total number of training steps to perform. Overrides
    :obj:`num_train_epochs`.
lr_scheduler_type (:obj:`str` or :class:`~transformers.SchedulerType`, `optional`, defaults to :obj:`"linear"`):
    The scheduler type to use. See the documentation of :class:`~transformers.SchedulerType` for all possible
    values.
warmup_steps (:obj:`int`, `optional`, defaults to 0):
    Number of steps used for a linear warmup from 0 to :obj:`learning_rate`.
logging_dir (:obj:`str`, `optional`):
    `TensorBoard &lt;https://www.tensorflow.org/tensorboard&gt;`__ log directory. Will default to
    `runs/**CURRENT_DATETIME_HOSTNAME**`.
logging_first_step (:obj:`bool`, `optional`, defaults to :obj:`False`):
    Whether to log and evaluate the first :obj:`global_step` or not.
logging_steps (:obj:`int`, `optional`, defaults to 500):
    Number of update steps between two logs.
save_steps (:obj:`int`, `optional`, defaults to 500):
    Number of updates steps before two checkpoint saves.
save_total_limit (:obj:`int`, `optional`):
    If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in
    :obj:`output_dir`.
no_cuda (:obj:`bool`, `optional`, defaults to :obj:`False`):
    Whether to not use CUDA even when it is available or not.
seed (:obj:`int`, `optional`, defaults to 42):
    Random seed for initialization.
fp16 (:obj:`bool`, `optional`, defaults to :obj:`False`):
    Whether to use 16-bit (mixed) precision training (through NVIDIA Apex) instead of 32-bit training.
fp16_opt_level (:obj:`str`, `optional`, defaults to 'O1'):
    For :obj:`fp16` training, Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']. See details
    on the `Apex documentation &lt;https://nvidia.github.io/apex/amp.html&gt;`__.
fp16_backend (:obj:`str`, `optional`, defaults to :obj:`"auto"`):
    The backend to use for mixed precision training. Must be one of :obj:`"auto"`, :obj:`"amp"` or
    :obj:`"apex"`. :obj:`"auto"` will use AMP or APEX depending on the PyTorch version detected, while the
    other choices will force the requested backend.
local_rank (:obj:`int`, `optional`, defaults to -1):
    Rank of the process during distributed training.
tpu_num_cores (:obj:`int`, `optional`):
    When training on TPU, the number of TPU cores (automatically passed by launcher script).
debug (:obj:`bool`, `optional`, defaults to :obj:`False`):
    When training on TPU, whether to print debug metrics or not.
dataloader_drop_last (:obj:`bool`, `optional`, defaults to :obj:`False`):
    Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch size)
    or not.
eval_steps (:obj:`int`, `optional`):
    Number of update steps between two evaluations if :obj:`evaluation_strategy="steps"`. Will default to the
    same value as :obj:`logging_steps` if not set.
dataloader_num_workers (:obj:`int`, `optional`, defaults to 0):
    Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded in the
    main process.
past_index (:obj:`int`, `optional`, defaults to -1):
    Some models like :doc:`TransformerXL &lt;../model_doc/transformerxl&gt;` or :doc`XLNet &lt;../model_doc/xlnet&gt;` can
    make use of the past hidden states for their predictions. If this argument is set to a positive int, the
    ``Trainer`` will use the corresponding output (usually index 2) as the past state and feed it to the model
    at the next training step under the keyword argument ``mems``.
run_name (:obj:`str`, `optional`):
    A descriptor for the run. Typically used for `wandb &lt;https://www.wandb.com/&gt;`_ logging.
disable_tqdm (:obj:`bool`, `optional`):
    Whether or not to disable the tqdm progress bars and table of metrics produced by
    :class:`~transformers.notebook.NotebookTrainingTracker` in Jupyter Notebooks. Will default to :obj:`True`
    if the logging level is set to warn or lower (default), :obj:`False` otherwise.
remove_unused_columns (:obj:`bool`, `optional`, defaults to :obj:`True`):
    If using :obj:`datasets.Dataset` datasets, whether or not to automatically remove the columns unused by the
    model forward method.

    (Note that this behavior is not implemented for :class:`~transformers.TFTrainer` yet.)
label_names (:obj:`List[str]`, `optional`):
    The list of keys in your dictionary of inputs that correspond to the labels.

    Will eventually default to :obj:`["labels"]` except if the model used is one of the
    :obj:`XxxForQuestionAnswering` in which case it will default to :obj:`["start_positions",
    "end_positions"]`.
load_best_model_at_end (:obj:`bool`, `optional`, defaults to :obj:`False`):
    Whether or not to load the best model found during training at the end of training.

    .. note::

        When set to :obj:`True`, the parameters :obj:`save_steps` will be ignored and the model will be saved
        after each evaluation.
metric_for_best_model (:obj:`str`, `optional`):
    Use in conjunction with :obj:`load_best_model_at_end` to specify the metric to use to compare two different
    models. Must be the name of a metric returned by the evaluation with or without the prefix :obj:`"eval_"`.
    Will default to :obj:`"loss"` if unspecified and :obj:`load_best_model_at_end=True` (to use the evaluation
    loss).

    If you set this value, :obj:`greater_is_better` will default to :obj:`True`. Don't forget to set it to
    :obj:`False` if your metric is better when lower.
greater_is_better (:obj:`bool`, `optional`):
    Use in conjunction with :obj:`load_best_model_at_end` and :obj:`metric_for_best_model` to specify if better
    models should have a greater metric or not. Will default to:

    - :obj:`True` if :obj:`metric_for_best_model` is set to a value that isn't :obj:`"loss"` or
      :obj:`"eval_loss"`.
    - :obj:`False` if :obj:`metric_for_best_model` is not set, or set to :obj:`"loss"` or :obj:`"eval_loss"`.
ignore_skip_data (:obj:`bool`, `optional`, defaults to :obj:`False`):
    When resuming training, whether or not to skip the epochs and batches to get the data loading at the same
    stage as in the previous training. If set to :obj:`True`, the training will begin faster (as that skipping
    step can take a long time) but will not yield the same results as the interrupted training would have.
sharded_ddp (:obj:`bool`, `optional`, defaults to :obj:`False`):
    Use Sharded DDP training from `FairScale &lt;https://github.com/facebookresearch/fairscale&gt;`__ (in distributed
    training only). This is an experimental feature.
deepspeed (:obj:`str`, `optional`):
    Use `Deepspeed &lt;https://github.com/microsoft/deepspeed&gt;`__. This is an experimental feature and its API may
    evolve in the future. The value is the location of its json config file (usually ``ds_config.json``).
label_smoothing_factor (:obj:`float`, `optional`, defaults to 0.0):
    The label smoothing factor to use. Zero means no label smoothing, otherwise the underlying onehot-encoded
    labels are changed from 0s and 1s to :obj:`label_smoothing_factor/num_labels` and :obj:`1 -
    label_smoothing_factor + label_smoothing_factor/num_labels` respectively.
adafactor (:obj:`bool`, `optional`, defaults to :obj:`False`):
    Whether or not to use the :class:`~transformers.Adafactor` optimizer instead of
    :class:`~transformers.AdamW`.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student_model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">student_model_name</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">teacher_model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;lewtun/bert-base-uncased-finetuned-squad-v1&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">frac_of_samples</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">if</span> <span class="n">frac_of_samples</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>    
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_enc</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">frac_of_samples</span> <span class="o">*</span> <span class="n">train_enc</span><span class="o">.</span><span class="n">num_rows</span><span class="p">)))</span>
    <span class="n">eval_ds</span> <span class="o">=</span> <span class="n">valid_enc</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">frac_of_samples</span> <span class="o">*</span> <span class="n">valid_enc</span><span class="o">.</span><span class="n">num_rows</span><span class="p">)))</span>
    <span class="n">eval_raw_ds</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">frac_of_samples</span> <span class="o">*</span> <span class="n">squad</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">num_rows</span><span class="p">)))</span>
    
    <span class="k">assert</span> <span class="n">eval_ds</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">==</span> <span class="n">eval_raw_ds</span><span class="o">.</span><span class="n">num_rows</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_enc</span>
    <span class="n">eval_ds</span> <span class="o">=</span> <span class="n">valid_enc</span>
    <span class="n">eval_raw_ds</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of training examples: </span><span class="si">{</span><span class="n">train_ds</span><span class="o">.</span><span class="n">num_rows</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of validation examples: </span><span class="si">{</span><span class="n">eval_ds</span><span class="o">.</span><span class="n">num_rows</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of raw validation examples: </span><span class="si">{</span><span class="n">eval_raw_ds</span><span class="o">.</span><span class="n">num_rows</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">logging_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

<span class="n">student_training_args</span> <span class="o">=</span> <span class="n">DistillationTrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;checkpoints&quot;</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">data_collator</span> <span class="o">=</span> <span class="n">default_data_collator</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

Number of training examples: 88524
Number of validation examples: 10784
Number of raw validation examples: 10570
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">distil_trainer</span> <span class="o">=</span> <span class="n">DistillationTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">student_model</span><span class="p">,</span>
    <span class="n">teacher_model</span><span class="o">=</span><span class="n">teacher_model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">student_training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_ds</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_ds</span><span class="p">,</span>
    <span class="n">eval_examples</span><span class="o">=</span><span class="n">eval_raw_ds</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">student_tokenizer</span><span class="p">,</span>
    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">squad_metrics</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">distil_trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
        </style>
      
      <progress value='1348' max='674' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [674/674 1:26:54]
    </div>
    
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;eval_loss&#39;: &#39;No log&#39;,
 &#39;eval_exact_match&#39;: 0.15137180700094607,
 &#39;eval_f1&#39;: 7.167017942222715}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">distil_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
        </style>
      
      <progress value='16599' max='16599' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [16599/16599 4:02:30, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Exact Match</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1.000000</td>
      <td>1.487708</td>
      <td>No log</td>
      <td>76.404920</td>
      <td>84.762400</td>
    </tr>
    <tr>
      <td>2.000000</td>
      <td>0.764606</td>
      <td>No log</td>
      <td>77.417219</td>
      <td>85.620589</td>
    </tr>
    <tr>
      <td>3.000000</td>
      <td>0.609311</td>
      <td>No log</td>
      <td>78.391675</td>
      <td>86.447313</td>
    </tr>
  </tbody>
</table><p>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>


</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TrainOutput(global_step=16599, training_loss=0.9538024121202958)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">distil_trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s1">&#39;models/distilbert-base-uncased-distilled-squad-v1&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-pipeline">Create pipeline<a class="anchor-link" href="#Create-pipeline"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student_pipe</span> <span class="o">=</span> <span class="n">QuestionAnsweringPipeline</span><span class="p">(</span><span class="n">distil_trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">),</span> <span class="n">student_tokenizer</span><span class="p">)</span>

<span class="n">context</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;context&#39;</span><span class="p">]</span>
<span class="n">question</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">question</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">context</span><span class="p">)</span>

<span class="c1"># expected answer: &#39;Denver Broncos&#39;, score: 0.8437, start: 177, end: 191</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">student_pipe</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
<span class="n">result</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(&#39;Which NFL team represented the AFC at Super Bowl 50?\n&#39;
 &#39;Super Bowl 50 was an American football game to determine the champion of the &#39;
 &#39;National Football League (NFL) for the 2015 season. The American Football &#39;
 &#39;Conference (AFC) champion Denver Broncos defeated the National Football &#39;
 &#39;Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super &#39;
 &#34;Bowl title. The game was played on February 7, 2016, at Levi&#39;s Stadium in &#34;
 &#39;the San Francisco Bay Area at Santa Clara, California. As this was the 50th &#39;
 &#39;Super Bowl, the league emphasized the &#34;golden anniversary&#34; with various &#39;
 &#39;gold-themed initiatives, as well as temporarily suspending the tradition of &#39;
 &#39;naming each Super Bowl game with Roman numerals (under which the game would &#39;
 &#39;have been known as &#34;Super Bowl L&#34;), so that the logo could prominently &#39;
 &#39;feature the Arabic numerals 50.&#39;)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;score&#39;: 0.8734882473945618,
 &#39;start&#39;: 177,
 &#39;end&#39;: 191,
 &#39;answer&#39;: &#39;Denver Broncos&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Speed-test">Speed test<a class="anchor-link" href="#Speed-test"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student_model_ckpt</span> <span class="o">=</span> <span class="s1">&#39;lewtun/distilbert-base-uncased-distilled-squad-v1&#39;</span>
<span class="n">teacher_model_ckpt</span> <span class="o">=</span> <span class="s1">&#39;lewtun/bert-base-uncased-finetuned-squad-v1&#39;</span>

<span class="n">student_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">student_model_ckpt</span><span class="p">)</span>
<span class="n">student_model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">student_model_ckpt</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="n">teacher_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">teacher_model_ckpt</span><span class="p">)</span>
<span class="n">teacher_model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">teacher_model_ckpt</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>







</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student_pipe</span> <span class="o">=</span> <span class="n">QuestionAnsweringPipeline</span><span class="p">(</span><span class="n">student_model</span><span class="p">,</span> <span class="n">student_tokenizer</span><span class="p">)</span>
<span class="n">teacher_pipe</span> <span class="o">=</span> <span class="n">QuestionAnsweringPipeline</span><span class="p">(</span><span class="n">teacher_model</span><span class="p">,</span> <span class="n">teacher_tokenizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;context&#39;</span><span class="p">]</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span>
    <span class="n">teacher_pipe</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 43min 46s, sys: 19.9 s, total: 44min 6s
Wall time: 6min 38s
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;context&#39;</span><span class="p">]</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">squad</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span>
    <span class="n">student_pipe</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 21min 11s, sys: 9.75 s, total: 21min 21s
Wall time: 3min 12s
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

