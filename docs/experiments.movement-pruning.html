---

title: Movement Pruning


keywords: fastai
sidebar: home_sidebar

summary: "A partial re-implementation of Movement Pruning: Adaptive Sparsity by Fine-Tuning by Victor Sanh, Thomas Wolf, and Alexander M. Rush <a href='https://arxiv.org/abs/2005.07683'>[arXiv:2005.07683</a>]"
description: "A partial re-implementation of Movement Pruning: Adaptive Sparsity by Fine-Tuning by Victor Sanh, Thomas Wolf, and Alexander M. Rush <a href='https://arxiv.org/abs/2005.07683'>[arXiv:2005.07683</a>]"
nb_path: "experiments.movement-pruning.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: experiments.movement-pruning.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The main goal of this notebook is to adapt Victor Sanh's <a href="https://github.com/huggingface/transformers/tree/master/examples/research_projects/movement-pruning">implementation</a> of movement pruning to:</p>
<ul>
<li>Integrate with a custom trainer</li>
<li>Experiment with pruning on small datasets</li>
<li>Be compatible with v4 of the <code>transformers</code> library</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-libraries">Load libraries<a class="anchor-link" href="#Load-libraries"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">datasets</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity_error</span><span class="p">()</span>
<span class="n">transformers</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity_error</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForQuestionAnswering</span><span class="p">,</span> <span class="n">default_data_collator</span><span class="p">,</span> <span class="n">AdamW</span><span class="p">,</span> 
                          <span class="n">get_linear_schedule_with_warmup</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">transformerlab.question_answering</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">transformerlab.pruning</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using transformers v</span><span class="si">{</span><span class="n">transformers</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2"> and datasets v</span><span class="si">{</span><span class="n">datasets</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running on device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using transformers v4.1.1 and datasets v1.2.0
Running on device: cuda
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-data">Load data<a class="anchor-link" href="#Load-data"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As usual, we'll be using the SQuAD v1 dataset as our benchmark so let's quickly load it as follows:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">squad_ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;squad&quot;</span><span class="p">)</span>
<span class="n">squad_ds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>DatasetDict({
    train: Dataset({
        features: [&#39;id&#39;, &#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;answers&#39;],
        num_rows: 87599
    })
    validation: Dataset({
        features: [&#39;id&#39;, &#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;answers&#39;],
        num_rows: 10570
    })
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, let's tokenize and encode a subset so we can run the experiments more quickly:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_ckpt</span> <span class="o">=</span> <span class="s1">&#39;bert-base-uncased&#39;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_ckpt</span><span class="p">)</span>

<span class="n">num_train_examples</span> <span class="o">=</span> <span class="mi">1600</span>
<span class="n">num_eval_examples</span> <span class="o">=</span> <span class="mi">320</span>
<span class="n">train_ds</span><span class="p">,</span> <span class="n">eval_ds</span><span class="p">,</span> <span class="n">eval_examples</span> <span class="o">=</span> <span class="n">convert_examples_to_features</span><span class="p">(</span><span class="n">squad_ds</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">num_train_examples</span><span class="p">,</span> <span class="n">num_eval_examples</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Create-the-trainer">Create the trainer<a class="anchor-link" href="#Create-the-trainer"> </a></h2><p>There are three main components we need in order to fine-prune with a <code>Trainer</code>:</p>
<ul>
<li>A cubic sparsity scheduler to control the amount of pruning at each training step</li>
<li>Optimisation of the scores ${\bf S}$ after $T$ gradient updates</li>
<li>A loss that accounts for the current mask threshold</li>
</ul>
<p>The following code does the trick:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">PruningTrainingArguments</span><span class="p">(</span><span class="n">QuestionAnsweringTrainingArguments</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">initial_threshold</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">final_threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">initial_warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">final_warmup</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">final_lambda</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                 <span class="n">mask_scores_learning_rate</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> 
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">initial_threshold</span> <span class="o">=</span> <span class="n">initial_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_threshold</span> <span class="o">=</span> <span class="n">final_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_warmup</span> <span class="o">=</span> <span class="n">initial_warmup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_warmup</span> <span class="o">=</span> <span class="n">final_warmup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_lambda</span> <span class="o">=</span> <span class="n">final_lambda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_scores_learning_rate</span> <span class="o">=</span> <span class="n">mask_scores_learning_rate</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">PruningTrainer</span><span class="p">(</span><span class="n">QuestionAnsweringTrainer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">t_total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">max_steps</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">//</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">())</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">t_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">())</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span>
            
        
    <span class="k">def</span> <span class="nf">create_optimizer_and_scheduler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">no_decay</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="s2">&quot;LayerNorm.weight&quot;</span><span class="p">]</span>
        <span class="n">optimizer_grouped_parameters</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;mask_score&quot;</span> <span class="ow">in</span> <span class="n">n</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">],</span>
                <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_scores_learning_rate</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="n">p</span>
                    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
                    <span class="k">if</span> <span class="s2">&quot;mask_score&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">n</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)</span>
                <span class="p">],</span>
                <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="n">p</span>
                    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
                    <span class="k">if</span> <span class="s2">&quot;mask_score&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">n</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)</span>
                <span class="p">],</span>
                <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">optimizer_grouped_parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">adam_epsilon</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">t_total</span>
        <span class="p">)</span>
        
        
    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
            
        <span class="n">threshold</span><span class="p">,</span> <span class="n">regu_lambda</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_schedule_threshold</span><span class="p">(</span>
            <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">global_step</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">total_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">t_total</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">,</span>
            <span class="n">final_threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">final_threshold</span><span class="p">,</span>
            <span class="n">initial_threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">initial_threshold</span><span class="p">,</span>
            <span class="n">final_warmup</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">final_warmup</span><span class="p">,</span>
            <span class="n">initial_warmup</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">initial_warmup</span><span class="p">,</span>
            <span class="n">final_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">final_lambda</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">threshold</span>  
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">start_logits_stu</span><span class="p">,</span> <span class="n">end_logits_stu</span> <span class="o">=</span> <span class="n">outputs</span>
        
        <span class="k">return</span> <span class="n">loss</span>
    
    <span class="k">def</span> <span class="nf">_schedule_threshold</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">total_step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">warmup_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">initial_threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">final_threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">initial_warmup</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">final_warmup</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">final_lambda</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">&lt;=</span> <span class="n">initial_warmup</span> <span class="o">*</span> <span class="n">warmup_steps</span><span class="p">:</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">initial_threshold</span>
        <span class="k">elif</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">total_step</span> <span class="o">-</span> <span class="n">final_warmup</span> <span class="o">*</span> <span class="n">warmup_steps</span><span class="p">):</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">final_threshold</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spars_warmup_steps</span> <span class="o">=</span> <span class="n">initial_warmup</span> <span class="o">*</span> <span class="n">warmup_steps</span>
            <span class="n">spars_schedu_steps</span> <span class="o">=</span> <span class="p">(</span><span class="n">final_warmup</span> <span class="o">+</span> <span class="n">initial_warmup</span><span class="p">)</span> <span class="o">*</span> <span class="n">warmup_steps</span>
            <span class="n">mul_coeff</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">step</span> <span class="o">-</span> <span class="n">spars_warmup_steps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">total_step</span> <span class="o">-</span> <span class="n">spars_schedu_steps</span><span class="p">)</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">final_threshold</span> <span class="o">+</span> <span class="p">(</span><span class="n">initial_threshold</span> <span class="o">-</span> <span class="n">final_threshold</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">mul_coeff</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">regu_lambda</span> <span class="o">=</span> <span class="n">final_lambda</span> <span class="o">*</span> <span class="n">threshold</span> <span class="o">/</span> <span class="n">final_threshold</span>
        <span class="k">return</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">regu_lambda</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Configure-the-trainer">Configure the trainer<a class="anchor-link" href="#Configure-the-trainer"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The next thing to do is configure the trainer. First, we need to use the special "masked" model and its configuration from the <code>transformerlab.pruning</code> module:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">masked_config</span> <span class="o">=</span> <span class="n">MaskedBertConfig</span><span class="p">(</span><span class="n">pruning_method</span><span class="o">=</span><span class="s1">&#39;topK&#39;</span><span class="p">,</span> <span class="n">mask_init</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">mask_scale</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">model_init</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">MaskedBertForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_ckpt</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">masked_config</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we're using a <code>model_init</code> function so that we can perform multiple runs wih the same trainer. Next we specify the hyperparameter that will be fixed across each run:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">logging_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

<span class="c1"># pruning params</span>
<span class="n">initial_threshold</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">initial_warmup</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">final_warmup</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">final_lambda</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">pruning_training_args</span> <span class="o">=</span> <span class="n">PruningTrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;checkpoints&quot;</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
    <span class="n">initial_threshold</span><span class="o">=</span><span class="n">initial_threshold</span><span class="p">,</span>
    <span class="n">initial_warmup</span><span class="o">=</span><span class="n">initial_warmup</span><span class="p">,</span>
    <span class="n">final_warmup</span><span class="o">=</span><span class="n">final_warmup</span><span class="p">,</span>
    <span class="n">final_lambda</span><span class="o">=</span><span class="n">final_lambda</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pruning_trainer</span> <span class="o">=</span> <span class="n">PruningTrainer</span><span class="p">(</span>
    <span class="n">model_init</span><span class="o">=</span><span class="n">model_init</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">pruning_training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_ds</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_ds</span><span class="p">,</span>
    <span class="n">eval_examples</span><span class="o">=</span><span class="n">eval_examples</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next let's wrap the key hyperparameters in a function, noting that we need to add the <code>final_threshold</code> to the evaluation set with our current implementation:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fine_prune</span><span class="p">(</span><span class="n">final_threshold</span><span class="p">,</span> <span class="n">num_train_epochs</span><span class="p">,</span> <span class="n">mask_scores_learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">):</span>
    <span class="n">eval_ds</span><span class="o">.</span><span class="n">reset_format</span><span class="p">()</span>
    <span class="n">pruning_trainer</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="p">{</span><span class="s1">&#39;threshold&#39;</span><span class="p">:</span> <span class="n">final_threshold</span><span class="p">})</span>
    <span class="n">pruning_trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">final_threshold</span> <span class="o">=</span> <span class="n">final_threshold</span>
    <span class="n">pruning_trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_scores_learning_rate</span> <span class="o">=</span> <span class="n">mask_scores_learning_rate</span>
    <span class="n">pruning_trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">=</span> <span class="n">num_train_epochs</span>
    <span class="n">pruning_trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_train_examples</span> <span class="o">/</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_train_epochs</span> <span class="o">*</span> <span class="o">.</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fine-pruning </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">pruning_trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">final_threshold</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">% of weights with lr = </span><span class="si">{</span><span class="n">pruning_trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2"> and mask_lr = </span><span class="si">{</span><span class="n">pruning_trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_scores_learning_rate</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">pruning_trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">warmup_steps</span><span class="si">}</span><span class="s2"> warmup steps&quot;</span><span class="p">)</span>
    <span class="n">pruning_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="BERT-base-experiments">BERT-base experiments<a class="anchor-link" href="#BERT-base-experiments"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="0%-pruning">0% pruning<a class="anchor-link" href="#0%-pruning"> </a></h3><p>As a baseline, let's set the final threshold to 1 (no pruning) and train for 5 epochs:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fine_prune</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
        </style>
      
      <progress value='303' max='303' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [303/303 06:53, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Exact Match</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1.000000</td>
      <td>4.200213</td>
      <td>No log</td>
      <td>31.562500</td>
      <td>44.250428</td>
    </tr>
    <tr>
      <td>2.000000</td>
      <td>2.207515</td>
      <td>No log</td>
      <td>41.250000</td>
      <td>53.709763</td>
    </tr>
    <tr>
      <td>3.000000</td>
      <td>1.592967</td>
      <td>No log</td>
      <td>44.062500</td>
      <td>56.170856</td>
    </tr>
  </tbody>
</table><p>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>


</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="10%-pruning">10% pruning<a class="anchor-link" href="#10%-pruning"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fine_prune</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="30%-pruning">30% pruning<a class="anchor-link" href="#30%-pruning"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="50%-pruning">50% pruning<a class="anchor-link" href="#50%-pruning"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="70%-pruning">70% pruning<a class="anchor-link" href="#70%-pruning"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="90%-pruning">90% pruning<a class="anchor-link" href="#90%-pruning"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="DistilBERT-experiments">DistilBERT experiments<a class="anchor-link" href="#DistilBERT-experiments"> </a></h2><p>Do Victor's "masked" model classes play nice with DistilBERT?</p>

</div>
</div>
</div>
</div>
 

