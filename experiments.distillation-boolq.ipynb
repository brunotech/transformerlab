{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge distillation on BoolQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers v4.1.1 and datasets v1.2.0\n",
      "Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "datasets.logging.set_verbosity_error()\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using transformers v{transformers.__version__} and datasets v{datasets.__version__}\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 9427\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 3270\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 3245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq = load_dataset(\"super_glue\", \"boolq\")\n",
    "boolq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq.rename_column_(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'labels': 1,\n",
       " 'passage': 'Persian language -- Persian (/ˈpɜːrʒən, -ʃən/), also known by its endonym Farsi (فارسی fārsi (fɒːɾˈsiː) ( listen)), is one of the Western Iranian languages within the Indo-Iranian branch of the Indo-European language family. It is primarily spoken in Iran, Afghanistan (officially known as Dari since 1958), and Tajikistan (officially known as Tajiki since the Soviet era), and some other regions which historically were Persianate societies and considered part of Greater Iran. It is written in the Persian alphabet, a modified variant of the Arabic script, which itself evolved from the Aramaic alphabet.',\n",
       " 'question': 'do iran and afghanistan speak the same language'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq.set_format('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>passage</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Persian language -- Persian (/ˈpɜːrʒən, -ʃən/)...</td>\n",
       "      <td>do iran and afghanistan speak the same language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Good Samaritan law -- Good Samaritan laws offe...</td>\n",
       "      <td>do good samaritan laws protect those who help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Windows Movie Maker -- Windows Movie Maker (fo...</td>\n",
       "      <td>is windows movie maker part of windows essentials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Powdered sugar -- Powdered sugar, also called ...</td>\n",
       "      <td>is confectionary sugar the same as powdered sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Elder Scrolls Online -- As with other game...</td>\n",
       "      <td>is elder scrolls online the same as skyrim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  label                                            passage  \\\n",
       "0    0      1  Persian language -- Persian (/ˈpɜːrʒən, -ʃən/)...   \n",
       "1    1      1  Good Samaritan law -- Good Samaritan laws offe...   \n",
       "2    2      1  Windows Movie Maker -- Windows Movie Maker (fo...   \n",
       "3    3      1  Powdered sugar -- Powdered sugar, also called ...   \n",
       "4    4      0  The Elder Scrolls Online -- As with other game...   \n",
       "\n",
       "                                            question  \n",
       "0    do iran and afghanistan speak the same language  \n",
       "1  do good samaritan laws protect those who help ...  \n",
       "2  is windows movie maker part of windows essentials  \n",
       "3  is confectionary sugar the same as powdered sugar  \n",
       "4         is elder scrolls online the same as skyrim  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = boolq['train'][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_len'] = (df['question'] + df['passage']).apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fc9c60c8710>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot(df['input_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>passage</th>\n",
       "      <th>question</th>\n",
       "      <th>input_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada's Worst Driver -- In each season, eight...</td>\n",
       "      <td>does canada's worst driver lose their license</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>2352</td>\n",
       "      <td>1</td>\n",
       "      <td>Brooke Davis -- She spends all of Valentine's ...</td>\n",
       "      <td>one tree hill episode brooke finds out she's p...</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>3547</td>\n",
       "      <td>1</td>\n",
       "      <td>Lexie Grey -- After openly acknowledging the s...</td>\n",
       "      <td>do little grey and mark get back together</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7410</th>\n",
       "      <td>7410</td>\n",
       "      <td>0</td>\n",
       "      <td>Out of My Mind (Draper novel) -- Melody Brooks...</td>\n",
       "      <td>does penny die in out of my mind</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx  label                                            passage  \\\n",
       "204    204      0  Canada's Worst Driver -- In each season, eight...   \n",
       "2352  2352      1  Brooke Davis -- She spends all of Valentine's ...   \n",
       "3547  3547      1  Lexie Grey -- After openly acknowledging the s...   \n",
       "7410  7410      0  Out of My Mind (Draper novel) -- Melody Brooks...   \n",
       "\n",
       "                                               question  input_len  \n",
       "204       does canada's worst driver lose their license        764  \n",
       "2352  one tree hill episode brooke finds out she's p...        672  \n",
       "3547          do little grey and mark get back together        625  \n",
       "7410                   does penny die in out of my mind        645  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['input_len'] > 512)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5874\n",
       "0    3553\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_score.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune BERT-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_ckpt = \"bert-large-uncased-whole-word-masking\"\n",
    "bl_tokenizer = AutoTokenizer.from_pretrained(bl_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(x, tokenizer): return tokenizer(x['question'], x['passage'], truncation=\"only_second\")\n",
    "\n",
    "boolq_enc = boolq.map(tokenize_and_encode, fn_kwargs={'tokenizer' : bl_tokenizer}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_model = AutoModelForSequenceClassification.from_pretrained(bl_ckpt).to(device)\n",
    "\n",
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "num_train_epochs = 3\n",
    "logging_steps = len(boolq_enc['train']) // batch_size\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='checkpoints',\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=logging_steps,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "bl_trainer = Trainer(\n",
    "    args=args,\n",
    "    model= bl_model,\n",
    "    train_dataset=boolq_enc['train'],\n",
    "    eval_dataset=boolq_enc['validation'],\n",
    "    tokenizer=bl_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bl_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='7071' max='7071' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7071/7071 1:13:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659119</td>\n",
       "      <td>0.592962</td>\n",
       "      <td>0.692355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.543818</td>\n",
       "      <td>0.778216</td>\n",
       "      <td>0.759021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.281410</td>\n",
       "      <td>1.179402</td>\n",
       "      <td>0.787462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7071, training_loss=0.49457359432438136)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_trainer.save_model(\"models/bert-large-uncased-wwm-finetuned-boolq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune BERT-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_ckpt = \"bert-base-uncased\"\n",
    "bb_tokenizer = AutoTokenizer.from_pretrained(bb_ckpt)\n",
    "bb_model = AutoModelForSequenceClassification.from_pretrained(bb_ckpt).to(device)\n",
    "\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "num_train_epochs = 3\n",
    "logging_steps = len(boolq_enc['train']) // batch_size\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='checkpoints',\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=logging_steps,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=args,\n",
    "    model= bb_model,\n",
    "    train_dataset=boolq_enc['train'],\n",
    "    eval_dataset=boolq_enc['validation'],\n",
    "    tokenizer=bb_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [205/205 00:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7349509596824646, 'eval_accuracy': 0.3798165137614679}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1770' max='1770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1770/1770 21:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.651757</td>\n",
       "      <td>0.620844</td>\n",
       "      <td>0.661468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.552436</td>\n",
       "      <td>0.575712</td>\n",
       "      <td>0.703670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.414027</td>\n",
       "      <td>0.632376</td>\n",
       "      <td>0.713761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1770, training_loss=0.539351423716141)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"models/bert-base-uncased-finetuned-boolq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distill from BERT-large to BERT-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing we need to implement task-specific distillation is augment the standard cross-entropy loss with a distillation term (see above equation). We can implement this by overriding the `compute_loss` method of the `QuestionAnsweringTrainer`, but first let's define the training arguments we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha_ce=0.5, alpha_distil=0.5, temperature=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.alpha_ce = alpha_ce\n",
    "        self.alpha_distil = alpha_distil\n",
    "        self.temperature = temperature\n",
    "        self.disable_tqdm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the trainer, we'll need a few ingredients:\n",
    "\n",
    "* We need two models (a teacher and student), and since the `model` attribute is the one that is optimized, we'll just add an attribute for the teacher\n",
    "* When we pass the question and context to the student or teacher, we get a range of scores (logits) for the start and end positions. Since we want to minimize the distance between the teacher and student predictions , we'll use the KL-divergence as our distillation loss\n",
    "* Once the distillation loss is computed, we take a linear combination with the cross-entropy to obtain our final loss function\n",
    "\n",
    "The following code does the trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        self.teacher.eval()\n",
    "        \n",
    "    def compute_loss(self, model, inputs):\n",
    "        inputs_stu = {\n",
    "            \"input_ids\": inputs['input_ids'],\n",
    "            \"attention_mask\": inputs['attention_mask'],\n",
    "            \"token_type_ids\": inputs['token_type_ids'],\n",
    "            \"labels\": inputs['labels']\n",
    "            }\n",
    "        outputs_stu = model(**inputs_stu)\n",
    "        loss = outputs_stu.loss\n",
    "        logits_stu = outputs_stu.logits\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs_tea = self.teacher(\n",
    "                input_ids=inputs[\"input_ids\"], \n",
    "                token_type_ids=inputs[\"token_type_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                labels=inputs[\"labels\"])\n",
    "            logits_tea = outputs_tea.logits\n",
    "        assert logits_tea.size() == logits_stu.size()\n",
    "        \n",
    "        loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        loss_logits = (loss_fct(\n",
    "            F.log_softmax(logits_stu / self.args.temperature, dim=-1),\n",
    "            F.softmax(logits_tea / self.args.temperature, dim=-1)) * (self.args.temperature ** 2))\n",
    "        loss = self.args.alpha_distil * loss_logits + self.args.alpha_ce * loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then a similar process to configure and initialise the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "logging_steps = len(boolq_enc['train']) // batch_size\n",
    "\n",
    "student_training_args = DistillationTrainingArguments(\n",
    "    output_dir=f\"checkpoints\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_checkpoint = \"lewtun/bert-base-uncased-finetuned-squad-v1\"\n",
    "student_checkpoint = \"bert-base-uncased\"\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(teacher_checkpoint).to(device)\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(student_checkpoint).to(device)\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_checkpoint)\n",
    "\n",
    "distil_trainer = DistillationTrainer(\n",
    "    model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    args=student_training_args,\n",
    "    train_dataset=boolq_enc['train'],\n",
    "    eval_dataset=boolq_enc['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=student_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distil_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1770' max='1770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1770/1770 27:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.340498</td>\n",
       "      <td>0.596097</td>\n",
       "      <td>0.716820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303301</td>\n",
       "      <td>0.564495</td>\n",
       "      <td>0.741896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.271076</td>\n",
       "      <td>0.547016</td>\n",
       "      <td>0.755352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1770, training_loss=0.3049012473747555)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_trainer.save_model('models/bert-base-uncased-distilled-boolq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple benchmark, here we compare the time it takes for our teacher and student to generate 1,000 predictions on a CPU (to simulate a production environment). First, we load our fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_ckpt = 'lewtun/bert-base-uncased-distilled-boolq'\n",
    "teacher_model_ckpt = 'lewtun/bert-large-uncased-wwm-finetuned-boolq'\n",
    "\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_model_ckpt)\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(student_model_ckpt).to('cpu')\n",
    "\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_ckpt)\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(teacher_model_ckpt).to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create two pipelines for the student and teacher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_pipe = QuestionAnsweringPipeline(student_model, student_tokenizer)\n",
    "teacher_pipe = QuestionAnsweringPipeline(teacher_model, teacher_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then run the inference test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39min 55s, sys: 34.8 s, total: 40min 29s\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx in range(1000):\n",
    "    context = squad_ds['validation'][idx]['context']\n",
    "    question = squad_ds['validation'][idx]['question']\n",
    "    teacher_pipe(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 47s, sys: 13.3 s, total: 20min 1s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx in range(1000):\n",
    "    context = squad_ds['validation'][idx]['context']\n",
    "    question = squad_ds['validation'][idx]['question']\n",
    "    student_pipe(question=question, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this example, we see roughly a 2x speedup from using a distilled model with less than 3% drop in Exact Match / F1-score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
