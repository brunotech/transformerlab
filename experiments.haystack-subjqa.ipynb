{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/07/2021 09:42:10 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
      "03/07/2021 09:42:10 - INFO - faiss.loader -   Loading faiss.\n",
      "03/07/2021 09:42:11 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "from haystack.pipeline import ExtractiveQAPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books  electronics  grocery  movies  restaurants  tripadvisor\n"
     ]
    }
   ],
   "source": [
    "data = Path('./data/subjqa')\n",
    "!ls {data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>nn_mod</th>\n",
       "      <th>nn_asp</th>\n",
       "      <th>query_mod</th>\n",
       "      <th>query_asp</th>\n",
       "      <th>q_review_id</th>\n",
       "      <th>q_reviews_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_subj_level</th>\n",
       "      <th>ques_subj_score</th>\n",
       "      <th>is_ques_subjective</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>human_ans_spans</th>\n",
       "      <th>human_ans_indices</th>\n",
       "      <th>answer_subj_level</th>\n",
       "      <th>ans_subj_score</th>\n",
       "      <th>is_ans_subjective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0000BZOGJ</td>\n",
       "      <td>electronics</td>\n",
       "      <td>double</td>\n",
       "      <td>zipper</td>\n",
       "      <td>wide</td>\n",
       "      <td>strap</td>\n",
       "      <td>19d6980d862e90d9170006eaa8516e58</td>\n",
       "      <td>a26d5bd37e06bc8b284ceea6a1eab28d</td>\n",
       "      <td>What is strap?</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2e675cc6ca63d7052aa195f41fada781</td>\n",
       "      <td>I purchased this just this week, and while it holds myHP Pavilion DV9830US 1...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(1135, 1149)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0000BZOGJ</td>\n",
       "      <td>electronics</td>\n",
       "      <td>double</td>\n",
       "      <td>zipper</td>\n",
       "      <td>wide</td>\n",
       "      <td>strap</td>\n",
       "      <td>19d6980d862e90d9170006eaa8516e58</td>\n",
       "      <td>a26d5bd37e06bc8b284ceea6a1eab28d</td>\n",
       "      <td>What is strap?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2e675cc6ca63d7052aa195f41fada781</td>\n",
       "      <td>I purchased this just this week, and while it holds myHP Pavilion DV9830US 1...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(1135, 1149)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004T9RR6I</td>\n",
       "      <td>electronics</td>\n",
       "      <td>available</td>\n",
       "      <td>feature</td>\n",
       "      <td>major</td>\n",
       "      <td>issue</td>\n",
       "      <td>9272dfe044ca6bd7285e5e48ffe008a8</td>\n",
       "      <td>23c36d13271938c92b2eb22ebed15f73</td>\n",
       "      <td>Was it issue ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>52d167f982a274fd85d37903f857966f</td>\n",
       "      <td>UPDATE (26 June 2012):I got ready to add a USB storage device (Seagate 2TB) ...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(8416, 8430)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B004T9RR6I</td>\n",
       "      <td>electronics</td>\n",
       "      <td>available</td>\n",
       "      <td>feature</td>\n",
       "      <td>major</td>\n",
       "      <td>issue</td>\n",
       "      <td>9272dfe044ca6bd7285e5e48ffe008a8</td>\n",
       "      <td>23c36d13271938c92b2eb22ebed15f73</td>\n",
       "      <td>Was it issue ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>52d167f982a274fd85d37903f857966f</td>\n",
       "      <td>UPDATE (26 June 2012):I got ready to add a USB storage device (Seagate 2TB) ...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(8416, 8430)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004CLYEFK</td>\n",
       "      <td>electronics</td>\n",
       "      <td>thick</td>\n",
       "      <td>wire</td>\n",
       "      <td>enough</td>\n",
       "      <td>length</td>\n",
       "      <td>b67a9e235ed955a51d09c7f081a62cb5</td>\n",
       "      <td>86c3c5151f9afb17b8de96c6dfb37542</td>\n",
       "      <td>What is the length of the cable of a television ?</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>b1112cc98744b1dc26f6c9b80c2b97f0</td>\n",
       "      <td>What more can you say about Micra Digital USB A to USB B Cable other than it...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(199, 213)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id       domain     nn_mod   nn_asp query_mod query_asp  \\\n",
       "0  B0000BZOGJ  electronics     double   zipper      wide     strap   \n",
       "1  B0000BZOGJ  electronics     double   zipper      wide     strap   \n",
       "2  B004T9RR6I  electronics  available  feature     major     issue   \n",
       "3  B004T9RR6I  electronics  available  feature     major     issue   \n",
       "4  B004CLYEFK  electronics      thick     wire    enough    length   \n",
       "\n",
       "                        q_review_id                      q_reviews_id  \\\n",
       "0  19d6980d862e90d9170006eaa8516e58  a26d5bd37e06bc8b284ceea6a1eab28d   \n",
       "1  19d6980d862e90d9170006eaa8516e58  a26d5bd37e06bc8b284ceea6a1eab28d   \n",
       "2  9272dfe044ca6bd7285e5e48ffe008a8  23c36d13271938c92b2eb22ebed15f73   \n",
       "3  9272dfe044ca6bd7285e5e48ffe008a8  23c36d13271938c92b2eb22ebed15f73   \n",
       "4  b67a9e235ed955a51d09c7f081a62cb5  86c3c5151f9afb17b8de96c6dfb37542   \n",
       "\n",
       "                                            question  question_subj_level  \\\n",
       "0                                     What is strap?                    5   \n",
       "1                                     What is strap?                    1   \n",
       "2                                     Was it issue ?                    1   \n",
       "3                                     Was it issue ?                    1   \n",
       "4  What is the length of the cable of a television ?                    4   \n",
       "\n",
       "   ques_subj_score  is_ques_subjective                         review_id  \\\n",
       "0              0.0               False  2e675cc6ca63d7052aa195f41fada781   \n",
       "1              0.0               False  2e675cc6ca63d7052aa195f41fada781   \n",
       "2              0.0               False  52d167f982a274fd85d37903f857966f   \n",
       "3              0.0               False  52d167f982a274fd85d37903f857966f   \n",
       "4              0.0               False  b1112cc98744b1dc26f6c9b80c2b97f0   \n",
       "\n",
       "                                                                            review  \\\n",
       "0  I purchased this just this week, and while it holds myHP Pavilion DV9830US 1...   \n",
       "1  I purchased this just this week, and while it holds myHP Pavilion DV9830US 1...   \n",
       "2  UPDATE (26 June 2012):I got ready to add a USB storage device (Seagate 2TB) ...   \n",
       "3  UPDATE (26 June 2012):I got ready to add a USB storage device (Seagate 2TB) ...   \n",
       "4  What more can you say about Micra Digital USB A to USB B Cable other than it...   \n",
       "\n",
       "  human_ans_spans human_ans_indices  answer_subj_level  ans_subj_score  \\\n",
       "0  ANSWERNOTFOUND      (1135, 1149)                  1             0.0   \n",
       "1  ANSWERNOTFOUND      (1135, 1149)                  1             0.0   \n",
       "2  ANSWERNOTFOUND      (8416, 8430)                  1             0.0   \n",
       "3  ANSWERNOTFOUND      (8416, 8430)                  1             0.0   \n",
       "4  ANSWERNOTFOUND        (199, 213)                  4             0.0   \n",
       "\n",
       "   is_ans_subjective  \n",
       "0              False  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "4              False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df = pd.read_csv(data/'electronics/splits/test.csv')\n",
    "electronics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df[\"q_review_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1194"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df[\"q_reviews_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANSWERNOTFOUND                                                                  1399\n",
       "bass is solid and powerful                                                         3\n",
       "comfortable                                                                        3\n",
       "the sound quality is great                                                         3\n",
       "4 and 5 Star reviews                                                               2\n",
       "                                                                                ... \n",
       "speakers are too quiet                                                             1\n",
       "I do not give it 5 stars because the image quality is not full hd                  1\n",
       "accurate + bright display                                                          1\n",
       "The router took about 10 ' to install and has worked like a charm since then       1\n",
       "the resulting images will be very soft .   It sharpens up nicely by f/4            1\n",
       "Name: human_ans_spans, Length: 888, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df[\"human_ans_spans\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 19)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to SQuAD format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need this format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": \"Beyoncé\",\n",
    "            \"paragraphs\": [\n",
    "                {\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"question\": \"When did Beyonce start becoming popular?\",\n",
    "                            \"id\": \"56be85543aeaaa14008c9063\",\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": \"in the late 1990s\",\n",
    "                                    \"answer_start\": 269\n",
    "                                }\n",
    "                            ],\n",
    "                            \"is_impossible\": false\n",
    "                        }\n",
    "                        ...\n",
    "                    ],\n",
    "                    \"context\": \"Beyoncé ...\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                                                                                     B003VAGXWK\n",
       "domain                                                                                     electronics\n",
       "nn_mod                                                                                           sleek\n",
       "nn_asp                                                                                        keyboard\n",
       "query_mod                                                                                        solid\n",
       "query_asp                                                                                          key\n",
       "q_review_id                                                           73e8277fbf438a7ade8f720ddf8a4f47\n",
       "q_reviews_id                                                          55576d11e04159c488107b442aaff880\n",
       "question                                                            How are the keys of the  keyboard?\n",
       "question_subj_level                                                                                  1\n",
       "ques_subj_score                                                                                    0.0\n",
       "is_ques_subjective                                                                               False\n",
       "review_id                                                             74ae92c2bbeb9511fce8ddb5a4b9411b\n",
       "review                 I was reluctant to try a wireless keyboard, but due to a wire-chomping kitty...\n",
       "human_ans_spans                                                       The illuminated keys are helpful\n",
       "human_ans_indices                                                                           (421, 453)\n",
       "answer_subj_level                                                                                    1\n",
       "ans_subj_score                                                                                     0.0\n",
       "is_ans_subjective                                                                                False\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at single row\n",
    "row = electronics_df.query(\"human_ans_spans != 'ANSWERNOTFOUND'\").iloc[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we could have the following field mappings:\n",
    "\n",
    "* title -> item_id\n",
    "* question -> question\n",
    "* id -> q_review_id\n",
    "* answers -> human_ans_spans\n",
    "* answer_start -> first element of human_ans_indices\n",
    "* is_impossible -> if human_ans_spans == ANSWERNOTFOUND\n",
    "* context -> review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby `item_id` and build data structure from that? First build up paragraphs from row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 453)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(row[\"human_ans_indices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'qas': [{'question': 'How are the keys of the  keyboard?',\n",
       "    'id': '73e8277fbf438a7ade8f720ddf8a4f47',\n",
       "    'answers': [{'text': 'The illuminated keys are helpful',\n",
       "      'answer_start': 421}],\n",
       "    'is_impossible': False}],\n",
       "  'context': \"I was reluctant to try a wireless keyboard, but due to a wire-chomping kitty, decided it was best to go wireless. I'm so glad I did. This keyboard is sleek and stylish. It has a great feel under my fingertips. I was concerned that a wireless keyboard would be &#34;buggy&#34; and not be efficient, but this keyboard is as good as any corded keyboard. It charges easily via USB port and holds a charge for about ten days. The illuminated keys are helpful, if, like me, your eyes aren't as young as they once were. I already had the logitech unifying plug that plugs into my computer for my mouse and touchpad. I turned the keyboard on and the Logitech plug recognized it right away. I highly recommend this keyboard. ANSWERNOTFOUND\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars = [\n",
    "    {\"qas\": \n",
    "     [\n",
    "         {\"question\": row[\"question\"], \n",
    "          \"id\": row[\"q_review_id\"], \n",
    "          \"answers\": [\n",
    "              {\"text\": row[\"human_ans_spans\"], \n",
    "               \"answer_start\": eval(row[\"human_ans_indices\"])[0]}\n",
    "          ], \n",
    "          \"is_impossible\": True if row[\"human_ans_spans\"] == \"ANSWERNOTFOUND\" else False}],\n",
    "     \"context\": row[\"review\"]\n",
    "    }]\n",
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>nn_mod</th>\n",
       "      <th>nn_asp</th>\n",
       "      <th>query_mod</th>\n",
       "      <th>query_asp</th>\n",
       "      <th>q_review_id</th>\n",
       "      <th>q_reviews_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_subj_level</th>\n",
       "      <th>ques_subj_score</th>\n",
       "      <th>is_ques_subjective</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>human_ans_spans</th>\n",
       "      <th>human_ans_indices</th>\n",
       "      <th>answer_subj_level</th>\n",
       "      <th>ans_subj_score</th>\n",
       "      <th>is_ans_subjective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B006ZS5ATM</td>\n",
       "      <td>electronics</td>\n",
       "      <td>sore</td>\n",
       "      <td>ear</td>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>headphone</td>\n",
       "      <td>adb20314dbbd8196b7e9fb587b78147f</td>\n",
       "      <td>6e1052529424f3a98d303380155c9dde</td>\n",
       "      <td>What do you think about headphone?</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>197e760a49907baeff809b2ccdfe466f</td>\n",
       "      <td>I had a smaller headset that went on the ear. After a 8 - 10 hour workday, m...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(547, 561)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id       domain nn_mod nn_asp      query_mod  query_asp  \\\n",
       "0  B006ZS5ATM  electronics   sore    ear  uncomfortable  headphone   \n",
       "\n",
       "                        q_review_id                      q_reviews_id  \\\n",
       "0  adb20314dbbd8196b7e9fb587b78147f  6e1052529424f3a98d303380155c9dde   \n",
       "\n",
       "                             question  question_subj_level  ques_subj_score  \\\n",
       "0  What do you think about headphone?                    5              0.0   \n",
       "\n",
       "   is_ques_subjective                         review_id  \\\n",
       "0               False  197e760a49907baeff809b2ccdfe466f   \n",
       "\n",
       "                                                                            review  \\\n",
       "0  I had a smaller headset that went on the ear. After a 8 - 10 hour workday, m...   \n",
       "\n",
       "  human_ans_spans human_ans_indices  answer_subj_level  ans_subj_score  \\\n",
       "0  ANSWERNOTFOUND        (547, 561)                  5             0.0   \n",
       "\n",
       "   is_ans_subjective  \n",
       "0              False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = electronics_df.query(\"item_id == 'B006ZS5ATM' | item_id == 'B0074BW614'\")\n",
    "sample_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 19)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "B006ZS5ATM      5\n",
       "B0074BW614    103\n",
       "Name: q_review_id, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.groupby('item_id')['q_review_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paragraphs(group):\n",
    "    pars = []\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        qas = {\"qas\": \n",
    "               [\n",
    "                 {\"question\": row[\"question\"], \n",
    "                  \"id\": row[\"q_review_id\"], \n",
    "                  \"answers\": [\n",
    "                      {\"text\": row[\"answers_text\"], \n",
    "                       \"answer_start\": eval(row[\"human_ans_indices\"])[0]}\n",
    "                  ], \n",
    "                  \"is_impossible\": True if row[\"answers_text\"] == \"ANSWERNOTFOUND\" else False}],\n",
    "             \"context\": row[\"review\"]\n",
    "            }\n",
    "        pars.append(qas)\n",
    "        \n",
    "    return pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = electronics_df.groupby('item_id').apply(create_paragraphs).to_frame(name=\"paragraphs\").reset_index().rename(columns={\"item_id\":'title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00001P4ZH</td>\n",
       "      <td>[{'qas': [{'question': 'How is the bass?', 'id': '2543d296da9766d8d17d040ecc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00001WRSJ</td>\n",
       "      <td>[{'qas': [{'question': 'How is the audio bass?', 'id': '6895a59b470d8feee0f3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00004SABB</td>\n",
       "      <td>[{'qas': [{'question': 'How is the time?', 'id': '47110eb7720cffd03bb78f6099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00004SB92</td>\n",
       "      <td>[{'qas': [{'question': 'Is documentation clear?', 'id': '7af7e66deeecf69fc6e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00004T8R2</td>\n",
       "      <td>[{'qas': [{'question': 'How is the sound?', 'id': '54f67a1452a33068b8a6a93bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>B00GH0N1LM</td>\n",
       "      <td>[{'qas': [{'question': 'How do I get to the port?', 'id': '96bd81889288ed5d2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>B00GP4BVTO</td>\n",
       "      <td>[{'qas': [{'question': 'How about profile?', 'id': '12264045ff398038d51f77c3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>B00H3OYSHW</td>\n",
       "      <td>[{'qas': [{'question': 'Where can I feel my device?', 'id': 'e0ea72e711324b5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>B00HNGB1YS</td>\n",
       "      <td>[{'qas': [{'question': 'How is the grip?', 'id': 'a541ffd9697ebf0ad9d2264285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>B00HPM1G8Q</td>\n",
       "      <td>[{'qas': [{'question': 'How is the keyboard?', 'id': '7efc5e7ffaa79f53cc50f7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          title  \\\n",
       "0    B00001P4ZH   \n",
       "1    B00001WRSJ   \n",
       "2    B00004SABB   \n",
       "3    B00004SB92   \n",
       "4    B00004T8R2   \n",
       "..          ...   \n",
       "429  B00GH0N1LM   \n",
       "430  B00GP4BVTO   \n",
       "431  B00H3OYSHW   \n",
       "432  B00HNGB1YS   \n",
       "433  B00HPM1G8Q   \n",
       "\n",
       "                                                                          paragraphs  \n",
       "0    [{'qas': [{'question': 'How is the bass?', 'id': '2543d296da9766d8d17d040ecc...  \n",
       "1    [{'qas': [{'question': 'How is the audio bass?', 'id': '6895a59b470d8feee0f3...  \n",
       "2    [{'qas': [{'question': 'How is the time?', 'id': '47110eb7720cffd03bb78f6099...  \n",
       "3    [{'qas': [{'question': 'Is documentation clear?', 'id': '7af7e66deeecf69fc6e...  \n",
       "4    [{'qas': [{'question': 'How is the sound?', 'id': '54f67a1452a33068b8a6a93bf...  \n",
       "..                                                                               ...  \n",
       "429  [{'qas': [{'question': 'How do I get to the port?', 'id': '96bd81889288ed5d2...  \n",
       "430  [{'qas': [{'question': 'How about profile?', 'id': '12264045ff398038d51f77c3...  \n",
       "431  [{'qas': [{'question': 'Where can I feel my device?', 'id': 'e0ea72e711324b5...  \n",
       "432  [{'qas': [{'question': 'How is the grip?', 'id': 'a541ffd9697ebf0ad9d2264285...  \n",
       "433  [{'qas': [{'question': 'How is the keyboard?', 'id': '7efc5e7ffaa79f53cc50f7...  \n",
       "\n",
       "[434 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups.iloc[1][\"paragraphs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'B006ZS5ATM',\n",
       " 'paragraphs': [{'qas': [{'question': 'What do you think about headphone?',\n",
       "     'id': 'adb20314dbbd8196b7e9fb587b78147f',\n",
       "     'answers': [{'text': 'ANSWERNOTFOUND', 'answer_start': 547}],\n",
       "     'is_impossible': True}],\n",
       "   'context': \"I had a smaller headset that went on the ear. After a 8 - 10 hour workday, my ears were throbbing red and painfully sore. With this headset, I can go the same shift and not feel any pain on my ear. They may feel a little on the heavy side, but if you adjust the head phone cups just right and stretch them, you will not have any problems.Quality and sound, words cannot explain. Its so clear and loud, the headset holds in the sound. When I am on a call or listening to music, I do not hear nothing else, but what's coming in through the headset. ANSWERNOTFOUND\"},\n",
       "  {'qas': [{'question': 'What is the sound quality?',\n",
       "     'id': 'a3cd9be41531e7f23a9882c2a3cb15d4',\n",
       "     'answers': [{'text': 'Sound quality is awesome', 'answer_start': 490}],\n",
       "     'is_impossible': False}],\n",
       "   'context': \"So I was looking for a decent headset for pretty cheap, looked on Google to see the best headsets and these were #1, I figured i'd get them because they seemed decent and for pretty cheap. After I ordered them I saw a review saying that they don't work with Windows 8, I have Windows 8 so I started worrying about them. I got them and just as the comment said, they weren't working, so I looked up what to do and found solutions really easily online, now they work perfectly and amazingly. Sound quality is awesome. 7.1 in headphones?!?!?! Deal me in! They really are as comfortable as they look, build quality is just as nice, and the Mic is super clear. So if you're looking for a decent headset for pretty cheap, go with these :) ANSWERNOTFOUND\"},\n",
       "  {'qas': [{'question': 'What is the sound quality?',\n",
       "     'id': 'a3cd9be41531e7f23a9882c2a3cb15d4',\n",
       "     'answers': [{'text': 'Sound quality is awesome', 'answer_start': 490}],\n",
       "     'is_impossible': False}],\n",
       "   'context': \"So I was looking for a decent headset for pretty cheap, looked on Google to see the best headsets and these were #1, I figured i'd get them because they seemed decent and for pretty cheap. After I ordered them I saw a review saying that they don't work with Windows 8, I have Windows 8 so I started worrying about them. I got them and just as the comment said, they weren't working, so I looked up what to do and found solutions really easily online, now they work perfectly and amazingly. Sound quality is awesome. 7.1 in headphones?!?!?! Deal me in! They really are as comfortable as they look, build quality is just as nice, and the Mic is super clear. So if you're looking for a decent headset for pretty cheap, go with these :) ANSWERNOTFOUND\"},\n",
       "  {'qas': [{'question': 'What do you think about headphone?',\n",
       "     'id': 'adb20314dbbd8196b7e9fb587b78147f',\n",
       "     'answers': [{'text': 'ANSWERNOTFOUND', 'answer_start': 547}],\n",
       "     'is_impossible': True}],\n",
       "   'context': \"I had a smaller headset that went on the ear. After a 8 - 10 hour workday, my ears were throbbing red and painfully sore. With this headset, I can go the same shift and not feel any pain on my ear. They may feel a little on the heavy side, but if you adjust the head phone cups just right and stretch them, you will not have any problems.Quality and sound, words cannot explain. Its so clear and loud, the headset holds in the sound. When I am on a call or listening to music, I do not hear nothing else, but what's coming in through the headset. ANSWERNOTFOUND\"},\n",
       "  {'qas': [{'question': 'How is the sound quality of these plantronics microphone ?',\n",
       "     'id': '96406c29b0298769a44ccec56cce38bb',\n",
       "     'answers': [{'text': 'The sound quality is very decent',\n",
       "       'answer_start': 525}],\n",
       "     'is_impossible': False}],\n",
       "   'context': \"Decent sound, but there are negatives to considerThe quality of the construction and materials seems average. I would prefer if they were a little better built, but they're acceptable for the price. The fabric used on the ear pieces and the head padding is the same fabric they use in fabric lint rollers. It's soft enough, but collects lint accordingly. The mic boom is flexible rubber and decent quality, but it doesn't allow you to adjust its location in and out and sits further from the mouth than expected.Pros:Sound - The sound quality is very decent. I'm not an audiophile so take it with a grain of salt, but both games and music are quite enjoyable for me with this headset.Comfort - At first I found these uncomfortable and pinching which after an hour of use caused significant discomfort. However, once I lowered the ear pieces to wear this a bit loose (more loose than I normally prefer headphones) they fit much better. After hours of use they are still comfortable for me.Microphone - The mic is very sensitive and picks up sound really well.Cons:USB - The USB interface is one you want to avoid for headsets if you have a good soundcard. USB headsets include their own audio card built-in to the device in order to work. Therefore, using these will bypass the soundcard in your computer.  Also, the USB cable is quite short. This device isn't compatible with USB 3.0. Since I only have 3.0 on the front panel of my computer I would prefer a longer cord to run it from the back.Dolby - The simulated 7.1 is not appealing to me. It simulates surround by making the audio more `spatial'. This doesn't add to the audio quality though; it makes the sound worse in my opinion. The default setting is off,Volume Control - The volume control is a rocker switch in a convenient location on the back of the left ear-piece. The rocker switch is annoying. You rotate and hold it in one direction or the other to change the volume. I would prefer a dial instead of holding a switch.No Audio Controls - This device has no equalizer to adjust the audio. The audio levels it ships with is okay, but if you wanted to customize your sound you should purchase a different headset.Microphone - The mic is overly sensitive and even on low input volumes it picks up any background noise like you mouse and keyboard, breathing, etc.In summary, decent sound and comfort for the price, but has some limitations. ANSWERNOTFOUND\"}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.to_dict(orient='records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_data = {}\n",
    "squad_data[\"data\"] = groups.to_dict(orient='records')\n",
    "\n",
    "with open(\"data/subjqa/squad_format/electronics-test.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(squad_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/07/2021 11:00:07 - INFO - farm.utils -   Using device: CUDA \n",
      "03/07/2021 11:00:07 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/07/2021 11:00:07 - INFO - farm.utils -   Distributed Training: False\n",
      "03/07/2021 11:00:07 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/07/2021 11:00:21 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/07/2021 11:00:21 - INFO - farm.utils -   Using device: CUDA \n",
      "03/07/2021 11:00:21 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/07/2021 11:00:21 - INFO - farm.utils -   Distributed Training: False\n",
      "03/07/2021 11:00:21 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/07/2021 11:00:21 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/07/2021 11:00:21 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/07/2021 11:00:21 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/07/2021 11:00:21 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/07/2021 11:00:21 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True, context_window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>nn_mod</th>\n",
       "      <th>nn_asp</th>\n",
       "      <th>query_mod</th>\n",
       "      <th>query_asp</th>\n",
       "      <th>q_review_id</th>\n",
       "      <th>q_reviews_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_subj_level</th>\n",
       "      <th>ques_subj_score</th>\n",
       "      <th>is_ques_subjective</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>human_ans_spans</th>\n",
       "      <th>human_ans_indices</th>\n",
       "      <th>answer_subj_level</th>\n",
       "      <th>ans_subj_score</th>\n",
       "      <th>is_ans_subjective</th>\n",
       "      <th>answers_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>B0074BW614</td>\n",
       "      <td>electronics</td>\n",
       "      <td>solid</td>\n",
       "      <td>device</td>\n",
       "      <td>fast</td>\n",
       "      <td>processor</td>\n",
       "      <td>1a320a21598606afa533700b395eb71b</td>\n",
       "      <td>54a47a3867b408360b40b58eb93c1de0</td>\n",
       "      <td>How is processor?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>c687cef56ac10872ef5d0ae0869650db</td>\n",
       "      <td>I've been an iPad user since the original came out. I also have an iPad 3. I...</td>\n",
       "      <td>think great</td>\n",
       "      <td>(2476, 2497)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>think this is a great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       domain nn_mod  nn_asp query_mod  query_asp  \\\n",
       "729  B0074BW614  electronics  solid  device      fast  processor   \n",
       "\n",
       "                          q_review_id                      q_reviews_id  \\\n",
       "729  1a320a21598606afa533700b395eb71b  54a47a3867b408360b40b58eb93c1de0   \n",
       "\n",
       "              question  question_subj_level  ques_subj_score  \\\n",
       "729  How is processor?                    1              0.0   \n",
       "\n",
       "     is_ques_subjective                         review_id  \\\n",
       "729               False  c687cef56ac10872ef5d0ae0869650db   \n",
       "\n",
       "                                                                              review  \\\n",
       "729  I've been an iPad user since the original came out. I also have an iPad 3. I...   \n",
       "\n",
       "    human_ans_spans human_ans_indices  answer_subj_level  ans_subj_score  \\\n",
       "729     think great      (2476, 2497)                  1            0.75   \n",
       "\n",
       "     is_ans_subjective           answers_text  \n",
       "729               True  think this is a great  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.query(\"human_ans_spans == 'think great'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'think this is a great '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.query(\"human_ans_spans == 'think great'\").iloc[0][\"review\"][2476:2498]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_answer_spans(row):\n",
    "    start_idx, end_idx = eval(row[\"human_ans_indices\"])\n",
    "    return row[\"review\"][start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df[\"answers_text\"] = electronics_df.apply(create_answer_spans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ANSWERNOTFOUND\n",
       "1       ANSWERNOTFOUND\n",
       "24      ANSWERNOTFOUND\n",
       "45      ANSWERNOTFOUND\n",
       "51      ANSWERNOTFOUND\n",
       "             ...      \n",
       "2272    ANSWERNOTFOUND\n",
       "2283    ANSWERNOTFOUND\n",
       "2286              32GB\n",
       "2333    ANSWERNOTFOUND\n",
       "2334    ANSWERNOTFOUND\n",
       "Name: answers_text, Length: 108, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df[\"answers_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/subjqa/squad_format/electronics-test.json: 100%|██████████| 718/718 [00:01<00:00, 405.97 Dicts/s]\n",
      "Evaluating: 100%|██████████| 35/35 [00:19<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "reader_eval_results = reader.eval_on_file(\"data/subjqa/squad_format/\", \"electronics-test.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.7047353760445683\n",
      "Reader Exact Match: 0.2395543175487465\n",
      "Reader F1-Score: 0.30428376775021326\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.7961620469083156\n",
      "Reader Exact Match: 0.3390191897654584\n",
      "Reader F1-Score: 0.409314521578848\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boot ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -nc https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
    "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
    "! chown -R daemon:daemon elasticsearch-7.9.2\n",
    "\n",
    "es_server = Popen(['elasticsearch-7.9.2/bin/elasticsearch'],\n",
    "                   stdout=PIPE, stderr=STDOUT,\n",
    "                   preexec_fn=lambda: os.setuid(1)  # as daemon\n",
    "                  )\n",
    "# wait until ES has started\n",
    "! sleep 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/ [status:200 request:0.094s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.011s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.004s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.024s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.002s]\n"
     ]
    }
   ],
   "source": [
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/04/2021 21:20:03 - INFO - elasticsearch -   POST http://localhost:9200/document/_delete_by_query [status:200 request:0.970s]\n"
     ]
    }
   ],
   "source": [
    "document_store.delete_all_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Works perfectly and easy to use. Software download also great.The only surprise was that the one I ordered, (USB) doesn't work with an iPad.I was thinking it would work with both PC and iPad. My mistake. I use this with Logic Pro X on an iMac running Mavericks (it's replacing an Mbox) and with a Sony Vaio running Windows 7 and get excellent results (don't forget to install the Windows drivers or you'll run into latency issues). I also use it with the Auria App on my iPad Air. I did appreciate the direct line in switch...I could hear exactly what was being played into the unit without having to route through the computer. That was a nice feature. More recently, I was very happy to get this working with my ipad mini. I did purchase a recommended usb powered hub Belkin model &#34; F4U020&#34; and with that - I'm good to play music into and out of my ipad. Focusrite. An industry standard.I bought this specifically for use with an iPad to do mobile recording. The app I use is Auria, but GarageBand will work as well. Be sure to use/buy a POWERED USB hub in order to power the Scarlett.Wonderfully quiet device. Simple to use and the mic/instrument inputs are very warm sounding. It is truly shocking to see that you can achieve some VERY convincing, near commercial grade recording with this interface. Mac OS X 10.8.42: UpdateAmazon didn't sent me a 3rd replacement. And I'm really glad they didn't. I ended up saving a lot of money and buyingApogee Duet Audio Interface for iPad & Mac. After using Duet, I can tell you that any sound interface priced between 60 to 200 are the same thing. You may as well buy the simplest cheapest sound interface instead of this show off failure.I am very very VERY surprised about how many stars this product has. when i conect the headphones into the interface and give a test, i cant hear a suitable volume, i hear it very low; and if i increase the volume, this saturated.. very good this is honestly the best interface I've used for recording. this is a must but item you won't regret it. this is a beautiful piece of hardware. sounds really good. easy to use. and the director monitor function is great. the software that came with it is outdated and does not support Mavericks. however, I got on the help line and the gentlemen pointed me to a program called reaper that helped install the software so that I can take full advantage of it's benefits.Other than that! It's GREAT! and I love recording my guitar on it. Clean with no noise.\",\n",
       " 'meta': {'asin': 'B005OZE9SA', 'is_answerable': 1}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [{\"text\": row[\"text\"], \"meta\":{\"asin\": row[\"asin\"], \"is_answerable\": row[\"is_answerable\"]}} for _, row in qa_df.iterrows()]\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 15:11:02 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.124s]\n",
      "03/05/2021 15:11:04 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.382s]\n",
      "03/05/2021 15:11:05 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.381s]\n",
      "03/05/2021 15:11:06 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.281s]\n",
      "03/05/2021 15:11:08 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.237s]\n",
      "03/05/2021 15:11:09 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.254s]\n",
      "03/05/2021 15:11:10 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.260s]\n",
      "03/05/2021 15:11:12 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.275s]\n",
      "03/05/2021 15:11:13 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.273s]\n",
      "03/05/2021 15:11:14 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.272s]\n",
      "03/05/2021 15:11:16 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.264s]\n",
      "03/05/2021 15:11:17 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.276s]\n",
      "03/05/2021 15:11:18 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.331s]\n",
      "03/05/2021 15:11:20 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.288s]\n",
      "03/05/2021 15:11:21 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.285s]\n",
      "03/05/2021 15:11:22 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.257s]\n",
      "03/05/2021 15:11:24 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.265s]\n",
      "03/05/2021 15:11:25 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.238s]\n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 10:59:24 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/06/2021 10:59:42 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True, context_window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/squad/dev-v2.0.json: 100%|██████████| 1204/1204 [00:07<00:00, 162.32 Dicts/s]\n",
      "Evaluating: 100%|██████████| 274/274 [02:36<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# check evaluation on SQuAD v2\n",
    "reader_eval_results = reader.eval_on_file(\"data/squad\", \"dev-v2.0.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.9746483618293608\n",
      "Reader Exact Match: 0.7843005137707403\n",
      "Reader F1-Score: 0.8260896852846605\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1150/1150 [00:03<00:00, 371.15 Dicts/s]\n",
      "Evaluating: 100%|██████████| 133/133 [01:17<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# check evaluation on AmazonQA\n",
    "reader_eval_results = reader.eval_on_file(\"data/amazon-qa\", \"val-qar_squad-music.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.542608695652174\n",
      "Reader Exact Match: 0.0008695652173913044\n",
      "Reader F1-Score: 0.0752376647890378\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 14:39:19 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.088s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.25 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.14 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.83 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.97 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.93 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.88 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.86 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is a snare included?\n",
      "\n",
      "\n",
      "#1\n",
      "Answer: this one only came with one\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: the correct sounds out of it. When I slapped the \"bass\", it would play a \"snare\" sound combined with the bass. When I slapped the \"snare\", I would just get a wood sound.I've also seen images that most cajons come with multiple snares... this one only came with one.I'm really not sure what else to say. I wanted a Cajon to play with.but didn't want to pay 100.00 plus. This was a great option, Easy to put together with the limited tools I had on hand. And cheap enough that I wasn't worried to have \n",
      "\n",
      "\n",
      "\n",
      "#2\n",
      "Answer: this one only came with one\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: the correct sounds out of it. When I slapped the \"bass\", it would play a \"snare\" sound combined with the bass. When I slapped the \"snare\", I would just get a wood sound.I've also seen images that most cajons come with multiple snares... this one only came with one.I'm really not sure what else to say. I wanted a Cajon to play with.but didn't want to pay 100.00 plus. This was a great option, Easy to put together with the limited tools I had on hand. And cheap enough that I wasn't worried to have \n",
      "\n",
      "\n",
      "\n",
      "#3\n",
      "Answer: minimal snare sound\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: ussionist but a terrible wood worker so my husband built this for me. He said it was super easy and did not require a lot of tools. I've stained it black and added silver glitter paint and it looks snazzy. My only complaint is that it has a minimal snare sound. If you are a real percussionist, before you build this you may want to get some snare wires if you want more of a snare sound. I knew going in this would not be easy to put together. I tried to do as much research as possible, but... if y\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Is a snare included?\"\n",
    "# DIY drumkit\n",
    "asin = \"B009VDW4OW\"\n",
    "number_of_answers_to_fetch = 3\n",
    "\n",
    "prediction = pipe.run(query=query, filters={\"asin\": [asin]}, top_k_retriever=10, top_k_reader=number_of_answers_to_fetch)\n",
    "print(f\"Question: {prediction['query']}\")\n",
    "print(\"\\n\")\n",
    "for i in range(number_of_answers_to_fetch):\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Answer: {prediction['answers'][i]['answer']}\")\n",
    "    print(f\"ASIN: {prediction['answers'][i]['meta']['asin']}\")\n",
    "    print(f\"Is answerable?: {prediction['answers'][i]['meta']['is_answerable']}\")\n",
    "    print(f\"Context: {prediction['answers'][i]['context']}\")\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to the true SQuAD format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with our SQuAD dataset is that it is composed of _line-separated_ JSON instead of the single JSON object that SQuAD traditionally uses. So instead of having examples like \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"context\": \"blah blah\",\n",
    "    \"qas\": [\n",
    "        {\n",
    "            \"id\": 331392,\n",
    "            \"is_impossible\": false,\n",
    "            \"question\": \"blah blah?\",\n",
    "            \"answers\": [\n",
    "                {\n",
    "                    \"answer_start\": 2881,\n",
    "                    \"text\": \"blah blah\"\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            \"human_answers\": [\n",
    "                \"blah blah\",\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "what we really need is a JSON of the form\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": \"Beyoncé\",\n",
    "            \"paragraphs\": [\n",
    "                {\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"question\": \"When did Beyonce start becoming popular?\",\n",
    "                            \"id\": \"56be85543aeaaa14008c9063\",\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": \"in the late 1990s\",\n",
    "                                    \"answer_start\": 269\n",
    "                                }\n",
    "                            ],\n",
    "                            \"is_impossible\": false\n",
    "                        }\n",
    "                        ...\n",
    "                    ],\n",
    "                    \"context\": \"Beyoncé ...\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Let's write a function that does the conversion for us. To warm-up let's load a single example from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "with open(data/\"train-qar_squad.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        qid = ex[\"qas\"][0][\"id\"]\n",
    "        asin = qid2asin[qid]\n",
    "        if asin == \"B0057JCYYE\" or asin == \"B00F9ECDRU\":\n",
    "            examples.append(ex)\n",
    "        if len(examples) > 4:\n",
    "            break\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the human answers, but we do need the mapping from `qid` to `asin` so that we can collect all questions together that belong to the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin2qas = {}\n",
    "seen_asin = set()\n",
    "\n",
    "for ex in examples:\n",
    "    qid = ex[\"qas\"][0][\"id\"]\n",
    "    asin = qid2asin[qid]\n",
    "    qas = [{k:v for k,v in ex[\"qas\"][0].items() if k != \"human_answers\"}]\n",
    "    par = [{\"qas\": qas, \"context\": ex[\"context\"]}]\n",
    "\n",
    "    if asin in seen_asin:\n",
    "        asin2qas[asin].extend(par)\n",
    "    else:\n",
    "        asin2qas[asin] = par\n",
    "        seen_asin.add(asin)\n",
    "\n",
    "\n",
    "# asin2qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_data = []\n",
    "\n",
    "for k,v in asin2qas.items():\n",
    "    squad_ex = {}\n",
    "    squad_ex[\"title\"] = k\n",
    "    squad_ex[\"paragraphs\"] = v\n",
    "    squad_data.append(squad_ex)\n",
    "    \n",
    "squad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dict = {\"data\": squad_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data/\"train-qar_squad.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(squad_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out answer fields\n",
    "with open(data/\"val-qar_squad.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['answers_snippet_spans_bleu2',\n",
       " 'answers_snippet_spans_bleu4',\n",
       " 'answers_snippet_spans_rouge',\n",
       " 'answers_sentence_ir',\n",
       " 'answers_sentence_bleu2',\n",
       " 'answers_sentence_bleu4']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in ex[\"qas\"][0].keys() if k.startswith(\"answers\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_squad_format(input_file: Path, output_file: Path, category: str = \"Musical_Instruments\"):\n",
    "    squad_data = []\n",
    "    asin2qas = {}\n",
    "    seen_asin = set()\n",
    "    answer_fields = ['answers_snippet_spans_bleu2', 'answers_snippet_spans_bleu4',  \n",
    "                     'answers_snippet_spans_rouge', 'answers_sentence_ir', \n",
    "                     'answers_sentence_bleu2',  'answers_sentence_bleu4']\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for _, line in tqdm(enumerate(f)):\n",
    "            row = json.loads(line)\n",
    "            qid = row[\"qas\"][0][\"id\"]\n",
    "            if qid2category[qid] == category:\n",
    "                asin = qid2asin[qid]\n",
    "                qas = [{\"answers\" if k in answer_fields else k:v for k,v in row[\"qas\"][0].items()}]\n",
    "                par = [{\"qas\": qas, \"context\": row[\"context\"]}]\n",
    "                \n",
    "                if asin in seen_asin:\n",
    "                    asin2qas[asin].extend(par)\n",
    "                else:\n",
    "                    asin2qas[asin] = par\n",
    "                    seen_asin.add(asin)\n",
    "                    \n",
    "    for k,v in asin2qas.items():\n",
    "        squad_ex = {}\n",
    "        squad_ex[\"title\"] = k\n",
    "        squad_ex[\"paragraphs\"] = v\n",
    "        squad_data.append(squad_ex)\n",
    "\n",
    "    squad_dict = {\"data\": squad_data}\n",
    "        \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(squad_dict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "455931it [00:13, 34990.08it/s]\n"
     ]
    }
   ],
   "source": [
    "category = \"Electronics\"\n",
    "convert_to_squad_format(data/'train-qar_squad.jsonl', data/f'train-qar_squad-{category.lower()}.json', category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58969it [00:03, 15988.79it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_squad_format(data/'val-qar_squad.jsonl', data/f'val-qar_squad-{category.lower()}.json', category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_json(data/'train-qar_squad-electronics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'B00009R95M', 'paragraphs': [{'qas': [{'id': 604553, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'B0051GN8GQ', 'paragraphs': [{'qas': [{'id': 698250, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'B00CQ35HBQ', 'paragraphs': [{'qas': [{'id': 639762, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'B00BOYQH44', 'paragraphs': [{'qas': [{'id': 701290, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'B008HODL7K', 'paragraphs': [{'qas': [{'id': 319235, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25296</th>\n",
       "      <td>{'title': 'B005LLFY5Y', 'paragraphs': [{'qas': [{'id': 212671, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25297</th>\n",
       "      <td>{'title': 'B0053QC0EU', 'paragraphs': [{'qas': [{'id': 596763, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25298</th>\n",
       "      <td>{'title': 'B0068PVBLS', 'paragraphs': [{'qas': [{'id': 525680, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25299</th>\n",
       "      <td>{'title': 'B009I9MX5Y', 'paragraphs': [{'qas': [{'id': 632546, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25300</th>\n",
       "      <td>{'title': 'B0097F1LW0', 'paragraphs': [{'qas': [{'id': 193506, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25301 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  data\n",
       "0      {'title': 'B00009R95M', 'paragraphs': [{'qas': [{'id': 604553, 'is_impossibl...\n",
       "1      {'title': 'B0051GN8GQ', 'paragraphs': [{'qas': [{'id': 698250, 'is_impossibl...\n",
       "2      {'title': 'B00CQ35HBQ', 'paragraphs': [{'qas': [{'id': 639762, 'is_impossibl...\n",
       "3      {'title': 'B00BOYQH44', 'paragraphs': [{'qas': [{'id': 701290, 'is_impossibl...\n",
       "4      {'title': 'B008HODL7K', 'paragraphs': [{'qas': [{'id': 319235, 'is_impossibl...\n",
       "...                                                                                ...\n",
       "25296  {'title': 'B005LLFY5Y', 'paragraphs': [{'qas': [{'id': 212671, 'is_impossibl...\n",
       "25297  {'title': 'B0053QC0EU', 'paragraphs': [{'qas': [{'id': 596763, 'is_impossibl...\n",
       "25298  {'title': 'B0068PVBLS', 'paragraphs': [{'qas': [{'id': 525680, 'is_impossibl...\n",
       "25299  {'title': 'B009I9MX5Y', 'paragraphs': [{'qas': [{'id': 632546, 'is_impossibl...\n",
       "25300  {'title': 'B0097F1LW0', 'paragraphs': [{'qas': [{'id': 193506, 'is_impossibl...\n",
       "\n",
       "[25301 rows x 1 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either something is wrong with my data preparation or getting the model to generalise is _hard_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 14:57:00 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 14:57:10 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", use_gpu=True, context_window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"data/amazon-qa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 14:57:17 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-electronics.json:  88%|████████▊ | 96000/108614 [01:36<00:11, 1131.67 Dicts/s]Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-electronics.json: 100%|██████████| 108614/108614 [01:41<00:00, 1068.48 Dicts/s]\n",
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-electronics.json: 100%|██████████| 13647/13647 [00:15<00:00, 889.83 Dicts/s] \n",
      "03/06/2021 14:59:31 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_training_steps': 8551, 'num_warmup_steps': 1710}'\n",
      "Train epoch 0/0 (Cur. train loss: 2.1635):   5%|▍         | 421/8551 [06:50<2:12:16,  1.02it/s]"
     ]
    }
   ],
   "source": [
    "reader.train(data_dir=train_data, \n",
    "             train_filename=\"train-qar_squad-electronics.json\", \n",
    "             dev_filename=\"val-qar_squad-electronics.json\", \n",
    "             use_gpu=True, n_epochs=1, save_dir=\"models/haystack/\",\n",
    "             evaluate_every=1000,\n",
    "             batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 12:40:51 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 12:40:54 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "03/06/2021 12:40:54 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "new_reader = FARMReader(model_name_or_path=\"models/haystack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1150/1150 [00:02<00:00, 390.39 Dicts/s]\n",
      "Evaluating: 100%|██████████| 133/133 [01:17<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "reader_eval_results = new_reader.eval_on_file(\"data/amazon-qa\", \"val-qar_squad-music.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.7417391304347826\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(new_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.002s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2580>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2400>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2a60>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "ConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             response = self.pool.urlopen(\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    720\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;31m# Disabled, indicate to re-raise the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-671ad1318973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnumber_of_answers_to_fetch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"asin\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_answers_to_fetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Question: {prediction['query']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, filters, top_k_retriever, top_k_reader)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         output = self.pipeline.run(\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mhas_next_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_node_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"component\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mnext_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_node_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline_type, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipeline_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpipeline_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Indexing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/base.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, query, filters, top_k_retriever, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     ):\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/sparse.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self, query, filters, top_k, index)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/document_store/elasticsearch.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, filters, top_k, custom_query, index)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Retriever query: {body}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_es_hit_to_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_embedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"from\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m         return self.transport.perform_request(\n\u001b[0m\u001b[1;32m   1659\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0m_make_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0;31m# raise exception on last retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 status, headers_response, data = connection.perform_request(\n\u001b[0m\u001b[1;32m    359\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TIMEOUT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"N/A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# raise warnings if any from the 'Warnings' header.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused)"
     ]
    }
   ],
   "source": [
    "query = \"Is a snare included?\"\n",
    "# DIY drumkit\n",
    "asin = \"B009VDW4OW\"\n",
    "number_of_answers_to_fetch = 3\n",
    "\n",
    "prediction = pipe.run(query=query, filters={\"asin\": [asin]}, top_k_retriever=10, top_k_reader=number_of_answers_to_fetch)\n",
    "print(f\"Question: {prediction['query']}\")\n",
    "print(\"\\n\")\n",
    "for i in range(number_of_answers_to_fetch):\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Answer: {prediction['answers'][i]['answer']}\")\n",
    "    print(f\"ASIN: {prediction['answers'][i]['meta']['asin']}\")\n",
    "    print(f\"Is answerable?: {prediction['answers'][i]['meta']['is_answerable']}\")\n",
    "    print(f\"Context: {prediction['answers'][i]['context']}\")\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "#### New reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1828/1828 [00:03<00:00, 507.82 Dicts/s]\n",
      "Evaluating: 100%|██████████| 238/238 [02:16<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.5\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "reader_eval_results = new_reader.eval_on_file(train_data, \"val-qar_squad-music.json\", device='cuda')\n",
    "\n",
    "## Reader Top-N-Accuracy is the proportion of predicted answers that match with their corresponding correct answer\n",
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQuAD reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-music.json: 100%|██████████| 2100/2100 [00:03<00:00, 664.52 Dicts/s]\n",
      "Evaluating: 100%|██████████| 210/210 [02:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.0\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "reader_eval_results = reader.eval_on_file(train_data, \"train-qar_squad-music.json\", device='cuda')\n",
    "\n",
    "## Reader Top-N-Accuracy is the proportion of predicted answers that match with their corresponding correct answer\n",
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformerlab",
   "language": "python",
   "name": "transformerlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
