{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 15:07:58 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
      "03/06/2021 15:07:58 - INFO - faiss.loader -   Loading faiss.\n",
      "03/06/2021 15:07:59 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "from haystack.pipeline import ExtractiveQAPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books  electronics  grocery  movies  restaurants  tripadvisor\n"
     ]
    }
   ],
   "source": [
    "data = Path('./data/subjqa')\n",
    "!ls {data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>nn_mod</th>\n",
       "      <th>nn_asp</th>\n",
       "      <th>query_mod</th>\n",
       "      <th>query_asp</th>\n",
       "      <th>q_review_id</th>\n",
       "      <th>q_reviews_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_subj_level</th>\n",
       "      <th>ques_subj_score</th>\n",
       "      <th>is_ques_subjective</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>human_ans_spans</th>\n",
       "      <th>human_ans_indices</th>\n",
       "      <th>answer_subj_level</th>\n",
       "      <th>ans_subj_score</th>\n",
       "      <th>is_ans_subjective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B006ZS5ATM</td>\n",
       "      <td>electronics</td>\n",
       "      <td>sore</td>\n",
       "      <td>ear</td>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>headphone</td>\n",
       "      <td>adb20314dbbd8196b7e9fb587b78147f</td>\n",
       "      <td>6e1052529424f3a98d303380155c9dde</td>\n",
       "      <td>What do you think about headphone?</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>197e760a49907baeff809b2ccdfe466f</td>\n",
       "      <td>I had a smaller headset that went on the ear. After a 8 - 10 hour workday, m...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(547, 561)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0074BW614</td>\n",
       "      <td>electronics</td>\n",
       "      <td>perfect</td>\n",
       "      <td>size</td>\n",
       "      <td>single</td>\n",
       "      <td>complaint</td>\n",
       "      <td>991b7bc677086cc5ad62c997a35873ec</td>\n",
       "      <td>dc3a5caea480bb9e6f2af3fb84f7f2ac</td>\n",
       "      <td>What are complaint of these guys?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>0e61b7c301c4881e6c53ebd9f678e84f</td>\n",
       "      <td>I really am enjoying my Kindle Fire HD. It does so many things. You can find...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(541, 555)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B001ELJER4</td>\n",
       "      <td>electronics</td>\n",
       "      <td>great</td>\n",
       "      <td>feature</td>\n",
       "      <td>several</td>\n",
       "      <td>feature</td>\n",
       "      <td>2a47f58ba5c0e3a9e7eade75d7db125d</td>\n",
       "      <td>eb8f94f30b27bec871c9256b4f9bccc2</td>\n",
       "      <td>How is the feature?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>905de243991becdba0c365b595855452</td>\n",
       "      <td>Big complaint:  Garmin needs to trim the product line and concentrate on sel...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(5262, 5276)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00GP4BVTO</td>\n",
       "      <td>electronics</td>\n",
       "      <td>versatile</td>\n",
       "      <td>case</td>\n",
       "      <td>slim</td>\n",
       "      <td>profile</td>\n",
       "      <td>12264045ff398038d51f77c33433f4a9</td>\n",
       "      <td>eb0426464208a41782c22caa0df306ae</td>\n",
       "      <td>How about profile?</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>aafbb171c3904c5d6e6fcd3542b5d8fa</td>\n",
       "      <td>From the elegant box to the soft rubber like finish and everything in betwee...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(1091, 1105)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B001TH7T2U</td>\n",
       "      <td>electronics</td>\n",
       "      <td>digital</td>\n",
       "      <td>signal</td>\n",
       "      <td>perfect</td>\n",
       "      <td>image</td>\n",
       "      <td>81fa6a0ab1005f15b91e06c460f79c67</td>\n",
       "      <td>a5957740dca399a016a9585676aee4f5</td>\n",
       "      <td>Do you have good image quality?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>86eb84edc027f7230a02b8858e795da1</td>\n",
       "      <td>AmazonBasics are a fantastic value for quality of cable you get.  No need to...</td>\n",
       "      <td>ANSWERNOTFOUND</td>\n",
       "      <td>(478, 492)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id       domain     nn_mod   nn_asp      query_mod  query_asp  \\\n",
       "0  B006ZS5ATM  electronics       sore      ear  uncomfortable  headphone   \n",
       "1  B0074BW614  electronics    perfect     size         single  complaint   \n",
       "2  B001ELJER4  electronics      great  feature        several    feature   \n",
       "3  B00GP4BVTO  electronics  versatile     case           slim    profile   \n",
       "4  B001TH7T2U  electronics    digital   signal        perfect      image   \n",
       "\n",
       "                        q_review_id                      q_reviews_id  \\\n",
       "0  adb20314dbbd8196b7e9fb587b78147f  6e1052529424f3a98d303380155c9dde   \n",
       "1  991b7bc677086cc5ad62c997a35873ec  dc3a5caea480bb9e6f2af3fb84f7f2ac   \n",
       "2  2a47f58ba5c0e3a9e7eade75d7db125d  eb8f94f30b27bec871c9256b4f9bccc2   \n",
       "3  12264045ff398038d51f77c33433f4a9  eb0426464208a41782c22caa0df306ae   \n",
       "4  81fa6a0ab1005f15b91e06c460f79c67  a5957740dca399a016a9585676aee4f5   \n",
       "\n",
       "                             question  question_subj_level  ques_subj_score  \\\n",
       "0  What do you think about headphone?                    5              0.0   \n",
       "1   What are complaint of these guys?                    1              0.2   \n",
       "2                 How is the feature?                    1              0.0   \n",
       "3                  How about profile?                    2              0.0   \n",
       "4     Do you have good image quality?                    1              0.6   \n",
       "\n",
       "   is_ques_subjective                         review_id  \\\n",
       "0               False  197e760a49907baeff809b2ccdfe466f   \n",
       "1               False  0e61b7c301c4881e6c53ebd9f678e84f   \n",
       "2               False  905de243991becdba0c365b595855452   \n",
       "3               False  aafbb171c3904c5d6e6fcd3542b5d8fa   \n",
       "4                True  86eb84edc027f7230a02b8858e795da1   \n",
       "\n",
       "                                                                            review  \\\n",
       "0  I had a smaller headset that went on the ear. After a 8 - 10 hour workday, m...   \n",
       "1  I really am enjoying my Kindle Fire HD. It does so many things. You can find...   \n",
       "2  Big complaint:  Garmin needs to trim the product line and concentrate on sel...   \n",
       "3  From the elegant box to the soft rubber like finish and everything in betwee...   \n",
       "4  AmazonBasics are a fantastic value for quality of cable you get.  No need to...   \n",
       "\n",
       "  human_ans_spans human_ans_indices  answer_subj_level  ans_subj_score  \\\n",
       "0  ANSWERNOTFOUND        (547, 561)                  5             0.0   \n",
       "1  ANSWERNOTFOUND        (541, 555)                  5             0.0   \n",
       "2  ANSWERNOTFOUND      (5262, 5276)                  1             0.0   \n",
       "3  ANSWERNOTFOUND      (1091, 1105)                  2             0.0   \n",
       "4  ANSWERNOTFOUND        (478, 492)                  5             0.0   \n",
       "\n",
       "   is_ans_subjective  \n",
       "0              False  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "4              False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df = pd.read_csv(data/'electronics/splits/train.csv')\n",
    "electronics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df[\"q_review_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1194"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df[\"q_reviews_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANSWERNOTFOUND                                                             1399\n",
       "bass is solid and powerful                                                    3\n",
       "comfortable                                                                   3\n",
       "the sound quality is great                                                    3\n",
       "I especially like the fact that the image is good from almost any angle       2\n",
       "                                                                           ... \n",
       "the volume was just too low                                                   1\n",
       "The bass is great                                                             1\n",
       "The instructions were SUPER easy                                              1\n",
       "per color availability                                                        1\n",
       "It 's totally plug play and it detects when a device connected                1\n",
       "Name: human_ans_spans, Length: 888, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df[\"human_ans_spans\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 19)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to SQuAD format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need this format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": \"Beyoncé\",\n",
    "            \"paragraphs\": [\n",
    "                {\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"question\": \"When did Beyonce start becoming popular?\",\n",
    "                            \"id\": \"56be85543aeaaa14008c9063\",\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": \"in the late 1990s\",\n",
    "                                    \"answer_start\": 269\n",
    "                                }\n",
    "                            ],\n",
    "                            \"is_impossible\": false\n",
    "                        }\n",
    "                        ...\n",
    "                    ],\n",
    "                    \"context\": \"Beyoncé ...\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/squad/train-v2.0.json\", 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ex in data[\"data\"]:\n",
    "#     for qas in ex[\"paragraphs\"]:\n",
    "#         for x in qas[\"qas\"]:\n",
    "#             if x[\"is_impossible\"] == True:\n",
    "#                 print(x)\n",
    "#                 print(\"\\n\\n\")\n",
    "#                 print(qas[\"context\"])\n",
    "                \n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = electronics_df.query(\"human_ans_spans != 'ANSWERNOTFOUND'\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                                                                                     B003VAGXWK\n",
       "domain                                                                                     electronics\n",
       "nn_mod                                                                                           sleek\n",
       "nn_asp                                                                                        keyboard\n",
       "query_mod                                                                                        solid\n",
       "query_asp                                                                                          key\n",
       "q_review_id                                                           73e8277fbf438a7ade8f720ddf8a4f47\n",
       "q_reviews_id                                                          55576d11e04159c488107b442aaff880\n",
       "question                                                            How are the keys of the  keyboard?\n",
       "question_subj_level                                                                                  1\n",
       "ques_subj_score                                                                                    0.0\n",
       "is_ques_subjective                                                                               False\n",
       "review_id                                                             74ae92c2bbeb9511fce8ddb5a4b9411b\n",
       "review                 I was reluctant to try a wireless keyboard, but due to a wire-chomping kitty...\n",
       "human_ans_spans                                                       The illuminated keys are helpful\n",
       "human_ans_indices                                                                           (421, 453)\n",
       "answer_subj_level                                                                                    1\n",
       "ans_subj_score                                                                                     0.0\n",
       "is_ans_subjective                                                                                False\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I was reluctant to try a wireless keyboard, but due to a wire-chomping kitty, decided it was best to go wireless. I'm so glad I did. This keyboard is sleek and stylish. It has a great feel under my fingertips. I was concerned that a wireless keyboard would be &#34;buggy&#34; and not be efficient, but this keyboard is as good as any corded keyboard. It charges easily via USB port and holds a charge for about ten days. The illuminated keys are helpful, if, like me, your eyes aren't as young as they once were. I already had the logitech unifying plug that plugs into my computer for my mouse and touchpad. I turned the keyboard on and the Logitech plug recognized it right away. I highly recommend this keyboard. ANSWERNOTFOUND\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46c1aea2edb4d84bd6d61a9e8ee631e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1806.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a60c4cf21f40bbb08428b950d8cbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=963.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset squad_v2/squad_v2 (download: 44.34 MiB, generated: 122.57 MiB, post-processed: Unknown size, total: 166.91 MiB) to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/9cac55034b086140f0649ecb5c604d09d7da2f2f5b73a90caa2e2bcc1f5cac09...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08976f4807454c02ad3a4e788a1c110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9551051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514c73dba7e3451d80ab6a8ac47e3f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=800683.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad_v2 downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/9cac55034b086140f0649ecb5c604d09d7da2f2f5b73a90caa2e2bcc1f5cac09. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [475], 'text': ['bamboo books']}</td>\n",
       "      <td>The traditional picture of an orderly series of scripts, each one invented suddenly and then completely displacing the previous one, has been conclusively demonstrated to be fiction by the archaeological finds and scholarly research of the later 20th and early 21st centuries. Gradual evolution and the coexistence of two or more scripts was more often the case. As early as the Shang dynasty, oracle-bone script coexisted as a simplified form alongside the normal script of bamboo books (preserved in typical bronze inscriptions), as well as the extra-elaborate pictorial forms (often clan emblems) found on many bronzes.</td>\n",
       "      <td>5726d6b4708984140094d2f1</td>\n",
       "      <td>What were preserved in typical bronze inscriptions?</td>\n",
       "      <td>Chinese_characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>The gyromagnetic ratio γ is the constant of proportionality between the frequency ν of nuclear magnetic resonance (or electron paramagnetic resonance for electrons) and the applied magnetic field B: ν = γB. It is difficult to measure gyromagnetic ratios precisely because of the difficulties in precisely measuring B, but the value for protons in water at 7002298150000000000♠25 °C is known to better than one part per million. The protons are said to be \"shielded\" from the applied magnetic field by the electrons in the water molecule, the same effect that gives rise to chemical shift in NMR spectroscopy, and this is indicated by a prime on the symbol for the gyromagnetic ratio, γ′p. The gyromagnetic ratio is related to the shielded proton magnetic moment μ′p, the spin number I (I = 1⁄2 for protons) and the reduced Planck constant.</td>\n",
       "      <td>5a3ae27d3ff257001ab842eb</td>\n",
       "      <td>What ratio is the difference of proportionality between the frequency ν of nuclear magnetic resonance (or electron paramagnetic resonance for electrons) and the applied magnetic field?</td>\n",
       "      <td>Planck_constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [453], 'text': ['the whole Bible']}</td>\n",
       "      <td>Although the Adventist churches hold much in common, their theologies differ on whether the intermediate state is unconscious sleep or consciousness, whether the ultimate punishment of the wicked is annihilation or eternal torment, the nature of immortality, whether or not the wicked are resurrected after the millennium, and whether the sanctuary of Daniel 8 refers to the one in heaven or one on earth. The movement has encouraged the examination of the whole Bible, leading Seventh-day Adventists and some smaller Adventist groups to observe the Sabbath. The General Conference of Seventh-day Adventists has compiled that church's core beliefs in the 28 Fundamental Beliefs (1980 and 2005), which use Biblical references as justification.</td>\n",
       "      <td>5731e27cb9d445190005e617</td>\n",
       "      <td>The Adventist movement has encouraged examining what in full?</td>\n",
       "      <td>Protestantism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [294], 'text': ['lacquer']}</td>\n",
       "      <td>The die is a negative image of the glass master: typically, several are made, depending on the number of pressing mills that are to make the CD. The die then goes into a press, and the physical image is transferred to the blank CD, leaving a final positive image on the disc. A small amount of lacquer is applied as a ring around the center of the disc, and rapid spinning spreads it evenly over the surface. Edge protection lacquer is applied before the disc is finished. The disc can then be printed and packed.</td>\n",
       "      <td>572f67c704bcaa1900d768e6</td>\n",
       "      <td>How is the positive image on a CD protected?</td>\n",
       "      <td>Compact_disc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [497], 'text': ['civilization, and its art, philosophy, architecture and literature would be instrumental in the formation and development of Western culture.']}</td>\n",
       "      <td>The classical period of Greek civilization covers a time spanning from the early 5th century BC to the death of Alexander the Great, in 323 BC (some authors prefer to split this period into 'Classical', from the end of the Persian wars to the end of the Peloponnesian War, and 'Fourth Century', up to the death of Alexander). It is so named because it set the standards by which Greek civilization would be judged in later eras. The Classical period is also described as the \"Golden Age\" of Greek civilization, and its art, philosophy, architecture and literature would be instrumental in the formation and development of Western culture.</td>\n",
       "      <td>572fb308b2c2fd140056837b</td>\n",
       "      <td>What did the Greeks do that made it possible for the expansion and growth of the opposite of the Eastern Civilization ?</td>\n",
       "      <td>Greeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>Sunni Islam of the Hanafi school has been officially recognized by the government since 2009. Tajikistan considers itself a secular state with a Constitution providing for freedom of religion. The Government has declared two Islamic holidays, Id Al-Fitr and Idi Qurbon, as state holidays. According to a U.S. State Department release and Pew research group, the population of Tajikistan is 98% Muslim. Approximately 87%–95% of them are Sunni and roughly 3% are Shia and roughly 7% are non-denominational Muslims. The remaining 2% of the population are followers of Russian Orthodoxy, Protestantism, Zoroastrianism and Buddhism. A great majority of Muslims fast during Ramadan, although only about one third in the countryside and 10% in the cities observe daily prayer and dietary restrictions.</td>\n",
       "      <td>5aceec8532bba1001ae4b930</td>\n",
       "      <td>Who has declared three Islamic holidays?</td>\n",
       "      <td>Tajikistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'answer_start': [41], 'text': ['more than 10 million volumes']}</td>\n",
       "      <td>Nanjing Library, founded in 1907, houses more than 10 million volumes of printed materials and is the third largest library in China, after the National Library in Beijing and Shanghai Library. Other libraries, such as city-owned Jinling Library and various district libraries, also provide considerable amount of information to citizens. Nanjing University Library is the second largest university libraries in China after Peking University Library, and the fifth largest nationwide, especially in the number of precious collections.</td>\n",
       "      <td>56e7b49000c9c71400d77527</td>\n",
       "      <td>How many volumes does the Nanjing Library have?</td>\n",
       "      <td>Nanjing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'answer_start': [55], 'text': ['Nazi Germany']}</td>\n",
       "      <td>After the Holocaust, which had been perpetrated by the Nazi Germany and its allies prior to and during World War II, Lemkin successfully campaigned for the universal acceptance of international laws defining and forbidding genocides. In 1946, the first session of the United Nations General Assembly adopted a resolution that \"affirmed\" that genocide was a crime under international law, but did not provide a legal definition of the crime. In 1948, the UN General Assembly adopted the Convention on the Prevention and Punishment of the Crime of Genocide (CPPCG) which defined the crime of genocide for the first time.</td>\n",
       "      <td>57335849d058e614000b5896</td>\n",
       "      <td>In which war-era country was the Holocaust immortalized?</td>\n",
       "      <td>Genocide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'answer_start': [384], 'text': ['Yerevan's FC Ararat']}</td>\n",
       "      <td>During Soviet rule, Armenian athletes rose to prominence winning plenty of medals and helping the USSR win the medal standings at the Olympics on numerous occasions. The first medal won by an Armenian in modern Olympic history was by Hrant Shahinyan, who won two golds and two silvers in gymnastics at the 1952 Summer Olympics in Helsinki. In football, their most successful team was Yerevan's FC Ararat, which had claimed most of the Soviet championships in the 70s and had also gone to post victories against professional clubs like FC Bayern Munich in the Euro cup.</td>\n",
       "      <td>573245c9e99e3014001e6616</td>\n",
       "      <td>Which Armenian football team was the most successful?</td>\n",
       "      <td>Armenians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'answer_start': [202], 'text': ['July 1940']}</td>\n",
       "      <td>After the ceasefire following the Fall of France in June 1940, Alsace was annexed to Germany and a rigorous policy of Germanisation was imposed upon it by the Gauleiter Robert Heinrich Wagner. When, in July 1940, the first evacuees were allowed to return, only residents of Alsatian origin were admitted. The last Jews were deported on 15 July 1940 and the main synagogue, a huge Romanesque revival building that had been a major architectural landmark with its 54-metre-high dome since its completion in 1897, was set ablaze, then razed.</td>\n",
       "      <td>5728016b4b864d19001641e7</td>\n",
       "      <td>When were the first evacuees allowed to return?</td>\n",
       "      <td>Strasbourg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(squad[\"train\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup: no fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a single category like `Musical_Instruments` and build a `DataFrame` that has `asin`, `context` columns that we can use to create a simple QA system with an existing model fine-tuned on SQuAD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toys_and_Games'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2category = pd.Series(meta_df[\"category\"].values, index=meta_df[\"qid\"]).to_dict()\n",
    "qid2category[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B000MP20BU'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2asin = pd.Series(meta_df[\"asin\"].values, index=meta_df[\"qid\"]).to_dict()\n",
    "qid2asin[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that all SQuAD entries are answerable (does this make sense?). What about SQuAD v2 with impossible questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2isanswer = pd.Series(meta_df[\"is_answerable\"].values, index=meta_df[\"qid\"]).to_dict()\n",
    "qid2isanswer[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B0057JCYYE'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2asin[331392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "455931it [00:25, 17910.73it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "with open(data/'train-qar_squad.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for _, line in tqdm(enumerate(f)):\n",
    "        row = json.loads(line)\n",
    "        qid = row[\"qas\"][0][\"id\"]\n",
    "        if qid2category[qid] == \"Electronics\":\n",
    "            rows.append((qid2asin[qid], row[\"context\"], row[\"qas\"], qid2isanswer[qid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>qas</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009R95M</td>\n",
       "      <td>This is a pretty cool filter. If you spin it around it will totally change t...</td>\n",
       "      <td>[{'id': 604553, 'is_impossible': False, 'question': 'Does this come with a c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0051GN8GQ</td>\n",
       "      <td>so they fit well and function perfectly as workout headphones. BUT the littl...</td>\n",
       "      <td>[{'id': 698250, 'is_impossible': False, 'question': 'Will these headphones w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00CQ35HBQ</td>\n",
       "      <td>The memory fit into my dell inspiron 15 laptop. The memory was installed and...</td>\n",
       "      <td>[{'id': 639762, 'is_impossible': False, 'question': 'I have a new Dell Inspi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00BOYQH44</td>\n",
       "      <td>This is the best camera I have ever owned. I have shot over 800 pictures &amp; h...</td>\n",
       "      <td>[{'id': 701290, 'is_impossible': False, 'question': 'Does this camera have a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B008HODL7K</td>\n",
       "      <td>Great unit, really can't be beat for the price. Other reviews mentioned unev...</td>\n",
       "      <td>[{'id': 319235, 'is_impossible': False, 'question': 'Does this unit have a C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  B00009R95M   \n",
       "1  B0051GN8GQ   \n",
       "2  B00CQ35HBQ   \n",
       "3  B00BOYQH44   \n",
       "4  B008HODL7K   \n",
       "\n",
       "                                                                              text  \\\n",
       "0  This is a pretty cool filter. If you spin it around it will totally change t...   \n",
       "1  so they fit well and function perfectly as workout headphones. BUT the littl...   \n",
       "2  The memory fit into my dell inspiron 15 laptop. The memory was installed and...   \n",
       "3  This is the best camera I have ever owned. I have shot over 800 pictures & h...   \n",
       "4  Great unit, really can't be beat for the price. Other reviews mentioned unev...   \n",
       "\n",
       "                                                                               qas  \\\n",
       "0  [{'id': 604553, 'is_impossible': False, 'question': 'Does this come with a c...   \n",
       "1  [{'id': 698250, 'is_impossible': False, 'question': 'Will these headphones w...   \n",
       "2  [{'id': 639762, 'is_impossible': False, 'question': 'I have a new Dell Inspi...   \n",
       "3  [{'id': 701290, 'is_impossible': False, 'question': 'Does this camera have a...   \n",
       "4  [{'id': 319235, 'is_impossible': False, 'question': 'Does this unit have a C...   \n",
       "\n",
       "   is_answerable  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.DataFrame(rows, columns=['asin', 'text', \"qas\", 'is_answerable'])\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    108614\n",
       "Name: is_answerable, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df['is_answerable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108614, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25301"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df['asin'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boot ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -nc https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
    "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
    "! chown -R daemon:daemon elasticsearch-7.9.2\n",
    "\n",
    "es_server = Popen(['elasticsearch-7.9.2/bin/elasticsearch'],\n",
    "                   stdout=PIPE, stderr=STDOUT,\n",
    "                   preexec_fn=lambda: os.setuid(1)  # as daemon\n",
    "                  )\n",
    "# wait until ES has started\n",
    "! sleep 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/ [status:200 request:0.094s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.011s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.004s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.024s]\n",
      "03/05/2021 15:11:00 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.002s]\n"
     ]
    }
   ],
   "source": [
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/04/2021 21:20:03 - INFO - elasticsearch -   POST http://localhost:9200/document/_delete_by_query [status:200 request:0.970s]\n"
     ]
    }
   ],
   "source": [
    "document_store.delete_all_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Works perfectly and easy to use. Software download also great.The only surprise was that the one I ordered, (USB) doesn't work with an iPad.I was thinking it would work with both PC and iPad. My mistake. I use this with Logic Pro X on an iMac running Mavericks (it's replacing an Mbox) and with a Sony Vaio running Windows 7 and get excellent results (don't forget to install the Windows drivers or you'll run into latency issues). I also use it with the Auria App on my iPad Air. I did appreciate the direct line in switch...I could hear exactly what was being played into the unit without having to route through the computer. That was a nice feature. More recently, I was very happy to get this working with my ipad mini. I did purchase a recommended usb powered hub Belkin model &#34; F4U020&#34; and with that - I'm good to play music into and out of my ipad. Focusrite. An industry standard.I bought this specifically for use with an iPad to do mobile recording. The app I use is Auria, but GarageBand will work as well. Be sure to use/buy a POWERED USB hub in order to power the Scarlett.Wonderfully quiet device. Simple to use and the mic/instrument inputs are very warm sounding. It is truly shocking to see that you can achieve some VERY convincing, near commercial grade recording with this interface. Mac OS X 10.8.42: UpdateAmazon didn't sent me a 3rd replacement. And I'm really glad they didn't. I ended up saving a lot of money and buyingApogee Duet Audio Interface for iPad & Mac. After using Duet, I can tell you that any sound interface priced between 60 to 200 are the same thing. You may as well buy the simplest cheapest sound interface instead of this show off failure.I am very very VERY surprised about how many stars this product has. when i conect the headphones into the interface and give a test, i cant hear a suitable volume, i hear it very low; and if i increase the volume, this saturated.. very good this is honestly the best interface I've used for recording. this is a must but item you won't regret it. this is a beautiful piece of hardware. sounds really good. easy to use. and the director monitor function is great. the software that came with it is outdated and does not support Mavericks. however, I got on the help line and the gentlemen pointed me to a program called reaper that helped install the software so that I can take full advantage of it's benefits.Other than that! It's GREAT! and I love recording my guitar on it. Clean with no noise.\",\n",
       " 'meta': {'asin': 'B005OZE9SA', 'is_answerable': 1}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [{\"text\": row[\"text\"], \"meta\":{\"asin\": row[\"asin\"], \"is_answerable\": row[\"is_answerable\"]}} for _, row in qa_df.iterrows()]\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 15:11:02 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.124s]\n",
      "03/05/2021 15:11:04 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.382s]\n",
      "03/05/2021 15:11:05 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.381s]\n",
      "03/05/2021 15:11:06 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.281s]\n",
      "03/05/2021 15:11:08 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.237s]\n",
      "03/05/2021 15:11:09 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.254s]\n",
      "03/05/2021 15:11:10 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.260s]\n",
      "03/05/2021 15:11:12 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.275s]\n",
      "03/05/2021 15:11:13 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.273s]\n",
      "03/05/2021 15:11:14 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.272s]\n",
      "03/05/2021 15:11:16 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.264s]\n",
      "03/05/2021 15:11:17 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.276s]\n",
      "03/05/2021 15:11:18 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.331s]\n",
      "03/05/2021 15:11:20 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.288s]\n",
      "03/05/2021 15:11:21 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.285s]\n",
      "03/05/2021 15:11:22 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.257s]\n",
      "03/05/2021 15:11:24 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.265s]\n",
      "03/05/2021 15:11:25 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.238s]\n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 10:59:24 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 10:59:24 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/06/2021 10:59:42 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 10:59:42 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 10:59:45 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True, context_window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/squad/dev-v2.0.json: 100%|██████████| 1204/1204 [00:07<00:00, 162.32 Dicts/s]\n",
      "Evaluating: 100%|██████████| 274/274 [02:36<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# check evaluation on SQuAD v2\n",
    "reader_eval_results = reader.eval_on_file(\"data/squad\", \"dev-v2.0.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.9746483618293608\n",
      "Reader Exact Match: 0.7843005137707403\n",
      "Reader F1-Score: 0.8260896852846605\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1150/1150 [00:03<00:00, 371.15 Dicts/s]\n",
      "Evaluating: 100%|██████████| 133/133 [01:17<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# check evaluation on AmazonQA\n",
    "reader_eval_results = reader.eval_on_file(\"data/amazon-qa\", \"val-qar_squad-music.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.542608695652174\n",
      "Reader Exact Match: 0.0008695652173913044\n",
      "Reader F1-Score: 0.0752376647890378\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 14:39:19 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.088s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.25 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.14 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.83 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.97 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.93 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.88 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.86 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is a snare included?\n",
      "\n",
      "\n",
      "#1\n",
      "Answer: this one only came with one\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: the correct sounds out of it. When I slapped the \"bass\", it would play a \"snare\" sound combined with the bass. When I slapped the \"snare\", I would just get a wood sound.I've also seen images that most cajons come with multiple snares... this one only came with one.I'm really not sure what else to say. I wanted a Cajon to play with.but didn't want to pay 100.00 plus. This was a great option, Easy to put together with the limited tools I had on hand. And cheap enough that I wasn't worried to have \n",
      "\n",
      "\n",
      "\n",
      "#2\n",
      "Answer: this one only came with one\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: the correct sounds out of it. When I slapped the \"bass\", it would play a \"snare\" sound combined with the bass. When I slapped the \"snare\", I would just get a wood sound.I've also seen images that most cajons come with multiple snares... this one only came with one.I'm really not sure what else to say. I wanted a Cajon to play with.but didn't want to pay 100.00 plus. This was a great option, Easy to put together with the limited tools I had on hand. And cheap enough that I wasn't worried to have \n",
      "\n",
      "\n",
      "\n",
      "#3\n",
      "Answer: minimal snare sound\n",
      "ASIN: B009VDW4OW\n",
      "Is answerable?: 1\n",
      "Context: ussionist but a terrible wood worker so my husband built this for me. He said it was super easy and did not require a lot of tools. I've stained it black and added silver glitter paint and it looks snazzy. My only complaint is that it has a minimal snare sound. If you are a real percussionist, before you build this you may want to get some snare wires if you want more of a snare sound. I knew going in this would not be easy to put together. I tried to do as much research as possible, but... if y\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Is a snare included?\"\n",
    "# DIY drumkit\n",
    "asin = \"B009VDW4OW\"\n",
    "number_of_answers_to_fetch = 3\n",
    "\n",
    "prediction = pipe.run(query=query, filters={\"asin\": [asin]}, top_k_retriever=10, top_k_reader=number_of_answers_to_fetch)\n",
    "print(f\"Question: {prediction['query']}\")\n",
    "print(\"\\n\")\n",
    "for i in range(number_of_answers_to_fetch):\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Answer: {prediction['answers'][i]['answer']}\")\n",
    "    print(f\"ASIN: {prediction['answers'][i]['meta']['asin']}\")\n",
    "    print(f\"Is answerable?: {prediction['answers'][i]['meta']['is_answerable']}\")\n",
    "    print(f\"Context: {prediction['answers'][i]['context']}\")\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to the true SQuAD format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with our SQuAD dataset is that it is composed of _line-separated_ JSON instead of the single JSON object that SQuAD traditionally uses. So instead of having examples like \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"context\": \"blah blah\",\n",
    "    \"qas\": [\n",
    "        {\n",
    "            \"id\": 331392,\n",
    "            \"is_impossible\": false,\n",
    "            \"question\": \"blah blah?\",\n",
    "            \"answers\": [\n",
    "                {\n",
    "                    \"answer_start\": 2881,\n",
    "                    \"text\": \"blah blah\"\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            \"human_answers\": [\n",
    "                \"blah blah\",\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "what we really need is a JSON of the form\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": \"Beyoncé\",\n",
    "            \"paragraphs\": [\n",
    "                {\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"question\": \"When did Beyonce start becoming popular?\",\n",
    "                            \"id\": \"56be85543aeaaa14008c9063\",\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": \"in the late 1990s\",\n",
    "                                    \"answer_start\": 269\n",
    "                                }\n",
    "                            ],\n",
    "                            \"is_impossible\": false\n",
    "                        }\n",
    "                        ...\n",
    "                    ],\n",
    "                    \"context\": \"Beyoncé ...\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Let's write a function that does the conversion for us. To warm-up let's load a single example from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "with open(data/\"train-qar_squad.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        qid = ex[\"qas\"][0][\"id\"]\n",
    "        asin = qid2asin[qid]\n",
    "        if asin == \"B0057JCYYE\" or asin == \"B00F9ECDRU\":\n",
    "            examples.append(ex)\n",
    "        if len(examples) > 4:\n",
    "            break\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the human answers, but we do need the mapping from `qid` to `asin` so that we can collect all questions together that belong to the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin2qas = {}\n",
    "seen_asin = set()\n",
    "\n",
    "for ex in examples:\n",
    "    qid = ex[\"qas\"][0][\"id\"]\n",
    "    asin = qid2asin[qid]\n",
    "    qas = [{k:v for k,v in ex[\"qas\"][0].items() if k != \"human_answers\"}]\n",
    "    par = [{\"qas\": qas, \"context\": ex[\"context\"]}]\n",
    "\n",
    "    if asin in seen_asin:\n",
    "        asin2qas[asin].extend(par)\n",
    "    else:\n",
    "        asin2qas[asin] = par\n",
    "        seen_asin.add(asin)\n",
    "\n",
    "\n",
    "# asin2qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_data = []\n",
    "\n",
    "for k,v in asin2qas.items():\n",
    "    squad_ex = {}\n",
    "    squad_ex[\"title\"] = k\n",
    "    squad_ex[\"paragraphs\"] = v\n",
    "    squad_data.append(squad_ex)\n",
    "    \n",
    "squad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dict = {\"data\": squad_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data/\"train-qar_squad.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(squad_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out answer fields\n",
    "with open(data/\"val-qar_squad.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['answers_snippet_spans_bleu2',\n",
       " 'answers_snippet_spans_bleu4',\n",
       " 'answers_snippet_spans_rouge',\n",
       " 'answers_sentence_ir',\n",
       " 'answers_sentence_bleu2',\n",
       " 'answers_sentence_bleu4']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in ex[\"qas\"][0].keys() if k.startswith(\"answers\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_squad_format(input_file: Path, output_file: Path, category: str = \"Musical_Instruments\"):\n",
    "    squad_data = []\n",
    "    asin2qas = {}\n",
    "    seen_asin = set()\n",
    "    answer_fields = ['answers_snippet_spans_bleu2', 'answers_snippet_spans_bleu4',  \n",
    "                     'answers_snippet_spans_rouge', 'answers_sentence_ir', \n",
    "                     'answers_sentence_bleu2',  'answers_sentence_bleu4']\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for _, line in tqdm(enumerate(f)):\n",
    "            row = json.loads(line)\n",
    "            qid = row[\"qas\"][0][\"id\"]\n",
    "            if qid2category[qid] == category:\n",
    "                asin = qid2asin[qid]\n",
    "                qas = [{\"answers\" if k in answer_fields else k:v for k,v in row[\"qas\"][0].items()}]\n",
    "                par = [{\"qas\": qas, \"context\": row[\"context\"]}]\n",
    "                \n",
    "                if asin in seen_asin:\n",
    "                    asin2qas[asin].extend(par)\n",
    "                else:\n",
    "                    asin2qas[asin] = par\n",
    "                    seen_asin.add(asin)\n",
    "                    \n",
    "    for k,v in asin2qas.items():\n",
    "        squad_ex = {}\n",
    "        squad_ex[\"title\"] = k\n",
    "        squad_ex[\"paragraphs\"] = v\n",
    "        squad_data.append(squad_ex)\n",
    "\n",
    "    squad_dict = {\"data\": squad_data}\n",
    "        \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(squad_dict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "455931it [00:13, 34990.08it/s]\n"
     ]
    }
   ],
   "source": [
    "category = \"Electronics\"\n",
    "convert_to_squad_format(data/'train-qar_squad.jsonl', data/f'train-qar_squad-{category.lower()}.json', category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58969it [00:03, 15988.79it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_squad_format(data/'val-qar_squad.jsonl', data/f'val-qar_squad-{category.lower()}.json', category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_json(data/'train-qar_squad-electronics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'B00009R95M', 'paragraphs': [{'qas': [{'id': 604553, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'B0051GN8GQ', 'paragraphs': [{'qas': [{'id': 698250, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'B00CQ35HBQ', 'paragraphs': [{'qas': [{'id': 639762, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'B00BOYQH44', 'paragraphs': [{'qas': [{'id': 701290, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'B008HODL7K', 'paragraphs': [{'qas': [{'id': 319235, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25296</th>\n",
       "      <td>{'title': 'B005LLFY5Y', 'paragraphs': [{'qas': [{'id': 212671, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25297</th>\n",
       "      <td>{'title': 'B0053QC0EU', 'paragraphs': [{'qas': [{'id': 596763, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25298</th>\n",
       "      <td>{'title': 'B0068PVBLS', 'paragraphs': [{'qas': [{'id': 525680, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25299</th>\n",
       "      <td>{'title': 'B009I9MX5Y', 'paragraphs': [{'qas': [{'id': 632546, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25300</th>\n",
       "      <td>{'title': 'B0097F1LW0', 'paragraphs': [{'qas': [{'id': 193506, 'is_impossibl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25301 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  data\n",
       "0      {'title': 'B00009R95M', 'paragraphs': [{'qas': [{'id': 604553, 'is_impossibl...\n",
       "1      {'title': 'B0051GN8GQ', 'paragraphs': [{'qas': [{'id': 698250, 'is_impossibl...\n",
       "2      {'title': 'B00CQ35HBQ', 'paragraphs': [{'qas': [{'id': 639762, 'is_impossibl...\n",
       "3      {'title': 'B00BOYQH44', 'paragraphs': [{'qas': [{'id': 701290, 'is_impossibl...\n",
       "4      {'title': 'B008HODL7K', 'paragraphs': [{'qas': [{'id': 319235, 'is_impossibl...\n",
       "...                                                                                ...\n",
       "25296  {'title': 'B005LLFY5Y', 'paragraphs': [{'qas': [{'id': 212671, 'is_impossibl...\n",
       "25297  {'title': 'B0053QC0EU', 'paragraphs': [{'qas': [{'id': 596763, 'is_impossibl...\n",
       "25298  {'title': 'B0068PVBLS', 'paragraphs': [{'qas': [{'id': 525680, 'is_impossibl...\n",
       "25299  {'title': 'B009I9MX5Y', 'paragraphs': [{'qas': [{'id': 632546, 'is_impossibl...\n",
       "25300  {'title': 'B0097F1LW0', 'paragraphs': [{'qas': [{'id': 193506, 'is_impossibl...\n",
       "\n",
       "[25301 rows x 1 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either something is wrong with my data preparation or getting the model to generalise is _hard_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 14:57:00 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:00 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 14:57:10 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:10 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 14:57:11 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", use_gpu=True, context_window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"data/amazon-qa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 14:57:17 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 14:57:17 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-electronics.json:  88%|████████▊ | 96000/108614 [01:36<00:11, 1131.67 Dicts/s]Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-electronics.json: 100%|██████████| 108614/108614 [01:41<00:00, 1068.48 Dicts/s]\n",
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-electronics.json: 100%|██████████| 13647/13647 [00:15<00:00, 889.83 Dicts/s] \n",
      "03/06/2021 14:59:31 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "03/06/2021 14:59:31 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_training_steps': 8551, 'num_warmup_steps': 1710}'\n",
      "Train epoch 0/0 (Cur. train loss: 2.1635):   5%|▍         | 421/8551 [06:50<2:12:16,  1.02it/s]"
     ]
    }
   ],
   "source": [
    "reader.train(data_dir=train_data, \n",
    "             train_filename=\"train-qar_squad-electronics.json\", \n",
    "             dev_filename=\"val-qar_squad-electronics.json\", \n",
    "             use_gpu=True, n_epochs=1, save_dir=\"models/haystack/\",\n",
    "             evaluate_every=1000,\n",
    "             batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2021 12:40:51 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 12:40:51 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 12:40:54 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "03/06/2021 12:40:54 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Using device: CUDA \n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Number of GPUs: 1\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Distributed Training: False\n",
      "03/06/2021 12:40:54 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "03/06/2021 12:40:55 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "new_reader = FARMReader(model_name_or_path=\"models/haystack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1150/1150 [00:02<00:00, 390.39 Dicts/s]\n",
      "Evaluating: 100%|██████████| 133/133 [01:17<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "reader_eval_results = new_reader.eval_on_file(\"data/amazon-qa\", \"val-qar_squad-music.json\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.7417391304347826\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(new_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.002s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2580>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2400>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2a60>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "03/05/2021 18:21:35 - WARNING - elasticsearch -   POST http://localhost:9200/document/_search [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 245, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/root/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "ConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             response = self.pool.urlopen(\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    720\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;31m# Disabled, indicate to re-raise the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-671ad1318973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnumber_of_answers_to_fetch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"asin\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_answers_to_fetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Question: {prediction['query']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, filters, top_k_retriever, top_k_reader)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         output = self.pipeline.run(\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mhas_next_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_node_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"component\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mnext_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_node_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline_type, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipeline_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpipeline_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Indexing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/base.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, query, filters, top_k_retriever, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     ):\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_retriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/retriever/sparse.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self, query, filters, top_k, index)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/haystack/document_store/elasticsearch.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, filters, top_k, custom_query, index)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Retriever query: {body}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_es_hit_to_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_embedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"from\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m         return self.transport.perform_request(\n\u001b[0m\u001b[1;32m   1659\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0m_make_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0;31m# raise exception on last retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 status, headers_response, data = connection.perform_request(\n\u001b[0m\u001b[1;32m    359\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformerlab/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TIMEOUT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"N/A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# raise warnings if any from the 'Warnings' header.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7ff914bc2d00>: Failed to establish a new connection: [Errno 111] Connection refused)"
     ]
    }
   ],
   "source": [
    "query = \"Is a snare included?\"\n",
    "# DIY drumkit\n",
    "asin = \"B009VDW4OW\"\n",
    "number_of_answers_to_fetch = 3\n",
    "\n",
    "prediction = pipe.run(query=query, filters={\"asin\": [asin]}, top_k_retriever=10, top_k_reader=number_of_answers_to_fetch)\n",
    "print(f\"Question: {prediction['query']}\")\n",
    "print(\"\\n\")\n",
    "for i in range(number_of_answers_to_fetch):\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Answer: {prediction['answers'][i]['answer']}\")\n",
    "    print(f\"ASIN: {prediction['answers'][i]['meta']['asin']}\")\n",
    "    print(f\"Is answerable?: {prediction['answers'][i]['meta']['is_answerable']}\")\n",
    "    print(f\"Context: {prediction['answers'][i]['context']}\")\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "#### New reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/val-qar_squad-music.json: 100%|██████████| 1828/1828 [00:03<00:00, 507.82 Dicts/s]\n",
      "Evaluating: 100%|██████████| 238/238 [02:16<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.5\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "reader_eval_results = new_reader.eval_on_file(train_data, \"val-qar_squad-music.json\", device='cuda')\n",
    "\n",
    "## Reader Top-N-Accuracy is the proportion of predicted answers that match with their corresponding correct answer\n",
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQuAD reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/amazon-qa/train-qar_squad-music.json: 100%|██████████| 2100/2100 [00:03<00:00, 664.52 Dicts/s]\n",
      "Evaluating: 100%|██████████| 210/210 [02:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Top-N-Accuracy: 0.0\n",
      "Reader Exact Match: 0.0\n",
      "Reader F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "reader_eval_results = reader.eval_on_file(train_data, \"train-qar_squad-music.json\", device='cuda')\n",
    "\n",
    "## Reader Top-N-Accuracy is the proportion of predicted answers that match with their corresponding correct answer\n",
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformerlab",
   "language": "python",
   "name": "transformerlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
